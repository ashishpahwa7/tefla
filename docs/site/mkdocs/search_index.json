{
    "docs": [
        {
            "location": "/", 
            "text": "Tefla: Deep Learning library, a Higher level API for TensorFlow\n\n\nTefla is built on top of Tensorflow. It provides higher level access to tensorflow's features.  \n\n\nTefla features:\n\n\n    . Support for data-sets, data-augmentation\n\n    . easy to define complex deep models\n\n    . single and multi GPU training\n\n    . various prediction fnctions including ensembling of models\n\n    . different metrics for performance measurement\\\n\n    . custom losses\n\n    . learning rate schedules, polynomial, step, validation_loss based\n\n\n\nTensorFlow Installation\n\n\nTefla requires Tensorflow(version \n=r0.12)\n\n\nTefla Installation\n\n\nfor current version installation:\n\n\npip install git+https://github.com/n3011/tefla.git\n\n\n\n\nExamples\n\n\nMnist example gives a overview about Tefla usages\n\n\ndef model(is_training, reuse):\n    common_args = common_layer_args(is_training, reuse)\n    conv_args = make_args(batch_norm=True, activation=prelu, **common_args)\n    fc_args = make_args(activation=prelu, **common_args)\n    logit_args = make_args(activation=None, **common_args)\n\n    x = input((None, height, width, 1), **common_args)\n    x = conv2d(x, 32, name='conv1_1', **conv_args)\n    x = conv2d(x, 32, name='conv1_2', **conv_args)\n    x = max_pool(x, name='pool1', **common_args)\n    x = dropout(x, drop_p=0.25, name='dropout1', **common_args)\n    x = fully_connected(x, n_output=128, name='fc1', **fc_args)\n    x = dropout(x, drop_p=0.5, name='dropout2', **common_args)\n    logits = fully_connected(x, n_output=10, name=\nlogits\n, **logit_args)\n    predictions = softmax(logits, name='predictions', **common_args)\n\n    return end_points(is_training)\n\ntraining_cnf = {\n    'classification': True,\n    'validation_scores': [('validation accuracy', util.accuracy_wrapper), ('validation kappa', util.kappa_wrapper)],\n    'num_epochs': 50,\n    'lr_policy': StepDecayPolicy(\n        schedule={\n            0: 0.01,\n            30: 0.001,\n        }\n    )\n}\nutil.init_logging('train.log', file_log_level=logging.INFO, console_log_level=logging.INFO)\n\ntrainer = SupervisedTrainer(model, training_cnf, classification=training_cnf['classification'])\ntrainer.fit(data_set, weights_from=None, start_epoch=1, verbose=1, summary_every=10)", 
            "title": "Home"
        }, 
        {
            "location": "/#tefla-deep-learning-library-a-higher-level-api-for-tensorflow", 
            "text": "Tefla is built on top of Tensorflow. It provides higher level access to tensorflow's features.    Tefla features:      . Support for data-sets, data-augmentation\n\n    . easy to define complex deep models\n\n    . single and multi GPU training\n\n    . various prediction fnctions including ensembling of models\n\n    . different metrics for performance measurement\\\n\n    . custom losses\n\n    . learning rate schedules, polynomial, step, validation_loss based  TensorFlow Installation  Tefla requires Tensorflow(version  =r0.12)  Tefla Installation  for current version installation:  pip install git+https://github.com/n3011/tefla.git", 
            "title": "Tefla: Deep Learning library, a Higher level API for TensorFlow"
        }, 
        {
            "location": "/#examples", 
            "text": "Mnist example gives a overview about Tefla usages  def model(is_training, reuse):\n    common_args = common_layer_args(is_training, reuse)\n    conv_args = make_args(batch_norm=True, activation=prelu, **common_args)\n    fc_args = make_args(activation=prelu, **common_args)\n    logit_args = make_args(activation=None, **common_args)\n\n    x = input((None, height, width, 1), **common_args)\n    x = conv2d(x, 32, name='conv1_1', **conv_args)\n    x = conv2d(x, 32, name='conv1_2', **conv_args)\n    x = max_pool(x, name='pool1', **common_args)\n    x = dropout(x, drop_p=0.25, name='dropout1', **common_args)\n    x = fully_connected(x, n_output=128, name='fc1', **fc_args)\n    x = dropout(x, drop_p=0.5, name='dropout2', **common_args)\n    logits = fully_connected(x, n_output=10, name= logits , **logit_args)\n    predictions = softmax(logits, name='predictions', **common_args)\n\n    return end_points(is_training)\n\ntraining_cnf = {\n    'classification': True,\n    'validation_scores': [('validation accuracy', util.accuracy_wrapper), ('validation kappa', util.kappa_wrapper)],\n    'num_epochs': 50,\n    'lr_policy': StepDecayPolicy(\n        schedule={\n            0: 0.01,\n            30: 0.001,\n        }\n    )\n}\nutil.init_logging('train.log', file_log_level=logging.INFO, console_log_level=logging.INFO)\n\ntrainer = SupervisedTrainer(model, training_cnf, classification=training_cnf['classification'])\ntrainer.fit(data_set, weights_from=None, start_epoch=1, verbose=1, summary_every=10)", 
            "title": "Examples"
        }, 
        {
            "location": "/", 
            "text": "Tefla: Deep Learning library, a Higher level API for TensorFlow\n\n\nTefla is built on top of Tensorflow. It provides higher level access to tensorflow's features.  \n\n\nTefla features:\n\n\n    . Support for data-sets, data-augmentation\n\n    . easy to define complex deep models\n\n    . single and multi GPU training\n\n    . various prediction fnctions including ensembling of models\n\n    . different metrics for performance measurement\\\n\n    . custom losses\n\n    . learning rate schedules, polynomial, step, validation_loss based\n\n\n\nTensorFlow Installation\n\n\nTefla requires Tensorflow(version \n=r0.12)\n\n\nTefla Installation\n\n\nfor current version installation:\n\n\npip install git+https://github.com/n3011/tefla.git\n\n\n\n\nExamples\n\n\nMnist example gives a overview about Tefla usages\n\n\ndef model(is_training, reuse):\n    common_args = common_layer_args(is_training, reuse)\n    conv_args = make_args(batch_norm=True, activation=prelu, **common_args)\n    fc_args = make_args(activation=prelu, **common_args)\n    logit_args = make_args(activation=None, **common_args)\n\n    x = input((None, height, width, 1), **common_args)\n    x = conv2d(x, 32, name='conv1_1', **conv_args)\n    x = conv2d(x, 32, name='conv1_2', **conv_args)\n    x = max_pool(x, name='pool1', **common_args)\n    x = dropout(x, drop_p=0.25, name='dropout1', **common_args)\n    x = fully_connected(x, n_output=128, name='fc1', **fc_args)\n    x = dropout(x, drop_p=0.5, name='dropout2', **common_args)\n    logits = fully_connected(x, n_output=10, name=\nlogits\n, **logit_args)\n    predictions = softmax(logits, name='predictions', **common_args)\n\n    return end_points(is_training)\n\ntraining_cnf = {\n    'classification': True,\n    'validation_scores': [('validation accuracy', util.accuracy_wrapper), ('validation kappa', util.kappa_wrapper)],\n    'num_epochs': 50,\n    'lr_policy': StepDecayPolicy(\n        schedule={\n            0: 0.01,\n            30: 0.001,\n        }\n    )\n}\nutil.init_logging('train.log', file_log_level=logging.INFO, console_log_level=logging.INFO)\n\ntrainer = SupervisedTrainer(model, training_cnf, classification=training_cnf['classification'])\ntrainer.fit(data_set, weights_from=None, start_epoch=1, verbose=1, summary_every=10)", 
            "title": "Index"
        }, 
        {
            "location": "/#tefla-deep-learning-library-a-higher-level-api-for-tensorflow", 
            "text": "Tefla is built on top of Tensorflow. It provides higher level access to tensorflow's features.    Tefla features:      . Support for data-sets, data-augmentation\n\n    . easy to define complex deep models\n\n    . single and multi GPU training\n\n    . various prediction fnctions including ensembling of models\n\n    . different metrics for performance measurement\\\n\n    . custom losses\n\n    . learning rate schedules, polynomial, step, validation_loss based  TensorFlow Installation  Tefla requires Tensorflow(version  =r0.12)  Tefla Installation  for current version installation:  pip install git+https://github.com/n3011/tefla.git", 
            "title": "Tefla: Deep Learning library, a Higher level API for TensorFlow"
        }, 
        {
            "location": "/#examples", 
            "text": "Mnist example gives a overview about Tefla usages  def model(is_training, reuse):\n    common_args = common_layer_args(is_training, reuse)\n    conv_args = make_args(batch_norm=True, activation=prelu, **common_args)\n    fc_args = make_args(activation=prelu, **common_args)\n    logit_args = make_args(activation=None, **common_args)\n\n    x = input((None, height, width, 1), **common_args)\n    x = conv2d(x, 32, name='conv1_1', **conv_args)\n    x = conv2d(x, 32, name='conv1_2', **conv_args)\n    x = max_pool(x, name='pool1', **common_args)\n    x = dropout(x, drop_p=0.25, name='dropout1', **common_args)\n    x = fully_connected(x, n_output=128, name='fc1', **fc_args)\n    x = dropout(x, drop_p=0.5, name='dropout2', **common_args)\n    logits = fully_connected(x, n_output=10, name= logits , **logit_args)\n    predictions = softmax(logits, name='predictions', **common_args)\n\n    return end_points(is_training)\n\ntraining_cnf = {\n    'classification': True,\n    'validation_scores': [('validation accuracy', util.accuracy_wrapper), ('validation kappa', util.kappa_wrapper)],\n    'num_epochs': 50,\n    'lr_policy': StepDecayPolicy(\n        schedule={\n            0: 0.01,\n            30: 0.001,\n        }\n    )\n}\nutil.init_logging('train.log', file_log_level=logging.INFO, console_log_level=logging.INFO)\n\ntrainer = SupervisedTrainer(model, training_cnf, classification=training_cnf['classification'])\ntrainer.fit(data_set, weights_from=None, start_epoch=1, verbose=1, summary_every=10)", 
            "title": "Examples"
        }, 
        {
            "location": "/installation/", 
            "text": "Installation\n\n\nTensorflow Installation\n\n\nTefla requires Tensorflow (version \n= 0.12.0) to be installed.\n\n\nSelect the correct binary to install, according to your system:\n\n\n# Ubuntu/Linux 64-bit, CPU only, Python 2.7\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see \nInstalling from sources\n below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only, Python 2.7:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py2-none-any.whl\n\n# Mac OS X, GPU enabled, Python 2.7:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0-py2-none-any.whl\n\n# Ubuntu/Linux 64-bit, CPU only, Python 3.4\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp34-cp34m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 3.4\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see \nInstalling from sources\n below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp34-cp34m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, CPU only, Python 3.5\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp35-cp35m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 3.5\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see \nInstalling from sources\n below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-linux_x86_64.whl\n\n# Mac OS X, CPU only, Python 3.4 or 3.5:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\n\n# Mac OS X, GPU enabled, Python 3.4 or 3.5:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0-py3-none-any.whl\n\n\n\n\nThen install TensorFlow:\n\n\n# Python 2\n$ sudo pip install $TF_BINARY_URL\n\n# Python 3\n$ sudo pip3 install $TF_BINARY_URL\n\n\n\n\n\n\nFor more details: \nTensorflow installation instructions\n.\n\n\n\n\nTefla Installation\n\n\nTo install Tefla, the easiest way is to run\n\n\nFor the bleeding edge version:\n\n\npip install git+https://github.com/n3011/tefla.git\n\n\n\n\nOtherwise, you can also install from source by running (from source folder):\n\n\npython setup.py install\n\n\n\n\nUpgrade Tensorflow\n\n\nIf you version for Tensorflow is too old (under 0.12.0), you may upgrade Tensorflow to avoid some incompatibilities with Tefla.\nTo upgrade Tensorflow, you first need to uninstall Tensorflow and Protobuf:\n\n\npip uninstall protobuf\npip uninstall tensorflow\n\n\n\n\nThen you can re-install Tensorflow:\n\n\nUsing Latest Tensorflow\n\n\nTefla is compatible with \nmaster version\n of Tensorflow, but some warnings may appear.", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#installation", 
            "text": "", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#tensorflow-installation", 
            "text": "Tefla requires Tensorflow (version  = 0.12.0) to be installed.  Select the correct binary to install, according to your system:  # Ubuntu/Linux 64-bit, CPU only, Python 2.7\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 2.7\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see  Installing from sources  below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl\n\n# Mac OS X, CPU only, Python 2.7:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py2-none-any.whl\n\n# Mac OS X, GPU enabled, Python 2.7:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0-py2-none-any.whl\n\n# Ubuntu/Linux 64-bit, CPU only, Python 3.4\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp34-cp34m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 3.4\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see  Installing from sources  below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp34-cp34m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, CPU only, Python 3.5\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp35-cp35m-linux_x86_64.whl\n\n# Ubuntu/Linux 64-bit, GPU enabled, Python 3.5\n# Requires CUDA toolkit 8.0 and CuDNN v5. For other versions, see  Installing from sources  below.\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-linux_x86_64.whl\n\n# Mac OS X, CPU only, Python 3.4 or 3.5:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\n\n# Mac OS X, GPU enabled, Python 3.4 or 3.5:\n$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-0.12.0-py3-none-any.whl  Then install TensorFlow:  # Python 2\n$ sudo pip install $TF_BINARY_URL\n\n# Python 3\n$ sudo pip3 install $TF_BINARY_URL   For more details:  Tensorflow installation instructions .", 
            "title": "Tensorflow Installation"
        }, 
        {
            "location": "/installation/#tefla-installation", 
            "text": "To install Tefla, the easiest way is to run  For the bleeding edge version:  pip install git+https://github.com/n3011/tefla.git  Otherwise, you can also install from source by running (from source folder):  python setup.py install", 
            "title": "Tefla Installation"
        }, 
        {
            "location": "/installation/#upgrade-tensorflow", 
            "text": "If you version for Tensorflow is too old (under 0.12.0), you may upgrade Tensorflow to avoid some incompatibilities with Tefla.\nTo upgrade Tensorflow, you first need to uninstall Tensorflow and Protobuf:  pip uninstall protobuf\npip uninstall tensorflow  Then you can re-install Tensorflow:", 
            "title": "Upgrade Tensorflow"
        }, 
        {
            "location": "/installation/#using-latest-tensorflow", 
            "text": "Tefla is compatible with  master version  of Tensorflow, but some warnings may appear.", 
            "title": "Using Latest Tensorflow"
        }, 
        {
            "location": "/core/layers/", 
            "text": "Define input layer\n\n\ntefla.core.layers.input\n  (shape,  name='inputs',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nshape\n: A \nTensor\n, define the input shape\ne.g. for image input [batch_size, height, width, depth]\n\n\nname\n: A optional score/name for this op\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA placeholder for the input\n\n\n\n\nAdd item to colelction\n\n\ntefla.core.layers.register_to_collections\n  (inputs,  name=None,  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nshape\n: A \nTensor\n, define the input shape\ne.g. for image input [batch_size, height, width, depth]\n\n\nname\n: A optional score/name for this op\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA placeholder for the input\n\n\n\n\nAdds a fully connected layer\n\n\ntefla.core.layers.fully_connected\n  (x,  n_output,  is_training,  reuse,  trainable=True,  w_init=\n,  b_init=0.0,  w_regularizer=\n,  w_normalized=False,  name='fc',  batch_norm=None,  batch_norm_args=None,  activation=None,  params=None,  outputs_collections=None,  use_bias=True)\n\n\nfully_connected\n creates a variable called \nweights\n, representing a fully\nconnected weight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank greater than 2, then \nx\n is flattened\nprior to the initial matrix multiply by \nweights\n.\n\n\nArgs\n\n\n\n\n\nx\n: A \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, depth]\n, \n[None, None, None, channels]\n.\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n -\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 2-D \nTensor\n variable representing the result of the series of operations.\ne.g: 2-D \nTensor\n [batch, n_output].\n\n\n\n\nAdds a 2D convolutional layer\n\n\ntefla.core.layers.conv2d\n  (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nconvolutional layer\n creates a variable called \nweights\n, representing a conv\nweight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 4-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a 2D dilated convolutional layer\n\n\ntefla.core.layers.dilated_conv2d\n  (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  dilation=1,  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='dilated_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nalso known as convolution with holes or atrous convolution.\nIf the rate parameter is equal to one, it performs regular 2-D convolution.\nIf the rate parameter\nis greater than one, it performs convolution with holes, sampling the input\nvalues every rate pixels in the height and width dimensions.\n\nconvolutional layer\n creates a variable called \nweights\n, representing a conv\nweight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with rank 4 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\n\n\ndimensions of of the filters.\n\n\ndilation\n:  A positive int32. The stride with which we sample input values across\nthe height and width dimensions. Equivalently, the rate by which we upsample the\nfilter values by inserting zeros across the height and width dimensions. In the literature,\nthe same parameter is sometimes called input stride/rate or dilation.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 4-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a 2D seperable convolutional layer\n\n\ntefla.core.layers.separable_conv2d\n  (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  depth_multiplier=1,  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='separable_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nPerforms a depthwise convolution that acts separately on channels followed by\na pointwise convolution that mixes channels. Note that this is separability between\ndimensions [1, 2] and 3, not spatial separability between dimensions 1 and 2.\n\nconvolutional layer\n creates two variable called \ndepthwise_W\n and \npointwise_W\n,\n\ndepthwise_W\n is multiplied by \nx\n to produce depthwise conolution, which is multiplied by\nthe \npointwise_W\n to produce a output \nTensor\n\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with rank 4 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\ndimensions of of the filters.\n\n\ndepth_multiplier\n:  A positive int32. the number of depthwise convolution output channels for\neach input channel. The total number of depthwise convolution output\nchannels will be equal to `num_filters_in * depth_multiplier\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 4-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a 2D sdepthwise convolutional layer\n\n\ntefla.core.layers.depthwise_conv2d\n  (x,  depth_multiplier,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='depthwise_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nGiven an input tensor of shape [batch, in_height, in_width, in_channels] and a filter\ntensor of shape [filter_height, filter_width, in_channels, channel_multiplier] containing\nin_channels convolutional filters of depth 1, depthwise_conv2d applies a different filter\nto each input channel (expanding from 1 channel to channel_multiplier channels for each),\nthen concatenates the results together. The output has in_channels * channel_multiplier channels.\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with rank 4 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\ndepth_multiplier\n:  A positive int32. the number of depthwise convolution output channels for\neach input channel. The total number of depthwise convolution output\nchannels will be equal to `num_filters_in * depth_multiplier\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe tensor variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a 3D convolutional layer\n\n\ntefla.core.layers.conv3d\n  (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3,  3),  stride=  (1,  1,  1),  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='conv3d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nconvolutional layer\n creates a variable called \nweights\n, representing a conv\nweight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 5\n\n\nArgs\n\n\n\n\n\nx\n: A 5-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_depth, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int, or  list/tuple of 3 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int, or tuple/list of 3 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 5-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 5-D \nTensor\n [batch, new_depth, new_height, new_width, n_output].\n\n\n\n\nAdds a 2D upsampling or deconvolutional layer\n\n\ntefla.core.layers.upsample2d\n  (input_,  output_shape,  is_training,  reuse,  trainable=True,  filter_size=  (5,  5),  stride=  (2,  2),  w_init=\n,  b_init=0.0,  w_regularizer=\n,  batch_norm=None,  batch_norm_args=None,  activation=None,  name='deconv2d',  use_bias=True,  with_w=False,  outputs_collections=None,  **unused)\n\n\nhis operation is sometimes called \"deconvolution\" after Deconvolutional Networks,\nbut is actually the transpose (gradient) of conv2d rather than an actual deconvolution.\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\noutput_shape\n: 4D tensor, the output shape\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe tensor variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a 3D upsampling or deconvolutional layer\n\n\ntefla.core.layers.upsample3d\n  (input_,  output_shape,  is_training,  reuse,  trainable=True,  filter_size=  (5,  5,  5),  stride=  (2,  2,  2),  w_init=\n,  b_init=0.0,  w_regularizer=\n,  batch_norm=None,  batch_norm_args=None,  activation=None,  name='deconv3d',  use_bias=True,  with_w=False,  outputs_collections=None,  **unused)\n\n\nhis operation is sometimes called \"deconvolution\" after Deconvolutional Networks,\nbut is actually the transpose (gradient) of conv2d rather than an actual deconvolution.\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 5\n\n\nArgs\n\n\n\n\n\nx\n: A 5-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_depth, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\noutput_shape\n: 5D tensor, the output shape\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 3 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 3 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe tensor variable representing the result of the series of operations.\ne.g.: 5-D \nTensor\n [batch, new_depth, new_height, new_width, n_output].\n\n\n\n\nAdds a 1D convolutional layer\n\n\ntefla.core.layers.conv1d\n  (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=3,  stride=1,  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  untie_biases=False,  name='conv1d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nconvolutional layer\n creates a variable called \nweights\n, representing a conv\nweight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 3-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a `int specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a \nint\n specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 3-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 3-D \nTensor\n [batch, new_width, n_output].\n\n\n\n\nMax Pooling 1D\n\n\ntefla.core.layers.max_pool_1d\n  (x,  filter_size=3,  stride=2,  padding='SAME',  name='maxpool1d',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a 3-D \nTensor\n [batch_size, steps, in_channels].\n\n\nkernel_size\n: \nint\n or \nlist of int\n. Pooling kernel size.\n\n\nstrides\n: \nint\n or \nlist of int\n. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'maxpool1d'.\n\n\n\n\nReturns\n\n\n\n3-D Tensor [batch, pooled steps, in_channels].\n\n\n\n\nAvg Pooling 1D\n\n\ntefla.core.layers.avg_pool_1d\n  (x,  filter_size=3,  stride=2,  padding='SAME',  name='avgpool1d',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a 3-D \nTensor\n [batch_size, steps, in_channels].\n\n\nkernel_size\n: \nint\n or \nlist of int\n. Pooling kernel size.\n\n\nstrides\n: \nint\n or \nlist of int\n. Strides of conv operation.\nDefault: same as kernel_size.\n\n\npadding\n: \nstr\n from \n\"same\", \"valid\"\n. Padding algo to use.\nDefault: 'same'.\n\n\nname\n: A name for this layer (optional). Default: 'avgpool1d'.\n\n\n\n\nReturns\n\n\n\n3-D Tensor [batch, pooled steps, in_channels].\n\n\n\n\nAdds a 2D highway convolutional layer\n\n\ntefla.core.layers.highway_conv2d\n  (x,  n_output,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init=\n,  b_init=0.0,  w_regularizer=\n,  name='highway_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=\n,  use_bias=True,  outputs_collections=None)\n\n\nhttps://arxiv.org/abs/1505.00387\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank 4\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/ tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a fully connected highway layer\n\n\ntefla.core.layers.highway_fc2d\n  (x,  n_output,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  w_init=\n,  b_init=0.0,  w_regularizer=\n,  name='highway_fc2d',  activation=None,  use_bias=True,  outputs_collections=None)\n\n\nhttps://arxiv.org/abs/1505.00387\nIf a \nbatch_norm\n is provided (such as\n\nbatch_norm\n), it is then applied. Otherwise, if \nbatch_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank greater than 2, then \nx\n is flattened\nprior to the initial matrix multiply by \nweights\n.\n\n\nArgs\n\n\n\n\n\nx\n: A 2-D/4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, depth]\n, \n[None, None, None, channels]\n.\n\n\nis_training\n: Bool, training or testing\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 2-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 2-D \nTensor\n [batch_size, n_output]\n\n\n\n\nMax pooling layer\n\n\ntefla.core.layers.max_pool\n  (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name='pool',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D 'Tensor\nof shape\n[batch_size, height, width, channels]`\n\n\nfilter_size\n: A int or list/tuple of length 2: [kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 2: [stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, channels].\n\n\n\n\nMax pooling layer\n\n\ntefla.core.layers.max_pool_3d\n  (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name='pool',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 5-D 'Tensor\nof shape\n[batch_size, depth, height, width, channels]`\n\n\nfilter_size\n: A int or list/tuple of length 3: [kernel_depth, kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 3: [stride_depth, stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the pooling operation.\ne.g.: 5-D \nTensor\n [batch, new_depth, new_height, new_width, channels].\n\n\n\n\nFractional pooling layer\n\n\ntefla.core.layers.fractional_pool\n  (x,  pooling_ratio=[1.0,  1.44,  1.73,  1.0],  pseudo_random=None,  determinastic=None,  overlapping=None,  name='fractional_pool',  seed=None,  seed2=None,  type='avg',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, height, width, channels]\n\n\npooling_ratio\n: A list of floats that has length \n= 4. Pooling ratio for each\ndimension of value, currently only supports row and col dimension and should\nbe \n= 1.0. For example, a valid pooling ratio looks like [1.0, 1.44, 1.73, 1.0].\nThe first and last elements must be 1.0 because we don't allow pooling on batch and\nchannels dimensions. 1.44 and 1.73 are pooling ratio on height and width\ndimensions respectively.\n\n\npseudo_random\n: An optional bool. Defaults to False. When set to True, generates\nthe pooling sequence in a pseudorandom fashion, otherwise, in a random fashion.\nCheck paper Benjamin Graham, Fractional Max-Pooling for difference between\npseudorandom and random.\n\n\noverlapping\n: An optional bool. Defaults to False. When set to True, it means when pooling,\nthe values at the boundary of adjacent pooling cells are used by both cells.\nFor example: index 0 1 2 3 4\nvalue 20 5 16 3 7; If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used\ntwice. The result would be [41/3, 26/3] for fractional avg pooling.\n\n\ndeterministic\n: An optional bool. Defaults to False. When set to True, a fixed pooling\nregion will be used when iterating over a FractionalAvgPool node in the computation\ngraph. Mainly used in unit test to make FractionalAvgPool deterministic.\n\n\nseed\n: An optional int. Defaults to 0. If either seed or seed2 are set to be non-zero,\nthe random number generator is seeded by the given seed. Otherwise,\nit is seeded by a random seed.\n\n\nseed2\n: An optional int. Defaults to 0. An second seed to avoid seed collision.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntype\n: avg or max pool\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, channels].\n\n\n\n\nRMS pooling layer\n\n\ntefla.core.layers.rms_pool_2d\n  (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name='pool',  epsilon=1e-12,  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, height, width, channels]\n\n\nfilter_size\n: A int or list/tuple of length 2: [kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 2: [stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\nepsilon\n: prevents divide by zero\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, channels].\n\n\n\n\nRMS pooling layer\n\n\ntefla.core.layers.rms_pool_3d\n  (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name='pool',  epsilon=1e-12,  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 5-D \nTensor\n of shape \n[batch_size, depth, height, width, channels]\n\n\nfilter_size\n: A int or list/tuple of length 3: [kernel_depth, kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 3: [stride_depth, stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\nepsilon\n: prevents divide by zero\n\n\n\n\nReturns\n\n\n\nA 5-D \nTensor\n representing the results of the pooling operation.\ne.g.: 5-D \nTensor\n [batch, new_height, new_width, channels].\n\n\n\n\nAvg pooling layer\n\n\ntefla.core.layers.avg_pool_3d\n  (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name=None,  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, depth, height, width, channels]\n\n\nfilter_size\n: A int or list/tuple of length 3: [kernel_depth, kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 3: [stride_depth, stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 5-D \nTensor\n representing the results of the pooling operation.\ne.g.: 5-D \nTensor\n [batch, new_depth, new_height, new_width, channels].\n\n\n\n\nAvg pooling layer\n\n\ntefla.core.layers.avg_pool_2d\n  (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name=None,  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, height, width, channels]\n\n\nfilter_size\n: A int or list/tuple of length 2: [kernel_height, kernel_width] of the\npooling kernel over which the op is computed. Can be an int if both\nvalues are the same.\n\n\nstride\n: A int or list/tuple of length 2: [stride_height, stride_width].\n\n\npadding\n: The padding method, either 'VALID' or 'SAME'.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, channels].\n\n\n\n\nGloabl pooling layer\n\n\ntefla.core.layers.global_avg_pool\n  (x,  name='global_avg_pool',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, height, width, channels]\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, 1, 1, channels].\n\n\n\n\nGloabl max pooling layer\n\n\ntefla.core.layers.global_max_pool\n  (x,  name='global_max_pool',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of shape \n[batch_size, height, width, channels]\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch, 1, 1, channels].\n\n\n\n\nFeature max pooling layer\n\n\ntefla.core.layers.feature_max_pool_1d\n  (x,  stride=2,  name='feature_max_pool_1d',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 2-D tensor of shape \n[batch_size, channels]\n\n\nstride\n: A int.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 2-D \nTensor\n representing the results of the pooling operation.\ne.g.: 2-D \nTensor\n [batch_size, new_channels]\n\n\n\n\nFeature max pooling layer\n\n\ntefla.core.layers.feature_max_pool_2d\n  (x,  stride=2,  name='feature_max_pool_2d',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D tensor of shape \n[batch_size, height, width, channels]\n\n\nstride\n: A int.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\nname\n: Optional scope/name for name_scope.\n\n\n\n\nReturns\n\n\n\nA 4-D \nTensor\n representing the results of the pooling operation.\ne.g.: 4-D \nTensor\n [batch_size, height, width, new_channels]\n\n\n\n\nAdds a Batch Normalization layer from http://arxiv.org/abs/1502.03167\n\n\ntefla.core.layers.batch_norm_tf\n  (x,  name='bn',  scale=False,  updates_collections=None,  **kwargs)\n\n\"Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\", Sergey Ioffe, Christian Szegedy\nCan be used as a normalizer function for conv2d and fully_connected.\nNote: When is_training is True the moving_mean and moving_variance need to be\nupdated, by default the update_ops are placed in \ntf.GraphKeys.UPDATE_OPS\n so\nthey need to be added as a dependency to the \ntrain_op\n, example:\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\n\nif update_ops:\n\n\nupdates = tf.group(*update_ops)\n\n\ntotal_loss = control_flow_ops.with_dependencies([updates], total_loss)\n\nOne can set updates_collections=None to force the updates in place, but that\ncan have speed penalty, specially in distributed settings.\n\nArgs\n\n\n\n\nx\n: a \nTensor\n with 2 or more dimensions, where the first dimension has\n\nbatch_size\n. The normalization is over all but the last dimension if\n\ndata_format\n is \nNHWC\n and the second dimension if \ndata_format\n is\n\nNCHW\n.\n\n\ndecay\n: decay for the moving average. Reasonable values for \ndecay\n are close\nto 1.0, typically in the multiple-nines range: 0.999, 0.99, 0.9, etc.\nLower \ndecay\n value (recommend trying \ndecay\n=0.9) if model experiences\nreasonably good training performance but poor validation and/or test\nperformance. Try zero_debias_moving_mean=True for improved stability.\n\n\ncenter\n: If True, subtract \nbeta\n. If False, \nbeta\n is ignored.\n\n\nscale\n: If True, multiply by \ngamma\n. If False, \ngamma\n is\nnot used. When the next layer is linear (also e.g. \nnn.relu\n), this can be\ndisabled since the scaling can be done by the next layer.\n\n\nepsilon\n: small float added to variance to avoid dividing by zero.\n\n\nactivation_fn\n: activation function, default set to None to skip it and\nmaintain a linear activation.\n\n\nparam_initializers\n: optional initializers for beta, gamma, moving mean and\nmoving variance.\n\n\nupdates_collections\n: collections to collect the update ops for computation.\nThe updates_ops need to be executed with the train_op.\nIf None, a control dependency would be added to make sure the updates are\ncomputed in place.\n\n\nis_training\n: whether or not the layer is in training mode. In training mode\nit would accumulate the statistics of the moments into \nmoving_mean\n and\n\nmoving_variance\n using an exponential moving average with the given\n\ndecay\n. When it is not in training mode then it would use the values of\nthe \nmoving_mean\n and the \nmoving_variance\n.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\noutputs_collections: collections to add the outputs.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see \ntf.Variable\n).\n\n\nbatch_weights\n: An optional tensor of shape \n[batch_size]\n,\ncontaining a frequency weight for each batch item. If present,\nthen the batch normalization uses weighted mean and\nvariance. (This can be used to correct for bias in training\nexample selection.)\n\n\nfused\n:  Use nn.fused_batch_norm if True, nn.batch_normalization otherwise.\n\n\nname\n: Optional scope/name for \nvariable_scope\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the output of the operation.\n\n\n\n\nAdds a Batch Normalization layer from http://arxiv.org/abs/1502.03167\n\n\ntefla.core.layers.batch_norm_lasagne\n  (x,  is_training,  reuse,  trainable=True,  decay=0.9,  epsilon=0.0001,  name='bn',  updates_collections='update_ops',  outputs_collections=None)\n\nInstead of storing and updating moving variance, this layer store and\nupdate moving inverse standard deviation\n\"Batch Normalization: Accelerating Deep Network Training by Reducin Internal Covariate Shift\"\nSergey Ioffe, Christian Szegedy\nCan be used as a normalizer function for conv2d and fully_connected.\nNote: When is_training is True the moving_mean and moving_variance need to be\nupdated, by default the update_ops are placed in \ntf.GraphKeys.UPDATE_OPS\n so\nthey need to be added as a dependency to the \ntrain_op\n, example:\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\n\nif update_ops:\n\n\nupdates = tf.group(*update_ops)\n\n\ntotal_loss = control_flow_ops.with_dependencies([updates], total_loss)\n\nOne can set updates_collections=None to force the updates in place, but that\ncan have speed penalty, specially in distributed settings.\n\n\nArgs\n\n\n\n\n\nx\n: a tensor with 2 or more dimensions, where the first dimension has\n\nbatch_size\n. The normalization is over all but the last dimension if\n\ndata_format\n is \nNHWC\n and the second dimension if \ndata_format\n is\n\nNCHW\n.\n\n\ndecay\n: decay for the moving average. Reasonable values for \ndecay\n are close\nto 1.0, typically in the multiple-nines range: 0.999, 0.99, 0.9, etc.\nLower \ndecay\n value (recommend trying \ndecay\n=0.9) if model experiences\nreasonably good training performance but poor validation and/or test\nperformance. Try zero_debias_moving_mean=True for improved stability.\n\n\nepsilon\n: small float added to variance to avoid dividing by zero.\n\n\nupdates_collections\n: collections to collect the update ops for computation.\nThe updates_ops need to be executed with the train_op.\nIf None, a control dependency would be added to make sure the updates are\ncomputed in place.\n\n\nis_training\n: whether or not the layer is in training mode. In training mode\nit would accumulate the statistics of the moments into \nmoving_mean\n and\n\nmoving_variance\n using an exponential moving average with the given\n\ndecay\n. When it is not in training mode then it would use the values of\nthe \nmoving_mean\n and the \nmoving_variance\n.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\noutputs_collections\n: collections to add the outputs.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see \ntf.Variable\n).\n\n\nname\n: Optional scope/name for \nvariable_scope\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the output of the operation.\n\n\n\n\nPrametric rectifier linear layer\n\n\ntefla.core.layers.prelu\n  (x,  reuse,  alpha_init=0.2,  trainable=True,  name='prelu',  outputs_collections=None)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nalpha_init\n: initalization value for alpha\n\n\ntrainable\n: a bool, training or fixed value\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the prelu activation operation.\n\n\n\n\nComputes relu\n\n\ntefla.core.layers.relu\n  (x,  name='relu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nRectifier linear relu6 layer\n\n\ntefla.core.layers.relu6\n  (x,  name='relu6',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the relu6 activation operation.\n\n\n\n\nSoftplus layer\n\n\ntefla.core.layers.softplus\n  (x,  name='softplus',  outputs_collections=None,  **unused)\n\nComputes softplus: log(exp(x) + 1).\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nSoftsign layer\n\n\ntefla.core.layers.softsign\n  (x,  name='softsign',  outputs_collections=None,  **unused)\n\nComputes softsign: x / (abs(x) + 1).\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes Concatenated ReLU\n\n\ntefla.core.layers.crelu\n  (x,  name='crelu',  outputs_collections=None,  **unused)\n\nConcatenates a ReLU which selects only the positive part of the activation with\na ReLU which selects only the negative part of the activation. Note that\nat as a result this non-linearity doubles the depth of the activations.\nSource: https://arxiv.org/abs/1603.05201\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes exponential linear: exp(features) - 1 if \n 0, features otherwise\n\n\ntefla.core.layers.elu\n  (x,  name='elu',  outputs_collections=None,  **unused)\n\nSee \"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\"\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nlike concatenated ReLU (http://arxiv.org/abs/1603.05201), but then with ELU\n\n\ntefla.core.layers.concat_elu\n  (x,  name='concat_elu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes leaky relu\n\n\ntefla.core.layers.leaky_relu\n  (x,  alpha=0.01,  name='leaky_relu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\naplha\n: the conatant fro scalling the activation\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes reaky relu lasagne style\n\n\ntefla.core.layers.lrelu\n  (x,  leak=0.2,  name='lrelu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nleak\n: the conatant fro scalling the activation\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes maxout activation\n\n\ntefla.core.layers.maxout\n  (x,  k=2,  name='maxout',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nk\n: output channel splitting factor\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes maxout activation\n\n\ntefla.core.layers.offset_maxout\n  (x,  k=2,  name='maxout',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nk\n: output channel splitting factor\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes softmax activation\n\n\ntefla.core.layers.softmax\n  (x,  name='softmax',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nComputes selu\n\n\ntefla.core.layers.selu\n  (x,  alpha=None,  scale=None,  name='selu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nalpha\n: float, selu parameters calculated from fixed points\n\n\nscale\n: float, selu parameters calculated from fixed points\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the selu activation operation.\n\n\n\n\nDropout layer for self normalizing networks\n\n\ntefla.core.layers.dropout_selu\n  (x,  is_training,  drop_p=0.2,  alpha=-1.7580993408473766,  fixedPointMean=0.0,  fixedPointVar=1.0,  noise_shape=None,  seed=None,  name='dropout_selu',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\nx\n: a \nTensor\n.\n\n\nis_training\n: a bool, training or validation\n\n\ndrop_p\n: probability of droping unit\n\n\nfixedPointsMean\n: float, the mean used to calculate the selu parameters\n\n\nfixedPointsVar\n: float, the Variance used to calculate the selu parameters\n\n\nalpha\n: float, product of the two selu parameters\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the dropout operation.\n\n\n\n\nComputes Gumbel Softmax\n\n\ntefla.core.layers.gumbel_softmax\n  (logits,  temperature,  hard=False)\n\nSample from the Gumbel-Softmax distribution and optionally discretize.\nhttp://blog.evjang.com/2016/11/tutorial-categorical-variational.html\nhttps://arxiv.org/abs/1611.01144\n\n\nArgs\n\n\n\n\n\nlogits\n: [batch_size, n_class] unnormalized log-probs\n\n\ntemperature\n: non-negative scalar\n\n\nhard\n: if True, take argmax, but differentiate w.r.t. soft sample y\n\n\n\n\nReturns\n\n\n\n[batch_size, n_class] sample from the Gumbel-Softmax distribution.\nIf hard=True, then the returned sample will be one-hot, otherwise it will\nbe a probabilitiy distribution that sums to 1 across classes\n\n\n\n\nComputes pixel wise softmax activation\n\n\ntefla.core.layers.pixel_wise_softmax\n  (inputs)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n with type \nfloat\n, \ndouble\n, \nint32\n, \nint64\n, \nuint8\n, int16\n, or\nint8`.\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the activation operation.\n\n\n\n\nDropout layer\n\n\ntefla.core.layers.dropout\n  (x,  is_training,  drop_p=0.5,  seed=None,  name='dropout',  outputs_collections=None,  **unused)\n\n\nArgs\n\n\n\n\nx\n: a \nTensor\n.\n\n\nis_training\n: a bool, training or validation\n\n\ndrop_p\n: probability of droping unit\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the dropout operation.\n\n\n\n\nRepeat op\n\n\ntefla.core.layers.repeat\n  (x,  repetitions,  layer,  num_outputs=None,  name='Repeat',  outputs_collections=None,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nx\n: a \nTensor\n.\n\n\nrepetitions\n: a int, number of times to apply the same operation\n\n\nlayer\n: the layer function with arguments to repeat\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the repetition operation.\n\n\n\n\nMerge op\n\n\ntefla.core.layers.merge\n  (tensors_list,  mode,  axis=1,  name='merge',  outputs_collections=None,  **kwargs)\n\n\nArgs\n\n\n\n\n\ntensor_list\n: A list \nTensors\n to merge\n\n\nmode\n: str, available modes are\n['concat', 'elemwise_sum', 'elemwise_mul', 'sum','mean', 'prod', 'max', 'min', 'and', 'or']\n\n\nname\n: a optional scope/name of the layer\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the results of the repetition operation.\n\n\n\n\nBuilds a stack of layers by applying layer repeatedly using stack_args\n\n\ntefla.core.layers.stack\n  (inputs,  layer,  stack_args,  is_training,  reuse,  outputs_collections=None,  **kwargs)\n\n\nstack\n allows you to repeatedly apply the same operation with different\narguments \nstack_args[i]\n. For each application of the layer, \nstack\n creates\na new scope appended with an increasing number. For example:\n\n\ny = stack(x, fully_connected, [32, 64, 128], scope='fc')\n   # It is equivalent to:\n   x = fully_connected(x, 32, scope='fc/fc_1')\n   x = fully_connected(x, 64, scope='fc/fc_2')\n   y = fully_connected(x, 128, scope='fc/fc_3')\n\n\n\n\nIf the \nscope\n argument is not given in \nkwargs\n, it is set to\n\nlayer.__name__\n, or \nlayer.func.__name__\n (for \nfunctools.partial\n\nobjects). If neither \n__name__\n nor \nfunc.__name__\n is available, the\nlayers are called with \nscope='stack'\n.\n\n\nArgs\n\n\n\n\n\ninputs\n: A \nTensor\n suitable for layer.\n\n\nlayer\n: A layer with arguments \n(inputs, *args, **kwargs)\n\n\nstack_args\n: A list/tuple of parameters for each call of layer.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\n**kwargs: Extra kwargs for the layer.\n\n\n\n\nReturns\n\n\n\na \nTensor\n result of applying the stacked layers.\n\n\n\n\nNormalizes the given input across the specified dimension to unit length\n\n\ntefla.core.layers.unit_norm\n  (inputs,  dim,  epsilon=1e-07,  scope=None)\n\nNote that the rank of \ninput\n must be known.\n\n\nArgs\n\n\n\n\n\ninputs\n: A \nTensor\n of arbitrary size.\n\n\ndim\n: The dimension along which the input is normalized.\n\n\nepsilon\n: A small value to add to the inputs to avoid dividing by zero.\n\n\nscope\n: Optional scope for variable_scope.\n\n\n\n\nReturns\n\n\n\nThe normalized \nTensor\n.\n\n\n\n\nConcates two features maps\n\n\ntefla.core.layers.crop_and_concat\n  (inputs1,  inputs2,  name='crop_concat')\n\n  concates different sizes feature maps cropping the larger map\n  concatenation across output channels\n\n\nArgs\n\n\n\n\n\ninputs1\n: A \nTensor\n\n\ninputs2\n: A \nTensor\n\n\n\n\nReturns\n\n\n\nconcated output tensor", 
            "title": "Layers"
        }, 
        {
            "location": "/core/layers/#define-input-layer", 
            "text": "tefla.core.layers.input   (shape,  name='inputs',  outputs_collections=None,  **unused)", 
            "title": "Define input layer"
        }, 
        {
            "location": "/core/layers/#add-item-to-colelction", 
            "text": "tefla.core.layers.register_to_collections   (inputs,  name=None,  outputs_collections=None,  **unused)", 
            "title": "Add item to colelction"
        }, 
        {
            "location": "/core/layers/#adds-a-fully-connected-layer", 
            "text": "tefla.core.layers.fully_connected   (x,  n_output,  is_training,  reuse,  trainable=True,  w_init= ,  b_init=0.0,  w_regularizer= ,  w_normalized=False,  name='fc',  batch_norm=None,  batch_norm_args=None,  activation=None,  params=None,  outputs_collections=None,  use_bias=True)  fully_connected  creates a variable called  weights , representing a fully\nconnected weight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank greater than 2, then  x  is flattened\nprior to the initial matrix multiply by  weights .", 
            "title": "Adds a fully connected layer"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-convolutional-layer", 
            "text": "tefla.core.layers.conv2d   (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  convolutional layer  creates a variable called  weights , representing a conv\nweight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-dilated-convolutional-layer", 
            "text": "tefla.core.layers.dilated_conv2d   (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  dilation=1,  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='dilated_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  also known as convolution with holes or atrous convolution.\nIf the rate parameter is equal to one, it performs regular 2-D convolution.\nIf the rate parameter\nis greater than one, it performs convolution with holes, sampling the input\nvalues every rate pixels in the height and width dimensions. convolutional layer  creates a variable called  weights , representing a conv\nweight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D dilated convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-seperable-convolutional-layer", 
            "text": "tefla.core.layers.separable_conv2d   (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  depth_multiplier=1,  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='separable_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  Performs a depthwise convolution that acts separately on channels followed by\na pointwise convolution that mixes channels. Note that this is separability between\ndimensions [1, 2] and 3, not spatial separability between dimensions 1 and 2. convolutional layer  creates two variable called  depthwise_W  and  pointwise_W , depthwise_W  is multiplied by  x  to produce depthwise conolution, which is multiplied by\nthe  pointwise_W  to produce a output  Tensor \nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D seperable convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-sdepthwise-convolutional-layer", 
            "text": "tefla.core.layers.depthwise_conv2d   (x,  depth_multiplier,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='depthwise_conv2d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter\ntensor of shape [filter_height, filter_width, in_channels, channel_multiplier] containing\nin_channels convolutional filters of depth 1, depthwise_conv2d applies a different filter\nto each input channel (expanding from 1 channel to channel_multiplier channels for each),\nthen concatenates the results together. The output has in_channels * channel_multiplier channels.\nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D sdepthwise convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-3d-convolutional-layer", 
            "text": "tefla.core.layers.conv3d   (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3,  3),  stride=  (1,  1,  1),  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='conv3d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  convolutional layer  creates a variable called  weights , representing a conv\nweight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 5", 
            "title": "Adds a 3D convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-upsampling-or-deconvolutional-layer", 
            "text": "tefla.core.layers.upsample2d   (input_,  output_shape,  is_training,  reuse,  trainable=True,  filter_size=  (5,  5),  stride=  (2,  2),  w_init= ,  b_init=0.0,  w_regularizer= ,  batch_norm=None,  batch_norm_args=None,  activation=None,  name='deconv2d',  use_bias=True,  with_w=False,  outputs_collections=None,  **unused)  his operation is sometimes called \"deconvolution\" after Deconvolutional Networks,\nbut is actually the transpose (gradient) of conv2d rather than an actual deconvolution.\nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D upsampling or deconvolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-3d-upsampling-or-deconvolutional-layer", 
            "text": "tefla.core.layers.upsample3d   (input_,  output_shape,  is_training,  reuse,  trainable=True,  filter_size=  (5,  5,  5),  stride=  (2,  2,  2),  w_init= ,  b_init=0.0,  w_regularizer= ,  batch_norm=None,  batch_norm_args=None,  activation=None,  name='deconv3d',  use_bias=True,  with_w=False,  outputs_collections=None,  **unused)  his operation is sometimes called \"deconvolution\" after Deconvolutional Networks,\nbut is actually the transpose (gradient) of conv2d rather than an actual deconvolution.\nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 5", 
            "title": "Adds a 3D upsampling or deconvolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-1d-convolutional-layer", 
            "text": "tefla.core.layers.conv1d   (x,  n_output_channels,  is_training,  reuse,  trainable=True,  filter_size=3,  stride=1,  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  untie_biases=False,  name='conv1d',  batch_norm=None,  batch_norm_args=None,  activation=None,  use_bias=True,  outputs_collections=None)  convolutional layer  creates a variable called  weights , representing a conv\nweight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 1D convolutional layer"
        }, 
        {
            "location": "/core/layers/#max-pooling-1d", 
            "text": "tefla.core.layers.max_pool_1d   (x,  filter_size=3,  stride=2,  padding='SAME',  name='maxpool1d',  outputs_collections=None,  **unused)", 
            "title": "Max Pooling 1D"
        }, 
        {
            "location": "/core/layers/#avg-pooling-1d", 
            "text": "tefla.core.layers.avg_pool_1d   (x,  filter_size=3,  stride=2,  padding='SAME',  name='avgpool1d',  outputs_collections=None,  **unused)", 
            "title": "Avg Pooling 1D"
        }, 
        {
            "location": "/core/layers/#adds-a-2d-highway-convolutional-layer", 
            "text": "tefla.core.layers.highway_conv2d   (x,  n_output,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  stride=  (1,  1),  padding='SAME',  w_init= ,  b_init=0.0,  w_regularizer= ,  name='highway_conv2d',  batch_norm=None,  batch_norm_args=None,  activation= ,  use_bias=True,  outputs_collections=None)  https://arxiv.org/abs/1505.00387\nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank 4", 
            "title": "Adds a 2D highway convolutional layer"
        }, 
        {
            "location": "/core/layers/#adds-a-fully-connected-highway-layer", 
            "text": "tefla.core.layers.highway_fc2d   (x,  n_output,  is_training,  reuse,  trainable=True,  filter_size=  (3,  3),  w_init= ,  b_init=0.0,  w_regularizer= ,  name='highway_fc2d',  activation=None,  use_bias=True,  outputs_collections=None)  https://arxiv.org/abs/1505.00387\nIf a  batch_norm  is provided (such as batch_norm ), it is then applied. Otherwise, if  batch_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank greater than 2, then  x  is flattened\nprior to the initial matrix multiply by  weights .", 
            "title": "Adds a fully connected highway layer"
        }, 
        {
            "location": "/core/layers/#max-pooling-layer", 
            "text": "tefla.core.layers.max_pool   (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name='pool',  outputs_collections=None,  **unused)", 
            "title": "Max pooling layer"
        }, 
        {
            "location": "/core/layers/#max-pooling-layer_1", 
            "text": "tefla.core.layers.max_pool_3d   (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name='pool',  outputs_collections=None,  **unused)", 
            "title": "Max pooling layer"
        }, 
        {
            "location": "/core/layers/#fractional-pooling-layer", 
            "text": "tefla.core.layers.fractional_pool   (x,  pooling_ratio=[1.0,  1.44,  1.73,  1.0],  pseudo_random=None,  determinastic=None,  overlapping=None,  name='fractional_pool',  seed=None,  seed2=None,  type='avg',  outputs_collections=None,  **unused)", 
            "title": "Fractional pooling layer"
        }, 
        {
            "location": "/core/layers/#rms-pooling-layer", 
            "text": "tefla.core.layers.rms_pool_2d   (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name='pool',  epsilon=1e-12,  outputs_collections=None,  **unused)", 
            "title": "RMS pooling layer"
        }, 
        {
            "location": "/core/layers/#rms-pooling-layer_1", 
            "text": "tefla.core.layers.rms_pool_3d   (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name='pool',  epsilon=1e-12,  outputs_collections=None,  **unused)", 
            "title": "RMS pooling layer"
        }, 
        {
            "location": "/core/layers/#avg-pooling-layer", 
            "text": "tefla.core.layers.avg_pool_3d   (x,  filter_size=  (3,  3,  3),  stride=  (2,  2,  2),  padding='SAME',  name=None,  outputs_collections=None,  **unused)", 
            "title": "Avg pooling layer"
        }, 
        {
            "location": "/core/layers/#avg-pooling-layer_1", 
            "text": "tefla.core.layers.avg_pool_2d   (x,  filter_size=  (3,  3),  stride=  (2,  2),  padding='SAME',  name=None,  outputs_collections=None,  **unused)", 
            "title": "Avg pooling layer"
        }, 
        {
            "location": "/core/layers/#gloabl-pooling-layer", 
            "text": "tefla.core.layers.global_avg_pool   (x,  name='global_avg_pool',  outputs_collections=None,  **unused)", 
            "title": "Gloabl pooling layer"
        }, 
        {
            "location": "/core/layers/#gloabl-max-pooling-layer", 
            "text": "tefla.core.layers.global_max_pool   (x,  name='global_max_pool',  outputs_collections=None,  **unused)", 
            "title": "Gloabl max pooling layer"
        }, 
        {
            "location": "/core/layers/#feature-max-pooling-layer", 
            "text": "tefla.core.layers.feature_max_pool_1d   (x,  stride=2,  name='feature_max_pool_1d',  outputs_collections=None,  **unused)", 
            "title": "Feature max pooling layer"
        }, 
        {
            "location": "/core/layers/#feature-max-pooling-layer_1", 
            "text": "tefla.core.layers.feature_max_pool_2d   (x,  stride=2,  name='feature_max_pool_2d',  outputs_collections=None,  **unused)", 
            "title": "Feature max pooling layer"
        }, 
        {
            "location": "/core/layers/#adds-a-batch-normalization-layer-from-httparxivorgabs150203167", 
            "text": "tefla.core.layers.batch_norm_tf   (x,  name='bn',  scale=False,  updates_collections=None,  **kwargs) \n\"Batch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\", Sergey Ioffe, Christian Szegedy\nCan be used as a normalizer function for conv2d and fully_connected.\nNote: When is_training is True the moving_mean and moving_variance need to be\nupdated, by default the update_ops are placed in  tf.GraphKeys.UPDATE_OPS  so\nthey need to be added as a dependency to the  train_op , example: update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  if update_ops:  updates = tf.group(*update_ops)  total_loss = control_flow_ops.with_dependencies([updates], total_loss) \nOne can set updates_collections=None to force the updates in place, but that\ncan have speed penalty, specially in distributed settings.", 
            "title": "Adds a Batch Normalization layer from http://arxiv.org/abs/1502.03167"
        }, 
        {
            "location": "/core/layers/#adds-a-batch-normalization-layer-from-httparxivorgabs150203167_1", 
            "text": "tefla.core.layers.batch_norm_lasagne   (x,  is_training,  reuse,  trainable=True,  decay=0.9,  epsilon=0.0001,  name='bn',  updates_collections='update_ops',  outputs_collections=None) \nInstead of storing and updating moving variance, this layer store and\nupdate moving inverse standard deviation\n\"Batch Normalization: Accelerating Deep Network Training by Reducin Internal Covariate Shift\"\nSergey Ioffe, Christian Szegedy\nCan be used as a normalizer function for conv2d and fully_connected.\nNote: When is_training is True the moving_mean and moving_variance need to be\nupdated, by default the update_ops are placed in  tf.GraphKeys.UPDATE_OPS  so\nthey need to be added as a dependency to the  train_op , example: update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  if update_ops:  updates = tf.group(*update_ops)  total_loss = control_flow_ops.with_dependencies([updates], total_loss) \nOne can set updates_collections=None to force the updates in place, but that\ncan have speed penalty, specially in distributed settings.", 
            "title": "Adds a Batch Normalization layer from http://arxiv.org/abs/1502.03167"
        }, 
        {
            "location": "/core/layers/#prametric-rectifier-linear-layer", 
            "text": "tefla.core.layers.prelu   (x,  reuse,  alpha_init=0.2,  trainable=True,  name='prelu',  outputs_collections=None)", 
            "title": "Prametric rectifier linear layer"
        }, 
        {
            "location": "/core/layers/#computes-relu", 
            "text": "tefla.core.layers.relu   (x,  name='relu',  outputs_collections=None,  **unused)", 
            "title": "Computes relu"
        }, 
        {
            "location": "/core/layers/#rectifier-linear-relu6-layer", 
            "text": "tefla.core.layers.relu6   (x,  name='relu6',  outputs_collections=None,  **unused)", 
            "title": "Rectifier linear relu6 layer"
        }, 
        {
            "location": "/core/layers/#softplus-layer", 
            "text": "tefla.core.layers.softplus   (x,  name='softplus',  outputs_collections=None,  **unused) \nComputes softplus: log(exp(x) + 1).", 
            "title": "Softplus layer"
        }, 
        {
            "location": "/core/layers/#softsign-layer", 
            "text": "tefla.core.layers.softsign   (x,  name='softsign',  outputs_collections=None,  **unused) \nComputes softsign: x / (abs(x) + 1).", 
            "title": "Softsign layer"
        }, 
        {
            "location": "/core/layers/#computes-concatenated-relu", 
            "text": "tefla.core.layers.crelu   (x,  name='crelu',  outputs_collections=None,  **unused) \nConcatenates a ReLU which selects only the positive part of the activation with\na ReLU which selects only the negative part of the activation. Note that\nat as a result this non-linearity doubles the depth of the activations.\nSource: https://arxiv.org/abs/1603.05201", 
            "title": "Computes Concatenated ReLU"
        }, 
        {
            "location": "/core/layers/#computes-exponential-linear-expfeatures-1-if-0-features-otherwise", 
            "text": "tefla.core.layers.elu   (x,  name='elu',  outputs_collections=None,  **unused) \nSee \"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\"", 
            "title": "Computes exponential linear: exp(features) - 1 if &lt; 0, features otherwise"
        }, 
        {
            "location": "/core/layers/#like-concatenated-relu-httparxivorgabs160305201-but-then-with-elu", 
            "text": "tefla.core.layers.concat_elu   (x,  name='concat_elu',  outputs_collections=None,  **unused)", 
            "title": "like concatenated ReLU (http://arxiv.org/abs/1603.05201), but then with ELU"
        }, 
        {
            "location": "/core/layers/#computes-leaky-relu", 
            "text": "tefla.core.layers.leaky_relu   (x,  alpha=0.01,  name='leaky_relu',  outputs_collections=None,  **unused)", 
            "title": "Computes leaky relu"
        }, 
        {
            "location": "/core/layers/#computes-reaky-relu-lasagne-style", 
            "text": "tefla.core.layers.lrelu   (x,  leak=0.2,  name='lrelu',  outputs_collections=None,  **unused)", 
            "title": "Computes reaky relu lasagne style"
        }, 
        {
            "location": "/core/layers/#computes-maxout-activation", 
            "text": "tefla.core.layers.maxout   (x,  k=2,  name='maxout',  outputs_collections=None,  **unused)", 
            "title": "Computes maxout activation"
        }, 
        {
            "location": "/core/layers/#computes-maxout-activation_1", 
            "text": "tefla.core.layers.offset_maxout   (x,  k=2,  name='maxout',  outputs_collections=None,  **unused)", 
            "title": "Computes maxout activation"
        }, 
        {
            "location": "/core/layers/#computes-softmax-activation", 
            "text": "tefla.core.layers.softmax   (x,  name='softmax',  outputs_collections=None,  **unused)", 
            "title": "Computes softmax activation"
        }, 
        {
            "location": "/core/layers/#computes-selu", 
            "text": "tefla.core.layers.selu   (x,  alpha=None,  scale=None,  name='selu',  outputs_collections=None,  **unused)", 
            "title": "Computes selu"
        }, 
        {
            "location": "/core/layers/#dropout-layer-for-self-normalizing-networks", 
            "text": "tefla.core.layers.dropout_selu   (x,  is_training,  drop_p=0.2,  alpha=-1.7580993408473766,  fixedPointMean=0.0,  fixedPointVar=1.0,  noise_shape=None,  seed=None,  name='dropout_selu',  outputs_collections=None,  **unused)", 
            "title": "Dropout layer for self normalizing networks"
        }, 
        {
            "location": "/core/layers/#computes-gumbel-softmax", 
            "text": "tefla.core.layers.gumbel_softmax   (logits,  temperature,  hard=False) \nSample from the Gumbel-Softmax distribution and optionally discretize.\nhttp://blog.evjang.com/2016/11/tutorial-categorical-variational.html\nhttps://arxiv.org/abs/1611.01144", 
            "title": "Computes Gumbel Softmax"
        }, 
        {
            "location": "/core/layers/#computes-pixel-wise-softmax-activation", 
            "text": "tefla.core.layers.pixel_wise_softmax   (inputs)", 
            "title": "Computes pixel wise softmax activation"
        }, 
        {
            "location": "/core/layers/#dropout-layer", 
            "text": "tefla.core.layers.dropout   (x,  is_training,  drop_p=0.5,  seed=None,  name='dropout',  outputs_collections=None,  **unused)", 
            "title": "Dropout layer"
        }, 
        {
            "location": "/core/layers/#repeat-op", 
            "text": "tefla.core.layers.repeat   (x,  repetitions,  layer,  num_outputs=None,  name='Repeat',  outputs_collections=None,   args,   *kwargs)", 
            "title": "Repeat op"
        }, 
        {
            "location": "/core/layers/#merge-op", 
            "text": "tefla.core.layers.merge   (tensors_list,  mode,  axis=1,  name='merge',  outputs_collections=None,  **kwargs)", 
            "title": "Merge op"
        }, 
        {
            "location": "/core/layers/#builds-a-stack-of-layers-by-applying-layer-repeatedly-using-stack_args", 
            "text": "tefla.core.layers.stack   (inputs,  layer,  stack_args,  is_training,  reuse,  outputs_collections=None,  **kwargs)  stack  allows you to repeatedly apply the same operation with different\narguments  stack_args[i] . For each application of the layer,  stack  creates\na new scope appended with an increasing number. For example:  y = stack(x, fully_connected, [32, 64, 128], scope='fc')\n   # It is equivalent to:\n   x = fully_connected(x, 32, scope='fc/fc_1')\n   x = fully_connected(x, 64, scope='fc/fc_2')\n   y = fully_connected(x, 128, scope='fc/fc_3')  If the  scope  argument is not given in  kwargs , it is set to layer.__name__ , or  layer.func.__name__  (for  functools.partial \nobjects). If neither  __name__  nor  func.__name__  is available, the\nlayers are called with  scope='stack' .", 
            "title": "Builds a stack of layers by applying layer repeatedly using stack_args"
        }, 
        {
            "location": "/core/layers/#normalizes-the-given-input-across-the-specified-dimension-to-unit-length", 
            "text": "tefla.core.layers.unit_norm   (inputs,  dim,  epsilon=1e-07,  scope=None) \nNote that the rank of  input  must be known.", 
            "title": "Normalizes the given input across the specified dimension to unit length"
        }, 
        {
            "location": "/core/layers/#concates-two-features-maps", 
            "text": "tefla.core.layers.crop_and_concat   (inputs1,  inputs2,  name='crop_concat') \n  concates different sizes feature maps cropping the larger map\n  concatenation across output channels", 
            "title": "Concates two features maps"
        }, 
        {
            "location": "/core/rnn_cell/", 
            "text": "The most basic RNN cell\n\n\ntefla.core.rnn_cell.BasicRNNCell\n  (num_units,  reuse,  trainable=True,  w_init=\n,  use_bias=False,  input_size=None,  activation=\n,  layer_norm=None,  layer_norm_args=None)\n\n\nArgs\n\n\n\n\n\nnum_units\n: int, The number of units in the LSTM cell.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\ninput_size\n: Deprecated and unused.\n\n\nactivation\n: Activation function of the states.\n\n\nlayer_norm\n: If \nTrue\n, layer normalization will be applied.\n\n\nlayer_norm_args\n: optional dict, layer_norm arguments\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\n\n\nMethods\n\n\n\n \n\n\nadd_variable\n  (name,  shape,  dtype=None,  initializer=None,  regularizer=None,  trainable=True)\n\n\nArguments:\n  name: variable name.\n  shape: variable shape.\n  dtype: The type of the variable. Defaults to \nself.dtype\n.\n  initializer: initializer instance (callable).\n  regularizer: regularizer instance (callable).\n  trainable: whether the variable should be part of the layer's\n\"trainable_variables\" (e.g. variables, biases)\nor \"non_trainable_variables\" (e.g. BatchNorm mean, stddev).\n\n\nReturns\n\n\n\nThe created variable.\n\n\n \n\n\napply\n  (inputs,  \nargs,  \n*kwargs)\n\n\nThis simply wraps \nself.__call__\n.\n\n\nArguments:\n  inputs: Input tensor(s).\n  \nargs: additional positional arguments to be passed to \nself.call\n.\n  \n*kwargs: additional keyword arguments to be passed to \nself.call\n.\n\n\nReturns\n\n\n\nOutput tensor(s).\n\n\n \n\n\ncall\n  (inputs,  **kwargs)\n\n\nArguments:\n  inputs: input tensor(s).\n **kwargs: additional keyword arguments.\n\n\nReturns\n\n\n\nOutput tensor(s).\n\n\n \n\n\nget_losses_for\n  (inputs)\n\n\nArguments:\n  inputs: Input tensor or list/tuple of input tensors.\nMust match the \ninputs\n argument passed to the \n__call__\n\nmethod at the time the losses were created.\nIf you pass \ninputs=None\n, unconditional losses are returned,\nsuch as weight regularization losses.\n\n\nReturns\n\n\n\nList of loss tensors of the layer that depend on \ninputs\n.\n\n\n \n\n\nget_updates_for\n  (inputs)\n\n\nArguments:\n  inputs: Input tensor or list/tuple of input tensors.\nMust match the \ninputs\n argument passed to the \n__call__\n method\nat the time the updates were created.\nIf you pass \ninputs=None\n, unconditional updates are returned.\n\n\nReturns\n\n\n\nList of update ops of the layer that depend on \ninputs\n.\n\n\n \n\n\nzero_state\n  (batch_size,  dtype)\n\n\nArgs\n\n\n\nbatch_size: int, float, or unit Tensor representing the batch size.\n  dtype: the data type to use for the state.\n\n\nReturns\n\n\n\nIf \nstate_size\n is an int or TensorShape, then the return value is a\n  \nN-D\n tensor of shape \n[batch_size x state_size]\n filled with zeros.\n\n\n\n\nLSTM unit\n\n\ntefla.core.rnn_cell.LSTMCell\n  (num_units,  reuse,  trainable=True,  w_init=\n,  forget_bias=1.0,  use_bias=False,  input_size=None,  activation=\n,  inner_activation=\n,  keep_prob=1.0,  dropout_seed=None,  cell_clip=None,  layer_norm=None,  layer_norm_args=None)\n\n\nThis class adds layer normalization and recurrent dropout to a\nbasic LSTM unit. Layer normalization implementation is based on:\nhttps://arxiv.org/abs/1607.06450.\n\"Layer Normalization\" Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton\nand is applied before the internal nonlinearities.\nRecurrent dropout is base on:\nhttps://arxiv.org/abs/1603.05118\n\"Recurrent Dropout without Memory Loss\"\nStanislau Semeniuta, Aliaksei Severyn, Erhardt Barth.\n\n\nArgs\n\n\n\n\n\nnum_units\n: int, The number of units in the LSTM cell.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nforget_bias\n: float, The bias added to forget gates (see above).\n\n\ninput_size\n: Deprecated and unused.\n\n\nactivation\n: Activation function of the states.\n\n\ninner_activation\n: Activation function of the inner states.\n\n\nlayer_norm\n: If \nTrue\n, layer normalization will be applied.\n\n\nlayer_norm_args\n: optional dict, layer_norm arguments\n\n\ncell_clip\n: (optional) A float value, if provided the cell state is clipped\nby this value prior to the cell output activation.\n\n\nkeep_prob\n: unit Tensor or float between 0 and 1 representing the\nrecurrent dropout probability value. If float and 1.0, no dropout will\nbe applied.\n\n\ndropout_seed\n: (optional) integer, the randomness seed.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\n\n\n\n\nBasic attention cell\n\n\ntefla.core.rnn_cell.AttentionCell\n  (cell,  attn_length,  reuse,  w_init=\n,  use_bias=False,  trainable=True,  attn_size=None,  attn_vec_size=None,  input_size=None,  layer_norm=None,  layer_norm_args=None)\n\n\nImplementation based on https://arxiv.org/abs/1409.0473.\nCreate a cell with attention.\n\n\nArgs\n\n\n\n\n\ncell\n: an RNNCell, an attention is added to it.\ne.g.: a LSTMCell\n\n\nattn_length\n: integer, the size of an attention window.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nattn_size\n: integer, the size of an attention vector. Equal to\ncell.output_size by default.\n\n\nattn_vec_size\n: integer, the number of convolutional features calculated\non attention state and a size of the hidden layer built from\nbase cell state. Equal attn_size to by default.\n\n\ninput_size\n: integer, the size of a hidden linear layer,\n\n\nlayer_norm\n: If \nTrue\n, layer normalization will be applied.\n\n\nlayer_norm_args\n: optional dict, layer_norm arguments\nbuilt from inputs and attention. Derived from the input tensor by default.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\n\n\n\n\nGated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078)\n\n\ntefla.core.rnn_cell.GRUCell\n  (num_units,  reuse,  w_init=\n,  use_bias=False,  trainable=True,  input_size=None,  activation=\n,  inner_activation=\n,  b_init=1.0,  layer_norm=None,  layer_norm_args=None)\n\n\nArgs\n\n\n\n\n\nnum_units\n: int, The number of units in the LSTM cell.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\ninput_size\n: Deprecated and unused.\n\n\nactivation\n: Activation function of the states.\n\n\ninner_activation\n: Activation function of the inner states.\n\n\nlayer_norm\n: If \nTrue\n, layer normalization will be applied.\n\n\nlayer_norm_args\n: optional dict, layer_norm arguments\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\n\n\n\n\nRNN cell composed sequentially of multiple simple cells\n\n\ntefla.core.rnn_cell.MultiRNNCell\n  (cells,  state_is_tuple=True)\n\n\nCreate a RNN cell composed sequentially of a number of RNNCells.\n\nArgs\n\n\n\n\ncells\n: list of RNNCells that will be composed in this order.\n\n\n\n\n\n\nOperator adding dropout to inputs and outputs of the given cell\n\n\ntefla.core.rnn_cell.DropoutWrapper\n  (cell,  is_training,  input_keep_prob=1.0,  output_keep_prob=1.0,  seed=None)\n\n\nCreate a cell with added input and/or output dropout.\nDropout is never used on the state.\n\n\nArgs\n\n\n\n\n\ncell\n: an RNNCell, a projection to output_size is added to it.\n\n\nis_training\n: a bool, training if true else validation/testing\n\n\ninput_keep_prob\n: unit Tensor or float between 0 and 1, input keep\nprobability; if it is float and 1, no input dropout will be added.\n\n\noutput_keep_prob\n: unit Tensor or float between 0 and 1, output keep\nprobability; if it is float and 1, no output dropout will be added.\n\n\nseed\n: (optional) integer, the randomness seed.\n\n\n\n\n\n\nAdds a fully connected layer\n\n\ntefla.core.rnn_cell._linear\n  (x,  n_output,  reuse,  trainable=True,  w_init=\n,  b_init=0.0,  w_regularizer=\n,  name='fc',  layer_norm=None,  layer_norm_args=None,  activation=None,  outputs_collections=None,  use_bias=True)\n\n\nfully_connected\n creates a variable called \nweights\n, representing a fully\nconnected weight matrix, which is multiplied by the \nx\n to produce a\n\nTensor\n of hidden units. If a \nlayer_norm\n is provided (such as\n\nlayer_norm\n), it is then applied. Otherwise, if \nlayer_norm\n is\nNone and a \nb_init\n and \nuse_bias\n is provided then a \nbiases\n variable would be\ncreated and added the hidden units. Finally, if \nactivation\n is not \nNone\n,\nit is applied to the hidden units as well.\nNote: that if \nx\n have a rank greater than 2, then \nx\n is flattened\nprior to the initial matrix multiply by \nweights\n.\n\n\nArgs\n\n\n\n\n\nx\n: A \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, depth]\n, \n[None, None, None, channels]\n.\n\n\nn_output\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nlayer_norm\n: normalization function to use. If\n -\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nlayer_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\noutputs_collections\n: The collections to which the outputs are added.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 2-D \nTensor\n variable representing the result of the series of operations.\ne.g: 2-D \nTensor\n [batch, n_output].\n\n\n\n\nAdds a Layer Normalization layer from https://arxiv.org/abs/1607.06450\n\n\ntefla.core.rnn_cell.layer_norm\n  (x,  reuse,  center=True,  scale=True,  trainable=True,  epsilon=1e-12,  name='bn',  outputs_collections=None)\n\n\"Layer Normalization\" Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton\nCan be used as a normalizer function for conv2d and fully_connected.\n\n\nArgs\n\n\n\n\n\nx\n: a tensor with 2 or more dimensions, where the first dimension has\n\nbatch_size\n. The normalization is over all but the last dimension if\n\ndata_format\n is \nNHWC\n and the second dimension if \ndata_format\n is\n\nNCHW\n.\n\n\ncenter\n: If True, subtract \nbeta\n. If False, \nbeta\n is ignored.\n\n\nscale\n: If True, multiply by \ngamma\n. If False, \ngamma\n is\nnot used. When the next layer is linear (also e.g. \nnn.relu\n), this can be\ndisabled since the scaling can be done by the next layer.\n\n\nepsilon\n: small float added to variance to avoid dividing by zero.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\noutputs_collections\n: collections to add the outputs.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see \ntf.Variable\n).\n\n\nname\n: Optional scope/name for \nvariable_scope\n.\n\n\n\n\nReturns\n\n\n\nA \nTensor\n representing the output of the operation.\n\n\n\n\nLSTM\n\n\ntefla.core.rnn_cell.lstm\n  (inputs,  n_units,  reuse,  is_training,  activation=\n,  inner_activation=\n,  dropout=None,  use_bias=True,  w_init=\n,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=True,  trainable=True,  scope='lstm')\n\nLong Short Term Memory Recurrent Layer.\n\n\nArgs\n\n\n\n\n\ninputs\n: \nTensor\n. Inputs 3-D Tensor [samples, timesteps, input_dim].\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nis_training\n: \nbool\n, training if True\n\n\nactivation\n: \nfunction\n (returning a \nTensor\n).\n\n\ninner_activation\n: \nfunction\n (returning a \nTensor\n).\n\n\ndropout\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). The\ninput and output keep probability.\n\n\nuse_bias\n: \nbool\n. If True, a bias is used.\n\n\nw_init\n: \nfunction\n (returning a \nTensor\n). Weights initialization.\n\n\nforget_bias\n: \nfloat\n. Bias of the forget gate. Default: 1.0.\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_state\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state\n: \nTensor\n. An initial state for the RNN.  This must be\na tensor of appropriate type and shape [batch_size x cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share variables between layers. Note that scope will\noverride name.\n\n\n\n\nReturns\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor [samples, output dim].\n\n\n\n\nGRU\n\n\ntefla.core.rnn_cell.gru\n  (inputs,  n_units,  reuse,  is_training,  activation=\n,  inner_activation=\n,  dropout=None,  use_bias=True,  w_init=\n,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=True,  trainable=True,  scope='gru')\n\nGated Recurrent Layer.\n\n\nArgs\n\n\n\n\n\ninputs\n: \nTensor\n. Inputs 3-D Tensor [samples, timesteps, input_dim].\n\n\nn_units\n: \nint\n, number of units for this layer.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nis_training\n: \nbool\n, training if True\n\n\nactivation\n: \nfunction\n (returning a \nTensor\n).\n\n\ninner_activation\n: \nfunction\n (returning a \nTensor\n).\n\n\ndropout\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). The\ninput and output keep probability.\n\n\nuse_bias\n: \nbool\n. If True, a bias is used.\n\n\nw_init\n: \nfunction\n (returning a \nTensor\n). Weights initialization.\n\n\nforget_bias\n: \nfloat\n. Bias of the forget gate. Default: 1.0.\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_state\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state\n: \nTensor\n. An initial state for the RNN.  This must be\na tensor of appropriate type and shape [batch_size x cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share variables between layers. Note that scope will\noverride name.\n\n\n\n\nReturns\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor [samples, output dim].\n\n\n\n\nBidirectional RNN\n\n\ntefla.core.rnn_cell.bidirectional_rnn\n  (inputs,  rnncell_fw,  rnncell_bw,  reuse,  is_training,  dropout_fw=None,  dropout_bw=None,  return_seq=False,  return_states=False,  initial_state_fw=None,  initial_state_bw=None,  dynamic=False,  scope='BiRNN',  outputs_collections=None)\n\nBuild a bidirectional recurrent neural network, it requires 2 RNN Cells\nto process sequence in forward and backward order. Any RNN Cell can be\nused i.e. SimpleRNN, LSTM, GRU... with its own parameters. But the two\ncells number of units must match.\n\n\nArgs\n\n\n\n\n\ninputs\n: \nTensor\n. The 3D inputs Tensor [samples, timesteps, input_dim].\n\n\nrnncell_fw\n: \nRNNCell\n. The RNN Cell to use for foward computation.\n\n\nrnncell_bw\n: \nRNNCell\n. The RNN Cell to use for backward computation.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nis_training\n: \nbool\n, training if True\n\n\ndropout_fw\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). the\ninput and output keep probability.\n\n\ndropout_bw\n: \ntuple\n of \nfloat\n: (input_keep_prob, output_keep_prob). the\ninput and output keep probability.\n\n\nreturn_seq\n: \nbool\n. If True, returns the full sequence instead of\nlast sequence output only.\n\n\nreturn_states\n: \nbool\n. If True, returns a tuple with output and\nstates: (output, states).\n\n\ninitial_state_fw\n: \nTensor\n. An initial state for the forward RNN.\nThis must be a tensor of appropriate type and shape [batch_size\nx cell.state_size].\n\n\ninitial_state_bw\n: \nTensor\n. An initial state for the backward RNN.\nThis must be a tensor of appropriate type and shape [batch_size\nx cell.state_size].\n\n\ndynamic\n: \nbool\n. If True, dynamic computation is performed. It will not\ncompute RNN steps above the sequence length. Note that because TF\nrequires to feed sequences of same length, 0 is used as a mask.\nSo a sequence padded with 0 at the end must be provided. When\ncomputation is performed, it will stop when it meets a step with\na value of 0.\n\n\nscope\n: \nstr\n. Define this layer scope (optional). A scope can be\nused to share variables between layers. Note that scope will\noverride name.\n\n\n\n\nReturns\n\n\n\nif \nreturn_seq\n: 3-D Tensor [samples, timesteps, output dim].\nelse: 2-D Tensor Layer [samples, output dim].", 
            "title": "RNN"
        }, 
        {
            "location": "/core/rnn_cell/#the-most-basic-rnn-cell", 
            "text": "tefla.core.rnn_cell.BasicRNNCell   (num_units,  reuse,  trainable=True,  w_init= ,  use_bias=False,  input_size=None,  activation= ,  layer_norm=None,  layer_norm_args=None)", 
            "title": "The most basic RNN cell"
        }, 
        {
            "location": "/core/rnn_cell/#lstm-unit", 
            "text": "tefla.core.rnn_cell.LSTMCell   (num_units,  reuse,  trainable=True,  w_init= ,  forget_bias=1.0,  use_bias=False,  input_size=None,  activation= ,  inner_activation= ,  keep_prob=1.0,  dropout_seed=None,  cell_clip=None,  layer_norm=None,  layer_norm_args=None)  This class adds layer normalization and recurrent dropout to a\nbasic LSTM unit. Layer normalization implementation is based on:\nhttps://arxiv.org/abs/1607.06450.\n\"Layer Normalization\" Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton\nand is applied before the internal nonlinearities.\nRecurrent dropout is base on:\nhttps://arxiv.org/abs/1603.05118\n\"Recurrent Dropout without Memory Loss\"\nStanislau Semeniuta, Aliaksei Severyn, Erhardt Barth.", 
            "title": "LSTM unit"
        }, 
        {
            "location": "/core/rnn_cell/#basic-attention-cell", 
            "text": "tefla.core.rnn_cell.AttentionCell   (cell,  attn_length,  reuse,  w_init= ,  use_bias=False,  trainable=True,  attn_size=None,  attn_vec_size=None,  input_size=None,  layer_norm=None,  layer_norm_args=None)  Implementation based on https://arxiv.org/abs/1409.0473.\nCreate a cell with attention.", 
            "title": "Basic attention cell"
        }, 
        {
            "location": "/core/rnn_cell/#gated-recurrent-unit-cell-cf-httparxivorgabs14061078", 
            "text": "tefla.core.rnn_cell.GRUCell   (num_units,  reuse,  w_init= ,  use_bias=False,  trainable=True,  input_size=None,  activation= ,  inner_activation= ,  b_init=1.0,  layer_norm=None,  layer_norm_args=None)", 
            "title": "Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078)"
        }, 
        {
            "location": "/core/rnn_cell/#rnn-cell-composed-sequentially-of-multiple-simple-cells", 
            "text": "tefla.core.rnn_cell.MultiRNNCell   (cells,  state_is_tuple=True)  Create a RNN cell composed sequentially of a number of RNNCells.", 
            "title": "RNN cell composed sequentially of multiple simple cells"
        }, 
        {
            "location": "/core/rnn_cell/#operator-adding-dropout-to-inputs-and-outputs-of-the-given-cell", 
            "text": "tefla.core.rnn_cell.DropoutWrapper   (cell,  is_training,  input_keep_prob=1.0,  output_keep_prob=1.0,  seed=None)  Create a cell with added input and/or output dropout.\nDropout is never used on the state.", 
            "title": "Operator adding dropout to inputs and outputs of the given cell"
        }, 
        {
            "location": "/core/rnn_cell/#adds-a-fully-connected-layer", 
            "text": "tefla.core.rnn_cell._linear   (x,  n_output,  reuse,  trainable=True,  w_init= ,  b_init=0.0,  w_regularizer= ,  name='fc',  layer_norm=None,  layer_norm_args=None,  activation=None,  outputs_collections=None,  use_bias=True)  fully_connected  creates a variable called  weights , representing a fully\nconnected weight matrix, which is multiplied by the  x  to produce a Tensor  of hidden units. If a  layer_norm  is provided (such as layer_norm ), it is then applied. Otherwise, if  layer_norm  is\nNone and a  b_init  and  use_bias  is provided then a  biases  variable would be\ncreated and added the hidden units. Finally, if  activation  is not  None ,\nit is applied to the hidden units as well.\nNote: that if  x  have a rank greater than 2, then  x  is flattened\nprior to the initial matrix multiply by  weights .", 
            "title": "Adds a fully connected layer"
        }, 
        {
            "location": "/core/rnn_cell/#adds-a-layer-normalization-layer-from-httpsarxivorgabs160706450", 
            "text": "tefla.core.rnn_cell.layer_norm   (x,  reuse,  center=True,  scale=True,  trainable=True,  epsilon=1e-12,  name='bn',  outputs_collections=None) \n\"Layer Normalization\" Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton\nCan be used as a normalizer function for conv2d and fully_connected.", 
            "title": "Adds a Layer Normalization layer from https://arxiv.org/abs/1607.06450"
        }, 
        {
            "location": "/core/rnn_cell/#lstm", 
            "text": "tefla.core.rnn_cell.lstm   (inputs,  n_units,  reuse,  is_training,  activation= ,  inner_activation= ,  dropout=None,  use_bias=True,  w_init= ,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=True,  trainable=True,  scope='lstm') \nLong Short Term Memory Recurrent Layer.", 
            "title": "LSTM"
        }, 
        {
            "location": "/core/rnn_cell/#gru", 
            "text": "tefla.core.rnn_cell.gru   (inputs,  n_units,  reuse,  is_training,  activation= ,  inner_activation= ,  dropout=None,  use_bias=True,  w_init= ,  forget_bias=1.0,  return_seq=False,  return_state=False,  initial_state=None,  dynamic=True,  trainable=True,  scope='gru') \nGated Recurrent Layer.", 
            "title": "GRU"
        }, 
        {
            "location": "/core/rnn_cell/#bidirectional-rnn", 
            "text": "tefla.core.rnn_cell.bidirectional_rnn   (inputs,  rnncell_fw,  rnncell_bw,  reuse,  is_training,  dropout_fw=None,  dropout_bw=None,  return_seq=False,  return_states=False,  initial_state_fw=None,  initial_state_bw=None,  dynamic=False,  scope='BiRNN',  outputs_collections=None) \nBuild a bidirectional recurrent neural network, it requires 2 RNN Cells\nto process sequence in forward and backward order. Any RNN Cell can be\nused i.e. SimpleRNN, LSTM, GRU... with its own parameters. But the two\ncells number of units must match.", 
            "title": "Bidirectional RNN"
        }, 
        {
            "location": "/core/special_layers/", 
            "text": "Spatial Transformer Layer\n\n\ntefla.core.special_layers.spatialtransformer\n  (U,  theta,  batch_size=64,  downsample_factor=1.0,  num_transform=1,  name='SpatialTransformer',  **kwargs)\n\n\nImplements a spatial transformer layer as described in [1]\n.\nIt's based on lasagne implementation in [2]\n, modified by Mrinal Haloi\n\n\nArgs\n\n\n\n\n\nU\n: float\nThe output of a convolutional net should have the\nshape [batch_size, height, width, num_channels].\n\n\ntheta\n: float\nThe output of the localisation network should be [batch_size, num_transform, 6] or [batch_size, 6] if num_transform=1\n\npython`theta`` to : - identity = np.array([[1., 0., 0.], -  [0., 1., 0.]]) - identity = identity.flatten() - theta = tf.Variable(initial_value=identity)\n\n\ndownsample_factor\n: a float, determines output shape, downsample input shape by downsample_factor\n\n\n\n\nReturns\n\n\n\nspatial transformed output of the network\n\n\n\n\nSubsamples the input along the spatial dimensions\n\n\ntefla.core.special_layers.subsample\n  (inputs,  factor,  name=None)\n\n\nArgs\n\n\n\n\n\ninputs\n: A \nTensor\n of size [batch, height_in, width_in, channels].\n\n\nfactor\n: The subsampling factor.\n\n\nname\n: Optional variable_scope.\n\n\n\n\nReturns\n\n\n\noutput: A \nTensor\n of size [batch, height_out, width_out, channels] with the\ninput, either intact (if factor == 1) or subsampled (if factor \n 1).\n\n\n\n\nStrided 2-D convolution with 'SAME' padding\n\n\ntefla.core.special_layers.conv2d_same\n  (inputs,  num_outputs,  kernel_size,  stride,  rate=1,  name=None,  **kwargs)\n\n\nWhen stride \n 1, then we do explicit zero-padding, followed by conv2d with\n'VALID' padding.\n\n\nNote that\n\n\nnet = conv2d_same(inputs, num_outputs, 3, stride=stride)\n\n\nis equivalent to\n\n\nnet = conv2d(inputs, num_outputs, 3, stride=1, padding='SAME')\n   net = subsample(net, factor=stride)\n\n\nwhereas\n\n\nnet = conv2d(inputs, num_outputs, 3, stride=stride, padding='SAME')\n\n\nis different when the input's height or width is even, which is why we add the\ncurrent function. For more details, see ResnetUtilsTest.testConv2DSameEven().\n\n\nArgs\n\n\n\n\n\ninputs\n: A 4-D tensor of size [batch, height_in, width_in, channels].\n\n\nnum_outputs\n: An integer, the number of output filters.\n\n\nkernel_size\n: An int with the kernel_size of the filters.\n\n\nstride\n: An integer, the output stride.\n\n\nrate\n: An integer, rate for atrous convolution.\n\n\nname\n: name.\n\n\n\n\nReturns\n\n\n\noutput: A 4-D tensor of size [batch, height_out, width_out, channels] with\nthe convolution output.\n\n\n\n\nBottleneck residual unit variant with BN before convolutions\n\n\ntefla.core.special_layers.bottleneck_v1\n  (inputs,  depth,  depth_bottleneck,  stride,  rate=1,  name=None,  **kwargs)\n\n\nThis is the full preactivation residual unit variant proposed in [2]. See\nFig. 1(b) of [2] for its definition. Note that we use here the bottleneck\nvariant which has an extra bottleneck layer.\n\n\nWhen putting together two consecutive ResNet blocks that use this unit, one\nshould use stride = 2 in the last unit of the first block.\n\n\nArgs\n\n\n\n\n\ninputs\n: A tensor of size [batch, height, width, channels].\n\n\ndepth\n: The depth of the ResNet unit output.\n\n\ndepth_bottleneck\n: The depth of the bottleneck layers.\n\n\nstride\n: The ResNet unit's stride. Determines the amount of downsampling of\nthe units output compared to its input.\n\n\nrate\n: An integer, rate for atrous convolution.\n\n\noutputs_collections\n: Collection to add the ResNet unit output.\n\n\nname\n: Optional variable_scope.\n\n\n\n\nReturns\n\n\n\nThe ResNet unit's output.\n\n\n\n\nBottleneck residual unit variant with BN before convolutions\n\n\ntefla.core.special_layers.bottleneck_v2\n  (inputs,  depth,  depth_bottleneck,  stride,  rate=1,  name=None,  **kwargs)\n\n\nThis is the full preactivation residual unit variant proposed in [2]. See\nFig. 1(b) of [2] for its definition. Note that we use here the bottleneck\nvariant which has an extra bottleneck layer.\n\n\nWhen putting together two consecutive ResNet blocks that use this unit, one\nshould use stride = 2 in the last unit of the first block.\n\n\nArgs\n\n\n\n\n\ninputs\n: A tensor of size [batch, height, width, channels].\n\n\ndepth\n: The depth of the ResNet unit output.\n\n\ndepth_bottleneck\n: The depth of the bottleneck layers.\n\n\nstride\n: The ResNet unit's stride. Determines the amount of downsampling of\nthe units output compared to its input.\n\n\nrate\n: An integer, rate for atrous convolution.\n\n\noutputs_collections\n: Collection to add the ResNet unit output.\n\n\nname\n: Optional variable_scope.\n\n\n\n\nReturns\n\n\n\nThe ResNet unit's output.\n\n\n\n\nDenseCRF over unnormalised predictions\n\n\ntefla.core.special_layers.dense_crf\n  (probs,  img=None,  n_classes=21,  n_iters=10,  sxy_gaussian=  (1,  1),  compat_gaussian=4,  kernel_gaussian=\n,  normalisation_gaussian=\n,  sxy_bilateral=  (49,  49),  compat_bilateral=2,  srgb_bilateral=  (13,  13,  13),  kernel_bilateral=\n,  normalisation_bilateral=\n)\n\n   More details on the arguments at https://github.com/lucasb-eyer/pydensecrf.\n\n\nArgs\n\n\n\n\n\nprobs\n: class probabilities per pixel.\n\n\nimg\n: if given, the pairwise bilateral potential on raw RGB values will be computed.\n\n\nn_iters\n: number of iterations of MAP inference.\n\n\nsxy_gaussian\n: standard deviations for the location component\nof the colour-independent term.\n\n\ncompat_gaussian\n: label compatibilities for the colour-independent\nterm (can be a number, a 1D array, or a 2D array).\n\n\nkernel_gaussian\n: kernel precision matrix for the colour-independent\nterm (can take values CONST_KERNEL, DIAG_KERNEL, or FULL_KERNEL).\n\n\nnormalisation_gaussian\n: normalisation for the colour-independent term\n(possible values are NO_NORMALIZATION, NORMALIZE_BEFORE, NORMALIZE_AFTER, NORMALIZE_SYMMETRIC).\n\n\nsxy_bilateral\n: standard deviations for the location component of the colour-dependent term.\n\n\ncompat_bilateral\n: label compatibilities for the colour-dependent\nterm (can be a number, a 1D array, or a 2D array).\n\n\nsrgb_bilateral\n: standard deviations for the colour component\nof the colour-dependent term.\n\n\nkernel_bilateral\n: kernel precision matrix for the colour-dependent term\n(can take values CONST_KERNEL, DIAG_KERNEL, or FULL_KERNEL).\n\n\nnormalisation_bilateral\n: normalisation for the colour-dependent term\n(possible values are NO_NORMALIZATION, NORMALIZE_BEFORE, NORMALIZE_AFTER, NORMALIZE_SYMMETRIC).\n\n\n\n\nReturns\n\n\n\nRefined predictions after MAP inference.\n\n\n\n\nResNeXt Block\n\n\ntefla.core.special_layers.resnext_block\n  (inputs,  nb_blocks,  out_channels,  is_training,  reuse,  cardinality,  downsample=False,  downsample_strides=2,  activation=\n,  batch_norm=None,  batch_norm_args=None,  name='ResNeXtBlock',  **kwargs)\n\nresnext paper https://arxiv.org/pdf/1611.05431.pdf\n\n\nArgs\n\n\n\n\n\ninputs\n: \nTensor\n. Inputs 4-D Layer.\n\n\nnb_blocks\n: \nint\n. Number of layer blocks.\n\n\nout_channels\n: \nint\n. The number of convolutional filters of the\nlayers surrounding the bottleneck layer.\n\n\ncardinality\n: \nint\n. Number of aggregated residual transformations.\n\n\ndownsample\n: \nbool\n. If True, apply downsampling using\n'downsample_strides' for strides.\n\n\ndownsample_strides\n: \nint\n. The strides to use when downsampling.\n\n\nactivation\n: \nfunction\n (returning a \nTensor\n).\n\n\nbatch_norm\n: \nbool\n. If True, apply batch normalization.\n\n\nuse_ bias: \nbool\n. If True, a bias is used.\n\n\nw_init\n: \nfunction\n, Weights initialization.\n\n\nb_init\n: \ntf.Tensor\n. Bias initialization.\n\n\nw_regularizer\n: \nfunction\n. Add a regularizer to this\n\n\nweight_decay\n: \nfloat\n. Regularizer decay parameter. Default: 0.001.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\noverride name.\n\n\nname\n: A name for this layer (optional). Default: 'ResNeXtBlock'.\n\n\n\n\nReturns\n\n\n\n4-D Tensor [batch, new height, new width, out_channels].\n\n\n\n\nEmbedding\n\n\ntefla.core.special_layers.embedding\n  (inputs,  vocab_dim,  embedding_dim,  reuse,  validate_indices=False,  w_init=\n,  trainable=True,  normalize=False,  vocab_freqs=None,  name='Embedding')\n\nEmbedding layer for a sequence of integer ids or floats.\n\n\nArgs\n\n\n\n\n\ninputs\n: a 2-D \nTensor\n [samples, ids].\n\n\nvocab_dim\n: list of \nint\n. Vocabulary size (number of ids).\n\n\nembedding_dim\n: list of \nint\n. Embedding size.\n\n\nvalidate_indices\n: \nbool\n. Whether or not to validate gather indices.\n\n\nw_init\n:  Weights initialization.\n\n\ntrainable\n: \nbool\n. If True, weights will be trainable.\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nname\n: A name for this layer (optional). Default: 'Embedding'.\n\n\n\n\nReturns\n\n\n\n3-D Tensor [samples, embedded_ids, features].\n\n\n\n\nGated unit for language modelling\n\n\ntefla.core.special_layers.gated_layer\n  (inputs,  layer,  num_units,  is_training,  reuse,  name='gated_layer',  **kwargs)\n\n\nArgs\n\n\n\n\n\ninputs\n: a 3-D/4-D \nTensor\n, input [samples, timesteps, input_dim]\n\n\nlayer\n: a \nlayer\n, layer to pass the inputs\ne.g. \ntefla.core.layers\n\n\nnum_units\n: a \nint\n, number of units for each layer\n\n\nis_training\n: a \nboolean\n, Training if its true\n\n\nreuse\n: \nbool\n. If True and 'scope' is provided, this layer variables\nwill be reused (shared).\n\n\nname\n: A name for this layer (optional). Default: 'gated_layer'.\n\n\n\n\nReturns\n\n\n\na 3-D/4-D \nTensor\n, output of the gated unit\n\n\n\n\nReturns glimpses at the locations\n\n\ntefla.core.special_layers.glimpseSensor\n  (img,  normLoc,  minRadius=4,  depth=1,  sensorBandwidth=12)\n\n\nArgs\n\n\n\n\n\nimg\n: a 4-D \nTensor\n, [batch_size, width, height, channels]\n\n\nnormloc\n: a \nfloat\n, [0, 1] normalized location\n\n\nminRadius\n: a \nint\n, min radius for zooming\n\n\ndepth\n: a \nint\n, number of zooms\n\n\nsensorbandwidth\n: a \nint\n, output glimpse size, width/height\n\n\n\n\nReturns\n\n\n\na 5-D \ntensor\n of glimpses\n\n\n\n\nAdds a PVA block layer\n\n\ntefla.core.special_layers.pva_block_v1\n  (x,  num_units,  name='pva_block_v1',  **kwargs)\n\nconvolution followed by crelu and scaling\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nnum_units\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 4-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nAdds a PVA block v2 layer\n\n\ntefla.core.special_layers.pva_block_v2\n  (x,  num_units,  name='pva_block_v2',  **kwargs)\n\nfirst batch normalization followed by crelu and scaling, convolution is applied after scalling\n\n\nArgs\n\n\n\n\n\nx\n: A 4-D \nTensor\n of with at least rank 2 and value for the last dimension,\ni.e. \n[batch_size, in_height, in_width, depth]\n,\n\n\nis_training\n: Bool, training or testing\n\n\nnum_units\n: Integer or long, the number of output units in the layer.\n\n\nreuse\n: whether or not the layer and its variables should be reused. To be\nable to reuse the layer scope must be given.\n\n\nfilter_size\n: a int or list/tuple of 2 positive integers specifying the spatial\ndimensions of of the filters.\n\n\nstride\n: a int or tuple/list of 2 positive integers specifying the stride at which to\ncompute output.\n\n\npadding\n: one of \n\"VALID\"\n or \n\"SAME\"\n.\n\n\nactivation\n: activation function, set to None to skip it and maintain\na linear activation.\n\n\nbatch_norm\n: normalization function to use. If\n\nbatch_norm\n is \nTrue\n then google original implementation is used and\nif another function is provided then it is applied.\ndefault set to None for no normalizer function\n\n\nbatch_norm_args\n: normalization function parameters.\n\n\nw_init\n: An initializer for the weights.\n\n\nw_regularizer\n: Optional regularizer for the weights.\n\n\nuntie_biases\n: spatial dimensions wise baises\n\n\nb_init\n: An initializer for the biases. If None skip biases.\n\n\ntrainable\n: If \nTrue\n also add variables to the graph collection\n\nGraphKeys.TRAINABLE_VARIABLES\n (see tf.Variable).\n\n\nname\n: Optional name or scope for variable_scope/name_scope.\n\n\nuse_bias\n: Whether to add bias or not\n\n\n\n\nReturns\n\n\n\nThe 4-D \nTensor\n variable representing the result of the series of operations.\ne.g.: 4-D \nTensor\n [batch, new_height, new_width, n_output].\n\n\n\n\nPerforms a pooling operation that results in a fixed size:\n\n\ntefla.core.special_layers.max_pool_2d_nxn_regions\n  (inputs,  output_size,  mode='max')\n\noutput_size x output_size.\n\n\nUsed by spatial_pyramid_pool. Refer to appendix A in [1].\n\n\nArgs\n\n\n\n\n\ninputs\n: A 4D Tensor (B, H, W, C)\n\n\noutput_size\n: The output size of the pooling operation.\n\n\nmode\n: The pooling mode {max, avg}\n\n\n\n\nReturns\n\n\n\nA list of tensors, for each output bin.\nThe list contains output_size * output_size elements, where\neach elment is a Tensor (N, C).\n\n\n\n\nPerforms spatial pyramid pooling (SPP) over the input\n\n\ntefla.core.special_layers.spatial_pyramid_pool\n  (inputs,  dimensions=[2,  1],  mode='max',  implementation='kaiming')\n\nIt will turn a 2D input of arbitrary size into an output of fixed\ndimenson.\nHence, the convlutional part of a DNN can be connected to a dense part\nwith a fixed number of nodes even if the dimensions of the input\nimage are unknown.\n\n\nThe pooling is performed over :math:\nl\n pooling levels.\nEach pooling level :math:\ni\n will create :math:\nM_i\n output features.\n:math:\nM_i\n is given by :math:\nn_i * n_i\n, with :math:\nn_i\n as the number\nof pooling operations per dimension level :math:\ni\n.\n\n\nThe length of the parameter dimensions is the level of the spatial pyramid.\n\n\nArgs\n\n\n\n\n\ninputs\n: A 4D Tensor (B, H, W, C).\n\n\ndimensions\n: The list of :math:\nn_i\n's that define the output dimension\n\n\nof each pooling level :math:\ni\n. The length of dimensions is the level of\n\n\nthe spatial pyramid.\n\n\nmode\n: Pooling mode 'max' or 'avg'.\n\n\nimplementation\n: The implementation to use, either 'kaiming' or 'fast'.\n\n\nkamming is the original implementation from the paper, and supports variable\n\n\nsizes of input vectors, which fast does not support.\n\n\n\n\nReturns\n\n\n\nA fixed length vector representing the inputs.", 
            "title": "Special Layers"
        }, 
        {
            "location": "/core/special_layers/#spatial-transformer-layer", 
            "text": "tefla.core.special_layers.spatialtransformer   (U,  theta,  batch_size=64,  downsample_factor=1.0,  num_transform=1,  name='SpatialTransformer',  **kwargs)  Implements a spatial transformer layer as described in [1] .\nIt's based on lasagne implementation in [2] , modified by Mrinal Haloi", 
            "title": "Spatial Transformer Layer"
        }, 
        {
            "location": "/core/special_layers/#subsamples-the-input-along-the-spatial-dimensions", 
            "text": "tefla.core.special_layers.subsample   (inputs,  factor,  name=None)", 
            "title": "Subsamples the input along the spatial dimensions"
        }, 
        {
            "location": "/core/special_layers/#strided-2-d-convolution-with-same-padding", 
            "text": "tefla.core.special_layers.conv2d_same   (inputs,  num_outputs,  kernel_size,  stride,  rate=1,  name=None,  **kwargs)  When stride   1, then we do explicit zero-padding, followed by conv2d with\n'VALID' padding.  Note that  net = conv2d_same(inputs, num_outputs, 3, stride=stride)  is equivalent to  net = conv2d(inputs, num_outputs, 3, stride=1, padding='SAME')\n   net = subsample(net, factor=stride)  whereas  net = conv2d(inputs, num_outputs, 3, stride=stride, padding='SAME')  is different when the input's height or width is even, which is why we add the\ncurrent function. For more details, see ResnetUtilsTest.testConv2DSameEven().", 
            "title": "Strided 2-D convolution with 'SAME' padding"
        }, 
        {
            "location": "/core/special_layers/#bottleneck-residual-unit-variant-with-bn-before-convolutions", 
            "text": "tefla.core.special_layers.bottleneck_v1   (inputs,  depth,  depth_bottleneck,  stride,  rate=1,  name=None,  **kwargs)  This is the full preactivation residual unit variant proposed in [2]. See\nFig. 1(b) of [2] for its definition. Note that we use here the bottleneck\nvariant which has an extra bottleneck layer.  When putting together two consecutive ResNet blocks that use this unit, one\nshould use stride = 2 in the last unit of the first block.", 
            "title": "Bottleneck residual unit variant with BN before convolutions"
        }, 
        {
            "location": "/core/special_layers/#bottleneck-residual-unit-variant-with-bn-before-convolutions_1", 
            "text": "tefla.core.special_layers.bottleneck_v2   (inputs,  depth,  depth_bottleneck,  stride,  rate=1,  name=None,  **kwargs)  This is the full preactivation residual unit variant proposed in [2]. See\nFig. 1(b) of [2] for its definition. Note that we use here the bottleneck\nvariant which has an extra bottleneck layer.  When putting together two consecutive ResNet blocks that use this unit, one\nshould use stride = 2 in the last unit of the first block.", 
            "title": "Bottleneck residual unit variant with BN before convolutions"
        }, 
        {
            "location": "/core/special_layers/#densecrf-over-unnormalised-predictions", 
            "text": "tefla.core.special_layers.dense_crf   (probs,  img=None,  n_classes=21,  n_iters=10,  sxy_gaussian=  (1,  1),  compat_gaussian=4,  kernel_gaussian= ,  normalisation_gaussian= ,  sxy_bilateral=  (49,  49),  compat_bilateral=2,  srgb_bilateral=  (13,  13,  13),  kernel_bilateral= ,  normalisation_bilateral= ) \n   More details on the arguments at https://github.com/lucasb-eyer/pydensecrf.", 
            "title": "DenseCRF over unnormalised predictions"
        }, 
        {
            "location": "/core/special_layers/#resnext-block", 
            "text": "tefla.core.special_layers.resnext_block   (inputs,  nb_blocks,  out_channels,  is_training,  reuse,  cardinality,  downsample=False,  downsample_strides=2,  activation= ,  batch_norm=None,  batch_norm_args=None,  name='ResNeXtBlock',  **kwargs) \nresnext paper https://arxiv.org/pdf/1611.05431.pdf", 
            "title": "ResNeXt Block"
        }, 
        {
            "location": "/core/special_layers/#embedding", 
            "text": "tefla.core.special_layers.embedding   (inputs,  vocab_dim,  embedding_dim,  reuse,  validate_indices=False,  w_init= ,  trainable=True,  normalize=False,  vocab_freqs=None,  name='Embedding') \nEmbedding layer for a sequence of integer ids or floats.", 
            "title": "Embedding"
        }, 
        {
            "location": "/core/special_layers/#gated-unit-for-language-modelling", 
            "text": "tefla.core.special_layers.gated_layer   (inputs,  layer,  num_units,  is_training,  reuse,  name='gated_layer',  **kwargs)", 
            "title": "Gated unit for language modelling"
        }, 
        {
            "location": "/core/special_layers/#returns-glimpses-at-the-locations", 
            "text": "tefla.core.special_layers.glimpseSensor   (img,  normLoc,  minRadius=4,  depth=1,  sensorBandwidth=12)", 
            "title": "Returns glimpses at the locations"
        }, 
        {
            "location": "/core/special_layers/#adds-a-pva-block-layer", 
            "text": "tefla.core.special_layers.pva_block_v1   (x,  num_units,  name='pva_block_v1',  **kwargs) \nconvolution followed by crelu and scaling", 
            "title": "Adds a PVA block layer"
        }, 
        {
            "location": "/core/special_layers/#adds-a-pva-block-v2-layer", 
            "text": "tefla.core.special_layers.pva_block_v2   (x,  num_units,  name='pva_block_v2',  **kwargs) \nfirst batch normalization followed by crelu and scaling, convolution is applied after scalling", 
            "title": "Adds a PVA block v2 layer"
        }, 
        {
            "location": "/core/special_layers/#performs-a-pooling-operation-that-results-in-a-fixed-size", 
            "text": "tefla.core.special_layers.max_pool_2d_nxn_regions   (inputs,  output_size,  mode='max') \noutput_size x output_size.  Used by spatial_pyramid_pool. Refer to appendix A in [1].", 
            "title": "Performs a pooling operation that results in a fixed size:"
        }, 
        {
            "location": "/core/special_layers/#performs-spatial-pyramid-pooling-spp-over-the-input", 
            "text": "tefla.core.special_layers.spatial_pyramid_pool   (inputs,  dimensions=[2,  1],  mode='max',  implementation='kaiming') \nIt will turn a 2D input of arbitrary size into an output of fixed\ndimenson.\nHence, the convlutional part of a DNN can be connected to a dense part\nwith a fixed number of nodes even if the dimensions of the input\nimage are unknown.  The pooling is performed over :math: l  pooling levels.\nEach pooling level :math: i  will create :math: M_i  output features.\n:math: M_i  is given by :math: n_i * n_i , with :math: n_i  as the number\nof pooling operations per dimension level :math: i .  The length of the parameter dimensions is the level of the spatial pyramid.", 
            "title": "Performs spatial pyramid pooling (SPP) over the input"
        }, 
        {
            "location": "/core/layer_arg_ops/", 
            "text": "Creates all common parameters\n\n\ntefla.core.layer_arg_ops.common_layer_args\n  (is_training,  reuse,  **kwargs)\n\n\nArgs\n\n\n\n\n\nis_training\n: a bool, training or prediction\n\n\nresue\n: resue variables or initializes \n\n\n**kwargs: other  common arguments\n\n\n\n\n\n\nReturns end_points for training or validation\n\n\ntefla.core.layer_arg_ops.end_points\n  (is_training)\n\n\nArgs\n\n\n\n\n\nis_training\n: a bool, training or validation", 
            "title": "Layer Args"
        }, 
        {
            "location": "/core/layer_arg_ops/#creates-all-common-parameters", 
            "text": "tefla.core.layer_arg_ops.common_layer_args   (is_training,  reuse,  **kwargs)", 
            "title": "Creates all common parameters"
        }, 
        {
            "location": "/core/layer_arg_ops/#returns-end_points-for-training-or-validation", 
            "text": "tefla.core.layer_arg_ops.end_points   (is_training)", 
            "title": "Returns end_points for training or validation"
        }, 
        {
            "location": "/core/training/", 
            "text": "Supervised Trainer class\n\n\ntefla.core.training.SupervisedTrainer\n  (model,  cnf,  training_iterator=\n,  validation_iterator=\n,  start_epoch=1,  resume_lr=0.01,  classification=True,  clip_norm=True,  n_iters_per_epoch=1094,  num_classes=5,  gpu_memory_fraction=0.94,  is_summary=False,  loss_type='softmax_cross_entropy')\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition\n\n\ncnf\n: dict, training configs\n\n\ntraining_iterator\n: iterator to use for training data access, processing and augmentations\n\n\nvalidation_iterator\n: iterator to use for validation data access, processing and augmentations\n\n\nstart_epoch\n: int, training start epoch; for resuming training provide the last\n\n\nepoch number to resume training from, its a required parameter for training data balancing\n\n\nresume_lr\n: float, learning rate to use for new training\n\n\nclassification\n: bool, classificattion or regression\n\n\nclip_norm\n: bool, to clip gradient using gradient norm, stabilizes the training\n\n\nn_iters_per_epoch\n: int,  number of iteratiosn for each epoch;\ne.g: total_training_samples/batch_size\n\n\ngpu_memory_fraction\n: amount of gpu memory to use\n\n\nis_summary\n: bool, to write summary or not\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (data_set,  weights_from=None,  start_epoch=1,  summary_every=10,  weights_dir='weights',  verbose=0)\n\n\nArgs\n\n\n\n\n\ndata_set\n: dataset instance to use to access data for training/validation\n\n\nweights_from\n: str, if not None, initializes model from exisiting weights\n\n\nstart_epoch\n: int,  epoch number to start training from\ne.g. for retarining set the epoch number you want to resume training from\n\n\nsummary_every\n: int, epoch interval to write summary; higher value means lower frequency\nof summary writing\n\n\nverbose\n: log level\n\n\n\n\n\n\nClips the gradients by the given value\n\n\ntefla.core.training._clip_grad_norms\n  (gradients_to_variables,  max_norm=10)\n\n\nArgs\n\n\n\n\n\ngradients_to_variables\n: A list of gradient to variable pairs (tuples).\n\n\nmax_norm\n: the maximum norm value.\n\n\n\n\nReturns\n\n\n\nA list of clipped gradient to variable pairs.\n\n\n\n\nClips the gradients by the given value\n\n\ntefla.core.training.clip_grad_global_norms\n  (tvars,  loss,  opt,  global_norm=1,  gate_gradients=1,  gradient_noise_scale=4.0,  GATE_GRAPH=2,  grad_loss=None,  agre_method=None,  col_grad_ops=False)\n\n\nArgs\n\n\n\n\n\ntvars\n: trainable variables used for gradint updates\n\n\nloss\n: total loss of the network\n\n\nopt\n: optimizer\n\n\nglobal_norm\n: the maximum global norm\n\n\n\n\nReturns\n\n\n\nA list of clipped gradient to variable pairs.\n\n\n\n\nMultiply specified gradients\n\n\ntefla.core.training.multiply_gradients\n  (grads_and_vars,  gradient_multipliers)\n\n\nArgs\n\n\n\n\n\ngrads_and_vars\n: A list of gradient to variable pairs (tuples).\n\n\ngradient_multipliers\n: A map from either \nVariables\n or \nVariable\n op names\n\n\nto the coefficient by which the associated gradient should be scaled.\n\n\n\n\nReturns\n\n\n\nThe updated list of gradient to variable pairs.\n\n\n\n\nAdds scaled noise from a 0-mean normal distribution to gradients\n\n\ntefla.core.training.add_scaled_noise_to_gradients\n  (grads_and_vars,  gradient_noise_scale=10.0)\n\n\nArgs\n\n\n\n\n\ngrads_and_vars\n: list of gradient and variables\n\n\ngardient_noise_scale\n: value of noise factor\n\n\n\n\nReturns\n\n\n\nnoise added gradients", 
            "title": "Learner"
        }, 
        {
            "location": "/core/training/#supervised-trainer-class", 
            "text": "tefla.core.training.SupervisedTrainer   (model,  cnf,  training_iterator= ,  validation_iterator= ,  start_epoch=1,  resume_lr=0.01,  classification=True,  clip_norm=True,  n_iters_per_epoch=1094,  num_classes=5,  gpu_memory_fraction=0.94,  is_summary=False,  loss_type='softmax_cross_entropy')", 
            "title": "Supervised Trainer class"
        }, 
        {
            "location": "/core/training/#clips-the-gradients-by-the-given-value", 
            "text": "tefla.core.training._clip_grad_norms   (gradients_to_variables,  max_norm=10)", 
            "title": "Clips the gradients by the given value"
        }, 
        {
            "location": "/core/training/#clips-the-gradients-by-the-given-value_1", 
            "text": "tefla.core.training.clip_grad_global_norms   (tvars,  loss,  opt,  global_norm=1,  gate_gradients=1,  gradient_noise_scale=4.0,  GATE_GRAPH=2,  grad_loss=None,  agre_method=None,  col_grad_ops=False)", 
            "title": "Clips the gradients by the given value"
        }, 
        {
            "location": "/core/training/#multiply-specified-gradients", 
            "text": "tefla.core.training.multiply_gradients   (grads_and_vars,  gradient_multipliers)", 
            "title": "Multiply specified gradients"
        }, 
        {
            "location": "/core/training/#adds-scaled-noise-from-a-0-mean-normal-distribution-to-gradients", 
            "text": "tefla.core.training.add_scaled_noise_to_gradients   (grads_and_vars,  gradient_noise_scale=10.0)", 
            "title": "Adds scaled noise from a 0-mean normal distribution to gradients"
        }, 
        {
            "location": "/core/learning/", 
            "text": "Supervised Trainer, support data parallelism, multi GPU\n\n\ntefla.core.learning.SupervisedLearner\n  (model,  cnf,  clip_by_global_norm=False,  **kwargs)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition\n\n\ncnf\n: dict, training configs\n\n\ntraining_iterator\n: iterator to use for training data access, processing and augmentations\n\n\nvalidation_iterator\n: iterator to use for validation data access, processing and augmentations\n\n\nstart_epoch\n: int, training start epoch; for resuming training provide the last\n\n\nepoch number to resume training from, its a required parameter for training data balancing\n\n\nresume_lr\n: float, learning rate to use for new training\n\n\nclassification\n: bool, classificattion or regression\n\n\nclip_norm\n: bool, to clip gradient using gradient norm, stabilizes the training\n\n\nn_iters_per_epoch\n: int,  number of iteratiosn for each epoch;\ne.g: total_training_samples/batch_size\n\n\ngpu_memory_fraction\n: amount of gpu memory to use\n\n\nis_summary\n: bool, to write summary or not\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (data_set,  weights_from=None,  weights_dir='weights',  start_epoch=1,  summary_every=10,  keep_moving_averages=False)\n\n\nArgs\n\n\n\n\n\ndata_set\n: dataset instance to use to access data for training/validation\n\n\nweights_from\n: str, if not None, initializes model from exisiting weights\n\n\nstart_epoch\n: int,  epoch number to start training from\ne.g. for retarining set the epoch number you want to resume training from\n\n\nsummary_every\n: int, epoch interval to write summary; higher value means lower frequency\nof summary writing\n\n\nkeep_moving_averages\n: a bool, keep moving averages of trainable variables", 
            "title": "Learner Multi GPU"
        }, 
        {
            "location": "/core/learning/#supervised-trainer-support-data-parallelism-multi-gpu", 
            "text": "tefla.core.learning.SupervisedLearner   (model,  cnf,  clip_by_global_norm=False,  **kwargs)", 
            "title": "Supervised Trainer, support data parallelism, multi GPU"
        }, 
        {
            "location": "/core/learning_v2/", 
            "text": "Supervised Learner, support data parallelism, multi GPU, accept TFRecords data as input\n\n\ntefla.core.learning_v2.SupervisedLearner\n  (model,  cnf,  clip_by_global_norm=False,  data_balancing=1,  **kwargs)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition\n\n\ncnf\n: dict, training configs\n\n\ntraining_iterator\n: iterator to use for training data access, processing and augmentations\n\n\nvalidation_iterator\n: iterator to use for validation data access, processing and augmentations\n\n\nstart_epoch\n: int, training start epoch; for resuming training provide the last\n\n\nepoch number to resume training from, its a required parameter for training data balancing\n\n\nresume_lr\n: float, learning rate to use for new training\n\n\nclassification\n: bool, classificattion or regression\n\n\nclip_norm\n: bool, to clip gradient using gradient norm, stabilizes the training\n\n\nn_iters_per_epoch\n: int,  number of iteratiosn for each epoch;\ne.g: total_training_samples/batch_size\n\n\ngpu_memory_fraction\n: amount of gpu memory to use\n\n\nis_summary\n: bool, to write summary or not\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (data_dir,  data_dir_val=None,  features_keys=None,  weights_from=None,  weights_dir='weights',  max_to_keep=None,  start_epoch=1,  summary_every=10,  training_set_size=None,  val_set_size=None,  dataset_name='cifar10',  keep_moving_averages=False)\n\n\nArgs\n\n\n\n\n\ndata_dir\n: str, training dataset directory (where tfrecords are staored for training)\n\n\ndata_dir_val\n: str optional, validation dataset directory (where tfrecords are stored for validation)\n\n\nfeatures_keys\n: a dict, tfrecords keys to datum features\n\n\ne.g.:\n\n\nfeatures_keys = {\n'image/encoded/image': tf.FixedLenFeature((), tf.string, default_value=''),\n'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\n'image/class/label': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n\n\n}\n\n\nweights_from\n: str, if not None, initializes model from exisiting weights\n\n\ntraining_set_size\n: int, number of training examples\n\n\nval_set_size\n: int, set if data_dir_val not None, number of validation examples\n\n\ndataset_name\n: a optional, Name of the dataset\n\n\nstart_epoch\n: int,  epoch number to start training from\ne.g. for retarining set the epoch number you want to resume training from\n\n\nsummary_every\n: int, epoch interval to write summary; higher value means lower frequency\nof summary writing\n\n\nkeep_moving_averages\n: a bool, keep moving averages of trainable variables", 
            "title": "Learner Multi GPU V2"
        }, 
        {
            "location": "/core/learning_v2/#supervised-learner-support-data-parallelism-multi-gpu-accept-tfrecords-data-as-input", 
            "text": "tefla.core.learning_v2.SupervisedLearner   (model,  cnf,  clip_by_global_norm=False,  data_balancing=1,  **kwargs)", 
            "title": "Supervised Learner, support data parallelism, multi GPU, accept TFRecords data as input"
        }, 
        {
            "location": "/core/learning_ss/", 
            "text": "Semi Supervised Trainer\n\n\ntefla.core.learning_ss.SemiSupervisedTrainer\n  (model,  cnf,  clip_by_global_norm=False,  **kwargs)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition\n\n\ncnf\n: dict, training configs\n\n\ntraining_iterator\n: iterator to use for training data access, processing and augmentations\n\n\nvalidation_iterator\n: iterator to use for validation data access, processing and augmentations\n\n\nstart_epoch\n: int, training start epoch; for resuming training provide the last\n\n\nepoch number to resume training from, its a required parameter for training data balancing\n\n\nresume_lr\n: float, learning rate to use for new training\n\n\nclassification\n: bool, classificattion or regression\n\n\nclip_norm\n: bool, to clip gradient using gradient norm, stabilizes the training\n\n\nn_iters_per_epoch\n: int,  number of iteratiosn for each epoch;\ne.g: total_training_samples/batch_size\n\n\ngpu_memory_fraction\n: amount of gpu memory to use\n\n\nis_summary\n: bool, to write summary or not\n\n\n\n\nMethods\n\n\n\n \n\n\nfit\n  (data_set,  num_classes=6,  weights_from=None,  start_epoch=1,  summary_every=199,  model_name='multiclass_ss',  weights_dir='weights')\n\n\nArgs\n\n\n\n\n\ndata_set\n: dataset instance to use to access data for training/validation\n\n\nweights_from\n: str, if not None, initializes model from exisiting weights\n\n\nstart_epoch\n: int,  epoch number to start training from\ne.g. for retarining set the epoch number you want to resume training from\n\n\nsummary_every\n: int, epoch interval to write summary; higher value means lower frequency\nof summary writing\n\n\n\n\n \n\n\nsigmoid_kl_with_logits\n  (logits,  targets)\n\n\nArgs\n\n\n\n\nlogits\n: logits\n\n\ntargets\n: smooth targets\n\n\n\n\nReturns\n\n\n\ncross entropy loss", 
            "title": "Learner Semi Supervised"
        }, 
        {
            "location": "/core/learning_ss/#semi-supervised-trainer", 
            "text": "tefla.core.learning_ss.SemiSupervisedTrainer   (model,  cnf,  clip_by_global_norm=False,  **kwargs)", 
            "title": "Semi Supervised Trainer"
        }, 
        {
            "location": "/core/prediction/", 
            "text": "base mixin class for prediction\n\n\ntefla.core.prediction.PredictSession\n  (weights_from,  gpu_memory_fraction=None)\n\n\nArgs\n\n\n\n\n\nweights_from\n: path to the weights file\n\n\ngpu_memory_fraction\n: fraction of gpu memory to use, if not cpu prediction\n\n\n\n\n\n\nOne crop Predictor, it predict network out put from a single crop of an input image\n\n\ntefla.core.prediction.OneCropPredictor\n  (model,  cnf,  weights_from,  prediction_iterator)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition file\n\n\ncnf\n: prediction configs\n\n\nweights_from\n: location of the model weights file\n\n\nprediction_iterator\n: iterator to access and augment the data for prediction\n\n\ngpu_memory_fraction\n: fraction of gpu memory to use, if not cpu prediction\n\n\n\n\n\n\nQuasi transform predictor\n\n\ntefla.core.prediction.QuasiPredictor\n  (model,  cnf,  weights_from,  prediction_iterator,  number_of_transforms)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition file\n\n\ncnf\n: prediction configs\n\n\nweights_from\n: location of the model weights file\n\n\nprediction_iterator\n: iterator to access and augment the data for prediction\n\n\nnumber_of_transform\n: number of determinastic augmentaions to be performed on the input data\nresulted predictions are averaged over the augmentated transformation prediction outputs\n\n\ngpu_memory_fraction\n: fraction of gpu memory to use, if not cpu prediction\n\n\n\n\n\n\nMultiples non Data augmented crops predictor\n\n\ntefla.core.prediction.CropPredictor\n  (model,  cnf,  weights_from,  prediction_iterator,  im_size,  crop_size)\n\n\nArgs\n\n\n\n\n\nmodel\n: model definition file\n\n\ncnf\n: prediction configs\n\n\nweights_from\n: location of the model weights file\n\n\nprediction_iterator\n: iterator to access and augment the data for prediction\n\n\ncrop_size\n: crop size for network input\n\n\nim_size\n: original image size\n\n\nnumber_of_crops\n: total number of crops to extract from the input image\n\n\ngpu_memory_fraction\n: fraction of gpu memory to use, if not cpu prediction\n\n\n\n\n\n\n\n\nReturns predcitions from multiples models\n\n\ntefla.core.prediction.EnsemblePredictor\n  (predictors)\n\n\nEnsembled predictions from multiples models using ensemble type\n\n\nArgs\n\n\n\n\n\npredictors\n: predictor instances\n\n\n\n\nMethods\n\n\n\n \n\n\npredict\n  (X,  ensemble_type='mean')\n\n\nArgs\n\n\n\n\n\nX\n: 4D tensor, inputs\n\n\nensemble_type\n: operation to combine models probabilitiesavailable type: ['mean', 'gmean', 'log_mean']", 
            "title": "Predictor"
        }, 
        {
            "location": "/core/prediction/#base-mixin-class-for-prediction", 
            "text": "tefla.core.prediction.PredictSession   (weights_from,  gpu_memory_fraction=None)", 
            "title": "base mixin class for prediction"
        }, 
        {
            "location": "/core/prediction/#one-crop-predictor-it-predict-network-out-put-from-a-single-crop-of-an-input-image", 
            "text": "tefla.core.prediction.OneCropPredictor   (model,  cnf,  weights_from,  prediction_iterator)", 
            "title": "One crop Predictor, it predict network out put from a single crop of an input image"
        }, 
        {
            "location": "/core/prediction/#quasi-transform-predictor", 
            "text": "tefla.core.prediction.QuasiPredictor   (model,  cnf,  weights_from,  prediction_iterator,  number_of_transforms)", 
            "title": "Quasi transform predictor"
        }, 
        {
            "location": "/core/prediction/#multiples-non-data-augmented-crops-predictor", 
            "text": "tefla.core.prediction.CropPredictor   (model,  cnf,  weights_from,  prediction_iterator,  im_size,  crop_size)", 
            "title": "Multiples non Data augmented crops predictor"
        }, 
        {
            "location": "/core/prediction/#returns-predcitions-from-multiples-models", 
            "text": "tefla.core.prediction.EnsemblePredictor   (predictors)  Ensembled predictions from multiples models using ensemble type", 
            "title": "Returns predcitions from multiples models"
        }, 
        {
            "location": "/core/lr_policy/", 
            "text": "Training learning rate schedule based on  inputs dict with epoch number as keys\n\n\ntefla.core.lr_policy.StepDecayPolicy\n  (schedule,  start_epoch=1)\n\n\nArgs\n\n\n\n\n\nschedule\n: a dict, epoch number as keys and learning rate as values\n\n\nstart_epoch\n: training start epoch number\n\n\n\n\nMethods\n\n\n\n \n\n\nepoch_update\n  (learning_rate,  training_history)\n\n\nArgs\n\n\n\n\n\nlearning_rate\n: previous epoch learning rate\n\n\ntraining_histoty\n: a dict with epoch, training loss, validation loss as keys\n\n\n\n\nReturns\n\n\n\nupdated learning rate\n\n\n\n\nPolynomial learning rate decay policy\n\n\ntefla.core.lr_policy.PolyDecayPolicy\n  (base_lr,  power=10.0,  max_epoch=500,  n_iters_per_epoch=1094)\n\n\nthe effective learning rate follows a polynomial decay, to be\nzero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)\n\n\nArgs\n\n\n\n\n\nbase_lr\n: a float, starting learning rate\n\n\npower\n: a float, decay factor\n\n\nmax_epoch\n: a int, max training epoch\n\n\nn_iters_per_epoch\n: number of interations per epoch, e.g. total_training_samples/batch_size\n\n\n\n\nMethods\n\n\n\n \n\n\nbatch_update\n  (learning_rate,  iter_idx)\n\n\nit follows a polynomial decay policy\n\n\nArgs\n\n\n\n\n\nlearning_rate\n: current batch learning rate\n\n\niter_idx\n: iteration number,\ne.g. number_of_iterations_per_batch*epoch+current_batch_iteration_number\n\n\n\n\nReturns\n\n\n\nupdated_lr", 
            "title": "Lr_Policy"
        }, 
        {
            "location": "/core/lr_policy/#training-learning-rate-schedule-based-on-inputs-dict-with-epoch-number-as-keys", 
            "text": "tefla.core.lr_policy.StepDecayPolicy   (schedule,  start_epoch=1)", 
            "title": "Training learning rate schedule based on  inputs dict with epoch number as keys"
        }, 
        {
            "location": "/core/lr_policy/#polynomial-learning-rate-decay-policy", 
            "text": "tefla.core.lr_policy.PolyDecayPolicy   (base_lr,  power=10.0,  max_epoch=500,  n_iters_per_epoch=1094)  the effective learning rate follows a polynomial decay, to be\nzero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)", 
            "title": "Polynomial learning rate decay policy"
        }, 
        {
            "location": "/core/metrics/", 
            "text": "Computes accuracy metric\n\n\ntefla.core.metrics.accuracy_op\n  (predictions,  targets,  num_classes=5)\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor/array, predictions of the network\n\n\ntargets\n: 2D tensor/array, ground truth labels of the network\n\n\nnum_classes\n: int, num_classes of the network\n\n\n\n\nReturns\n\n\n\naccuracy\n\n\n\n\nRetruns one hot vector\n\n\ntefla.core.metrics.one_hot\n  (vec,  m=None)\n\n\nArgs\n\n\n\n\n\nvec\n: a vector\n\n\nm\n: num_classes\n\n\n\n\n\n\nCompute dice coef\n\n\ntefla.core.metrics.dice_coef\n  (y_true,  y_pred)\n\n\nArgs\n\n\n\n\n\ny_true\n: a 2-D \narray\n, ground truth label\n\n\ny_pred\n: q 2-D \narray\n, prediction\n\n\n\n\nReturns\n\n\n\na \nfloat\n, dice value\n\n\n\n\nComputes character level accuracy\n\n\ntefla.core.metrics.char_accuracy\n  (predictions,  targets,  rej_char,  streaming=False)\n\nBoth predictions and targets should have the same shape\n[batch_size x seq_length].\n\n\nArgs\n\n\n\n\n\npredictions\n: predicted characters ids.\n\n\ntargets\n: ground truth character ids.\n\n\nrej_char\n: the character id used to mark an empty element (end of sequence).\n\n\nstreaming\n: if True, uses the streaming mean from the slim.metric module.\n\n\n\n\nReturns\n\n\n\na update_ops for execution and value tensor whose value on evaluation\nreturns the total character accuracy.\n\n\n\n\nComputes sequence level accuracy\n\n\ntefla.core.metrics.sequence_accuracy\n  (predictions,  targets,  rej_char,  streaming=False)\n\nBoth input tensors should have the same shape: [batch_size x seq_length].\n\n\nArgs\n\n\n\n\n\npredictions\n: predicted character classes.\n\n\ntargets\n: ground truth character classes.\n\n\nrej_char\n: the character id used to mark empty element (end of sequence).\n\n\nstreaming\n: if True, uses the streaming mean from the slim.metric module.\n\n\n\n\nReturns\n\n\n\na update_ops for execution and value tensor whose value on evaluation\nreturns the total sequence accuracy.", 
            "title": "Metrics"
        }, 
        {
            "location": "/core/metrics/#computes-accuracy-metric", 
            "text": "tefla.core.metrics.accuracy_op   (predictions,  targets,  num_classes=5)", 
            "title": "Computes accuracy metric"
        }, 
        {
            "location": "/core/metrics/#retruns-one-hot-vector", 
            "text": "tefla.core.metrics.one_hot   (vec,  m=None)", 
            "title": "Retruns one hot vector"
        }, 
        {
            "location": "/core/metrics/#compute-dice-coef", 
            "text": "tefla.core.metrics.dice_coef   (y_true,  y_pred)", 
            "title": "Compute dice coef"
        }, 
        {
            "location": "/core/metrics/#computes-character-level-accuracy", 
            "text": "tefla.core.metrics.char_accuracy   (predictions,  targets,  rej_char,  streaming=False) \nBoth predictions and targets should have the same shape\n[batch_size x seq_length].", 
            "title": "Computes character level accuracy"
        }, 
        {
            "location": "/core/metrics/#computes-sequence-level-accuracy", 
            "text": "tefla.core.metrics.sequence_accuracy   (predictions,  targets,  rej_char,  streaming=False) \nBoth input tensors should have the same shape: [batch_size x seq_length].", 
            "title": "Computes sequence level accuracy"
        }, 
        {
            "location": "/core/initializers/", 
            "text": "He Normal initializer\n\n\ntefla.core.initializers.he_normal\n  (seed=None,  scale=1.0,  dtype=tf.float32)\n\nKaiming He et al. (2015): Delving deep into rectifiers: Surpassing human-level\nperformance on imagenet classification. arXiv preprint arXiv:1502.01852.\n\n\nArgs\n\n\n\n\n\nscale\n: float\n   Scaling factor for the weights. Set this to \n1.0\n for linear and\n   sigmoid units, to \nsqrt(2)\n for rectified linear units, and\n   to \nsqrt(2/(1+alpha**2))\n for leaky rectified linear units with\n   leakiness \nalpha\n. Other transfer functions may need different factors.\n\n\n\n\n\n\nHe Uniform initializer\n\n\ntefla.core.initializers.he_uniform\n  (seed=None,  scale=1.0,  dtype=tf.float32)\n\n\nArgs\n\n\n\n\n\nscale\n: float\n   Scaling factor for the weights. Set this to \n1.0\n for linear and\n   sigmoid units, to \nsqrt(2)\n for rectified linear units, and\n   to \nsqrt(2/(1+alpha**2))\n for leaky rectified linear units with\n   leakiness \nalpha\n. Other transfer functions may need different factors.\n\n\n\n\n\n\nRandom Normal initializer\n\n\ntefla.core.initializers.random_normal\n  (seed=None,  mean=0.0,  stddev=1.0,  dtype=tf.float32,  name=None)\n\n\nArgs\n\n\n\n\n\nmean\n: a \nfloat\n\n\nstddev\n: a \nfloat\n\n\n\n\n\n\nReturns an initializer that generates tensors without scaling variance\n\n\ntefla.core.initializers.variance_scaling_initializer_v2\n  (factor=2.0,  mode='FAN_IN',  uniform=False,  seed=None,  dtype=tf.float32,  mean=0.0,  stddev=1.0,  normal_type=None,  name=None)\n\nWhen initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. This initializer use the following formula:\n\n\n  if mode='FAN_IN': # Count only number of input connections.\nn = fan_in\n  elif mode='FAN_OUT': # Count only number of output connections.\nn = fan_out\n  elif mode='FAN_AVG': # Average number of inputs and output connections.\nn = (fan_in + fan_out)/2.0\ntruncated_normal(shape, 0.0, stddev=sqrt(factor / n))\n\n\n\n\n\n\nTo get \nDelving Deep into Rectifiers\n, use (Default):\n\n  \nfactor=2.0 mode='FAN_IN' uniform=False\n\n\nTo get \nConvolutional Architecture for Fast Feature Embedding\n, use:\n\n  \nfactor=1.0 mode='FAN_IN' uniform=True\n\n\nTo get \nUnderstanding the difficulty of training deep feedforward neural\n  networks\n,\n  use:\n\n  \nfactor=1.0 mode='FAN_AVG' uniform=True.\n\n\nTo get \nxavier_initializer\n use either:\n\n  \nfactor=1.0 mode='FAN_AVG' uniform=True\n, or\n\n  \nfactor=1.0 mode='FAN_AVG' uniform=False\n.\n\nArgs\n\n\n\n\nfactor: Float.  A multiplicative factor.\n  mode: String.  'FAN_IN', 'FAN_OUT', 'FAN_AVG'.\n  uniform: Whether to use uniform or normal distributed random initialization.\n  seed: A Python integer. Used to create random seeds. See\n - \nset_random_seed\n\n - for behavior.\n  dtype: The data type. Only floating point types are supported.\n\nReturns\n\n\nAn initializer that generates tensors with unit variance.\n\nRaises\n\n\nValueError: if \ndtype\n is not a floating point type.\n  TypeError: if \nmode\n is not in ['FAN_IN', 'FAN_OUT', 'FAN_AVG'].\n\n\nReturns\n\n\n\nAn initializer that generates tensors with unit variance.\n\nRaises\n\n\nValueError: if \ndtype\n is not a floating point type.\n  TypeError: if \nmode\n is not in ['FAN_IN', 'FAN_OUT', 'FAN_AVG'].\n\n\n\n\nBilinear initialization for up sampling operation\n\n\ntefla.core.initializers.bilinear\n  (f_shape)\n\n\nArgs\n\n\n\n\n\nf_shape\n: shape of the variable\n\n\n\n\nReturns\n\n\n\nbilinear initializer\n\n\n\n\nVariable initializer that produces a random orthonormal matrix\n\n\ntefla.core.initializers.random_orthonormal_initializer\n  (shape,  dtype=tf.float32,  partition_info=None)\n\n\nArgs\n\n\n\n\n\nshape\n: shape of the variable\n\n\n\n\nReturns\n\n\n\nrandom_orthogonal_matrix for initialization.", 
            "title": "Initializations"
        }, 
        {
            "location": "/core/initializers/#he-normal-initializer", 
            "text": "tefla.core.initializers.he_normal   (seed=None,  scale=1.0,  dtype=tf.float32) \nKaiming He et al. (2015): Delving deep into rectifiers: Surpassing human-level\nperformance on imagenet classification. arXiv preprint arXiv:1502.01852.", 
            "title": "He Normal initializer"
        }, 
        {
            "location": "/core/initializers/#he-uniform-initializer", 
            "text": "tefla.core.initializers.he_uniform   (seed=None,  scale=1.0,  dtype=tf.float32)", 
            "title": "He Uniform initializer"
        }, 
        {
            "location": "/core/initializers/#random-normal-initializer", 
            "text": "tefla.core.initializers.random_normal   (seed=None,  mean=0.0,  stddev=1.0,  dtype=tf.float32,  name=None)", 
            "title": "Random Normal initializer"
        }, 
        {
            "location": "/core/initializers/#returns-an-initializer-that-generates-tensors-without-scaling-variance", 
            "text": "tefla.core.initializers.variance_scaling_initializer_v2   (factor=2.0,  mode='FAN_IN',  uniform=False,  seed=None,  dtype=tf.float32,  mean=0.0,  stddev=1.0,  normal_type=None,  name=None) \nWhen initializing a deep network, it is in principle advantageous to keep\nthe scale of the input variance constant, so it does not explode or diminish\nby reaching the final layer. This initializer use the following formula:    if mode='FAN_IN': # Count only number of input connections.\nn = fan_in\n  elif mode='FAN_OUT': # Count only number of output connections.\nn = fan_out\n  elif mode='FAN_AVG': # Average number of inputs and output connections.\nn = (fan_in + fan_out)/2.0\ntruncated_normal(shape, 0.0, stddev=sqrt(factor / n))   To get  Delving Deep into Rectifiers , use (Default): \n   factor=2.0 mode='FAN_IN' uniform=False  To get  Convolutional Architecture for Fast Feature Embedding , use: \n   factor=1.0 mode='FAN_IN' uniform=True  To get  Understanding the difficulty of training deep feedforward neural\n  networks ,\n  use: \n   factor=1.0 mode='FAN_AVG' uniform=True.  To get  xavier_initializer  use either: \n   factor=1.0 mode='FAN_AVG' uniform=True , or \n   factor=1.0 mode='FAN_AVG' uniform=False .", 
            "title": "Returns an initializer that generates tensors without scaling variance"
        }, 
        {
            "location": "/core/initializers/#bilinear-initialization-for-up-sampling-operation", 
            "text": "tefla.core.initializers.bilinear   (f_shape)", 
            "title": "Bilinear initialization for up sampling operation"
        }, 
        {
            "location": "/core/initializers/#variable-initializer-that-produces-a-random-orthonormal-matrix", 
            "text": "tefla.core.initializers.random_orthonormal_initializer   (shape,  dtype=tf.float32,  partition_info=None)", 
            "title": "Variable initializer that produces a random orthonormal matrix"
        }, 
        {
            "location": "/core/losses/", 
            "text": "Define a log loss\n\n\ntefla.core.losses.log_loss_custom\n  (predictions,  labels,  eps=1e-07,  name='log')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D or array tensor, [batch_size, num_classes]  ground truth labels or target labels.\n\n\neps\n: a constant to set upper or lower limit for labels, smoothening factor\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the log loss.\n\n\n\n\nDefine a log loss\n\n\ntefla.core.losses.log_loss_tf\n  (predictions,  labels,  eps=1e-07,  weights=1.0,  name='log_loss')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D or array tensor, [batch_size, num_classes]  ground truth labels or target labels.\n\n\neps\n: a constant to set upper or lower limit for labels, smoothening factor\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the log loss.\n\n\n\n\nDefine a kappa loss, Its a continuous differentiable approximation of discrete kappa loss\n\n\ntefla.core.losses.kappa_loss\n  (predictions,  labels,  y_pow=1,  eps=1e-15,  num_ratings=5,  batch_size=32,  name='kappa')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D tensor or array,[batch_size, num_classes]  ground truth labels or target labels.\n\n\ny_pow\n: int, to whcih the labels should be raised; useful if model diverge. e.g. y_pow=2\n\n\nnum_ratings\n: numbers of rater to used, typically num_classes of the model\n\n\nbatch_size\n: batch_size of the training or validation ops\n\n\neps\n: a float, prevents divide by zero\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the kappa loss.\n\n\n\n\nDefine a joint kappa and log loss, Kappa is a continuous differentiable approximation of discrete kappa loss\n\n\ntefla.core.losses.kappa_log_loss\n  (predictions,  labels,  label_smoothing=0.0,  y_pow=1,  batch_size=32,  log_scale=0.5,  num_classes=5,  log_offset=0.5,  name='kappa_log')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D tensor or array,[batch_size, num_classes]  ground truth labels or target labels.\n\n\nlabel_smoothing\n: a float, used to smooth the labels for better generalization if greater than 0 then smooth the labels.\n\n\ny_pow\n: int, to whcih the labels should be raised; useful if model diverge. e.g. y_pow=2\n\n\nnum_ratings\n: numbers of rater to used, typically num_classes of the model\n\n\nbatch_size\n: batch_size of the training or validation ops\n\n\nlog_scale\n: a float, used to multiply the clipped log loss, e.g: 0.5\n\n\nlog_offset\n:a float minimum log loss offset to substract from original log loss; e.g. 0.50\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the kappa log loss.\n\n\n\n\nDefine a joint kappa and log loss; log loss is clipped by a defined min value; Kappa is a continuous differentiable approximation of discrete kappa loss\n\n\ntefla.core.losses.kappa_log_loss_clipped\n  (predictions,  labels,  label_smoothing=0.0,  y_pow=1,  batch_size=32,  log_scale=0.5,  log_cutoff=0.8,  num_classes=5,  name='kappa_log_clipped')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D tensor or array,[batch_size, num_classes]  ground truth labels or target labels.\n\n\nlabel_smoothing\n: a float, used to smooth the labels for better generalization if greater than 0 then smooth the labels.\n\n\ny_pow\n: int, to whcih the labels should be raised; useful if model diverge. e.g. y_pow=2\n\n\nnum_ratings\n: numbers of rater to used, typically num_classes of the model\n\n\nbatch_size\n: batch_size of the training or validation ops\n\n\nlog_scale\n: a float, used to multiply the clipped log loss, e.g: 0.5\n\n\nlog_cutoff\n:a float, minimum log loss value; e.g. 0.50\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the clipped kappa log loss.\n\n\n\n\nDefine a cross entropy loss with label smoothing\n\n\ntefla.core.losses.cross_entropy_loss\n  (logits,  labels,  label_smoothing=0.0,  weight=1.0,  name='cross_entropy_loss')\n\n\nArgs\n\n\n\n\n\npredictions\n: 2D tensor or array, [batch_size, num_classes] predictions of the network .\n\n\nlabels\n: 2D tensor or array,[batch_size, num_classes]  ground truth labels or target labels.\n\n\nlabel_smoothing\n: a float, used to smooth the labels for better generalizationif greater than 0 then smooth the labels.\n\n\nweight\n: scale the loss by this factor.\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the cross entropy loss.\n\n\n\n\nDefine a L2Loss, useful for regularize, i.e. weight decay\n\n\ntefla.core.losses.l1_l2_regularizer\n  (var,  weight_l1=1.0,  weight_l2=1.0,  name='l1_l2_regularizer')\n\n\nArgs\n\n\n\n\n\nvar\n: tensor to regularize.\n\n\nweight_l1\n: an optional weight to modulate the l1 loss.\n\n\nweight_l2\n: an optional weight to modulate the l2 loss.\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nthe l1+L2 loss op.\n\n\n\n\nReturns a function that can be used to apply L1 regularization to weights\n\n\ntefla.core.losses.l1_regularizer\n  (scale,  name='l1_regularizer')\n\nL1 regularization encourages sparsity.\n\n\nArgs\n\n\n\nscale: A scalar multiplier \nTensor\n. 0.0 disables the regularizer.\n  name: An optional name/scope name.\n\n\nReturns\n\n\n\nA function with signature \nl1(weights)\n that apply L1 regularization.\n\n\n\n\nReturns a function that can be used to apply L2 regularization to weights\n\n\ntefla.core.losses.l2_regularizer\n  (scale,  name='l2_regularizer')\n\nSmall values of L2 can help prevent overfitting the training data.\n\n\nArgs\n\n\n\nscale: A scalar multiplier \nTensor\n. 0.0 disables the regularizer.\n  name: An optional name/scope name.\n\n\nReturns\n\n\n\nA function with signature \nl2(weights)\n that applies L2 regularization.\n\n\n\n\nlog-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval\n\n\ntefla.core.losses.discretized_mix_logistic_loss\n  (inputs,  predictions,  sum_all=True,  name='disretized_mix_logistic_loss')\n\n\nArgs\n\n\n\n\n\npredictions\n: 4D tensor or array, [batch_size, width, height, out_channels] predictions of the network .\n\n\ninputs\n: 4D tensor or array, [batch_size, width, height, num_classes] ground truth labels or target labels.\n\n\nname\n: Optional scope/name for op_scope.\n\n\n\n\nReturns\n\n\n\nA tensor with the discretized mix logistic loss.\n\n\n\n\nPull Away loss calculation\n\n\ntefla.core.losses.pullaway_loss\n  (embeddings,  name='pullaway_loss')\n\n\nArgs\n\n\n\n\n\nembeddings\n: The embeddings to be orthogonalized for varied faces. Shape [batch_size, embeddings_dim]\n\n\n\n\n\n\nCalculate the loss from the logits and the labels\n\n\ntefla.core.losses.segment_loss\n  (logits,  labels,  num_classes,  head=None)\n\n\nArgs\n\n\n\nlogits: tensor, float - [batch_size * width * height, num_classes].\n -   Use vgg_fcn.up as logits.\n  labels: Labels tensor, int32 - [batch_size * width * height, num_classes].\n -   The ground truth of your data.\n  head: numpy array - [num_classes]\n -   Weighting the loss of each class\n -   Optional: Prioritize some classes\n\n\nReturns\n\n\n\nloss: Loss tensor of type float.\n\n\n\n\nCalculate the triplet loss according to the FaceNet paper\n\n\ntefla.core.losses.triplet_loss\n  (anchor,  positive,  negative,  alpha=0.2,  name='triplet_loss')\n\n\nArgs\n\n\n\nanchor: 2-D \ntensor\n [batch_size, embedding_size], the embeddings for the anchor images.\n  positive: 2-D \ntensor\n [batch_size, embedding_size], the embeddings for the positive images.\n  negative: 2-D \ntensor\n [batch_size, embedding_size], the embeddings for the negative images.\n  alpha: positive to negative triplet distance margin\n\n\nReturns\n\n\n\nthe triplet loss.\n\n\n\n\nDecov loss as described in https://arxiv.org/pdf/1511.06068.pdf\n\n\ntefla.core.losses.decov_loss\n  (xs,  name='decov_loss')\n\n'Reducing Overfitting In Deep Networks by Decorrelating Representation'\n\n\nArgs\n\n\n\n\n\nxs\n: 4-D \ntensor\n [batch_size, height, width, channels], input\n\n\n\n\nReturns\n\n\n\na \nfloat\n decov loss\n\n\n\n\nCenter loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n\n\ntefla.core.losses.center_loss\n  (features,  label,  alpha,  num_classes,  name='center_loss')\n\n   (http://ydwen.github.io/papers/WenECCV16.pdf)\n\n\nArgs\n\n\n\n\n\nfeatures\n: 2-D \ntensor\n [batch_size, feature_length], input features\n\n\nlabel\n: 1-D \ntensor\n [batch_size], input label\n\n\nalpha\n: center loss parameter\n\n\nnum_classes\n: a \nint\n numof classes for training\n\n\n\n\nReturns\n\n\n\na \nfloat\n, center loss\n\n\n\n\nAdds a similarity loss term, the correlation between two representations\n\n\ntefla.core.losses.correlation_loss\n  (source_samples,  target_samples,  weight,  name='corr_loss')\n\n\nArgs\n\n\n\n\n\nsource_samples\n: a tensor of shape [num_samples, num_features]\n\n\ntarget_samples\n: a tensor of shape [num_samples, num_features]\n\n\nweight\n: a scalar weight for the loss.\n\n\nscope\n: optional name scope for summary tags.\n\n\n\n\nReturns\n\n\n\na scalar tensor representing the correlation loss value.\n\n\n\n\nComputes the Maximum Mean Discrepancy (MMD) of two samples: x and y\n\n\ntefla.core.losses.maximum_mean_discrepancy\n  (x,  y,  kernel=\n,  name='maximum_mean_discrepancy')\n\n\nMaximum Mean Discrepancy (MMD) is a distance-measure between the samples of\nthe distributions of x and y. Here we use the kernel two sample estimate\nusing the empirical mean of the two distributions.\n\n\nMMD^2(P, Q) = || \\E{\\phi(x)} - \\E{\\phi(y)} ||^2= \\E{ K(x, x) } + \\E{ K(y, y) } - 2 \\E{ K(x, y) },\n\n\nwhere K = \n\\phi(x), \\phi(y)\n,\n  is the desired kernel function, in this case a radial basis kernel.\n\n\nArgs\n\n\n\n\n\nx\n: a tensor of shape [num_samples, num_features]\n\n\ny\n: a tensor of shape [num_samples, num_features]\n\n\nkernel\n: a function which computes the kernel in MMD. Defaults to theGaussianKernelMatrix.\n\n\n\n\nReturns\n\n\n\na scalar denoting the squared maximum mean discrepancy loss.\n\n\n\n\nAdds a similarity loss term, the MMD between two representations\n\n\ntefla.core.losses.mmd_loss\n  (source_samples,  target_samples,  weight,  name='mmd_loss')\n\n\nThis Maximum Mean Discrepancy (MMD) loss is calculated with a number of\ndifferent Gaussian kernels.\n\n\nArgs\n\n\n\nsource_samples: a tensor of shape [num_samples, num_features].\n  target_samples: a tensor of shape [num_samples, num_features].\n  weight: the weight of the MMD loss.\n  scope: optional name scope for summary tags.\n\n\nReturns\n\n\n\na scalar tensor representing the MMD loss value.\n\n\n\n\nAdds the domain adversarial (DANN) loss\n\n\ntefla.core.losses.dann_loss\n  (source_samples,  target_samples,  weight,  name='dann_loss')\n\n\nArgs\n\n\n\nsource_samples: a tensor of shape [num_samples, num_features].\n  target_samples: a tensor of shape [num_samples, num_features].\n  weight: the weight of the loss.\n  scope: optional name scope for summary tags.\n\n\nReturns\n\n\n\na scalar tensor representing the correlation loss value.\n\n\n\n\nAdds the difference loss between the private and shared representations\n\n\ntefla.core.losses.difference_loss\n  (private_samples,  shared_samples,  weight=1.0,  name='difference_loss')\n\n\nArgs\n\n\n\nprivate_samples: a tensor of shape [num_samples, num_features].\n  shared_samples: a tensor of shape [num_samples, num_features].\n  weight: the weight of the incoherence loss.\n  name: the name of the tf summary.\n\n\n\n\nA helper function to compute the error between quaternions\n\n\ntefla.core.losses.log_quaternion_loss_batch\n  (predictions,  labels,  name='log_quaternion_batch_loss')\n\n\nArgs\n\n\n\npredictions: A Tensor of size [batch_size, 4].\n  labels: A Tensor of size [batch_size, 4].\n  params: A dictionary of parameters. Expecting 'use_logging', 'batch_size'.\n\n\nReturns\n\n\n\nA Tensor of size [batch_size], denoting the error between the quaternions.\n\n\n\n\nA helper function to compute the mean error between batches of quaternions\n\n\ntefla.core.losses.log_quaternion_loss\n  (predictions,  labels,  batch_size,  name='log_quaternion_loss')\n\n\nThe caller is expected to add the loss to the graph.\n\n\nArgs\n\n\n\npredictions: A Tensor of size [batch_size, 4].\n  labels: A Tensor of size [batch_size, 4].\n  params: A dictionary of parameters. Expecting 'use_logging', 'batch_size'.\n\n\nReturns\n\n\n\nA Tensor of size 1, denoting the mean error between batches of quaternions.\n\n\n\n\nAdds noise to embeddings and recomputes classification loss\n\n\ntefla.core.losses.random_perturbation_loss\n  (embedded,  length,  loss_fn,  perturb_norm_length=0.1)\n\n\nArgs\n\n\n\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim]\n\n\nlength\n: a \nint\n, length of the mask\n\n\nloss_fn\n: a callable, that returns loss\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\nperturbation loss\n\n\n\n\nAdds gradient to embedding and recomputes classification loss\n\n\ntefla.core.losses.adversarial_loss\n  (embedded,  loss,  loss_fn,  perturb_norm_length=0.1)\n\n\nArgs\n\n\n\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim]\n\n\nloss\n: \nfloat\n, loss\n\n\nloss_fn\n: a callable, that returns loss\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\nadversial loss\n\n\n\n\nVirtual adversarial loss\n\n\ntefla.core.losses.virtual_adversarial_loss\n  (logits,  embedded,  labels,  length,  logits_from_embedding_fn,  num_classes,  num_power_iteration=1,  small_constant_for_finite_diff=0.001,  perturb_norm_length=0.1)\n\nComputes virtual adversarial perturbation by finite difference method and\npower iteration, adds it to the embedding, and computes the KL divergence\nbetween the new logits and the original logits.\n\n\nArgs\n\n\n\n\n\nlogits\n: 2-D float \nTensor\n, [num_timesteps*batch_size, m], where m=1 if\nnum_classes=2, otherwise m=num_classes.\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim].\n\n\nlabels\n: 1-D \nTensor\n, input labels\n\n\nlength\n: a \nint\n, input length\n\n\nlogits_from_embedding_fn\n: callable that takes embeddings and returns\nclassifier logits.\n\n\nnum_classes\n: num_classes for training\n\n\nvocab_size\n: a \nint\n, vocabular size of the problem\n\n\nnum_power_iteration\n: a \nint\n, the number of power iteration\n\n\nsmall_constant_for_finite_diff\n: a \nfloat\n, Small constant for finite difference method\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\na \nfloat\n \nscalar\n, KL divergence.\n\n\n\n\nAdds noise to embeddings and recomputes classification loss fir bidirectional rnn models\n\n\ntefla.core.losses.random_perturbation_loss_brnn\n  (embedded,  length,  loss_fn,  perturb_norm_length=0.1)\n\n\nArgs\n\n\n\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim]\n\n\nlength\n: a \nint\n, length of the mask\n\n\nloss_fn\n: a callable, that returns loss\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\nperturbation loss\n\n\n\n\nAdds gradient to embeddings and recomputes classification loss for bidirectional rnn models\n\n\ntefla.core.losses.adversarial_loss_brnn\n  (embedded,  loss,  loss_fn,  perurb_norm_length=0.1)\n\n\nArgs\n\n\n\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim]\n\n\nloss\n: \nfloat\n, loss\n\n\nloss_fn\n: a callable, that returns loss\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\nadversial loss\n\n\n\n\nVirtual adversarial loss for bidirectional models\n\n\ntefla.core.losses.virtual_adversarial_loss_brnn\n  (logits,  embedded,  labels,  length,  logits_from_embedding_fn,  vocab_size,  num_classes,  num_power_iteration=1,  small_constant_for_finite_diff=0.001,  perturb_norm_length=0.1)\n\nComputes virtual adversarial perturbation by finite difference method and\npower iteration, adds it to the embedding, and computes the KL divergence\nbetween the new logits and the original logits.\n\n\nArgs\n\n\n\n\n\nlogits\n: 2-D float \nTensor\n, [num_timesteps*batch_size, m], where m=1 if\nnum_classes=2, otherwise m=num_classes.\n\n\nembedded\n: 3-D float \nTensor\n, [batch_size, num_timesteps, embedding_dim].\n\n\nlabels\n: 1-D \nTensor\n, input labels\n\n\nlength\n: a \nint\n, input length\n\n\nlogits_from_embedding_fn\n: callable that takes embeddings and returns\nclassifier logits.\n\n\nnum_classes\n: num_classes for training\n\n\nvocab_size\n: a \nint\n, vocabular size of the problem\n\n\nnum_power_iteration\n: a \nint\n, the number of power iteration\n\n\nsmall_constant_for_finite_diff\n: a \nfloat\n, Small constant for finite difference method\n\n\nperturb_norm_length\n: a \nfloat\n, Norm length of adversarial perturbation to be optimized with validatio\n\n\n\n\nReturns\n\n\n\na \nfloat\n \nscalar\n, KL divergence.\n\n\n\n\nGenerate a mask for the EOS token (1.0 on EOS, 0.0 otherwise)\n\n\ntefla.core.losses._end_of_seq_mask\n  (tokens,  vocab_size)\n\n\nArgs\n\n\n\n\n\ntokens\n: 1-D integer \nTensor\n [num_timesteps*batch_size]. Each element is an\nid from the vocab.\n\n\nvocab_size\n: a \nint\n, vocabular size of the problem\n\n\n\n\nReturns\n\n\n\nFloat 1-D \nTensor\n same shape as tokens, whose values are 1.0 on the end of\nsequence and 0.0 on the others.\n\n\n\n\nReturns weighted KL divergence between distributions q and p\n\n\ntefla.core.losses._kl_divergence_with_logits\n  (q_logits,  p_logits,  weights,  num_classes)\n\n\nArgs\n\n\n\n\n\nq_logits\n: logits for 1st argument of KL divergence shape\n  [num_timesteps * batch_size, num_classes] if num_classes \n 2, and\n  [num_timesteps * batch_size] if num_classes == 2.\n\n\np_logits\n: logits for 2nd argument of KL divergence with same shape q_logits.\n\n\nweights\n: 1-D \nfloat\n tensor with shape [num_timesteps * batch_size].\n Elements should be 1.0 only on end of sequences\n\n\nnum_classes\n: a \nint\n, number of training classes\n\n\n\n\nReturns\n\n\n\na \nfloat\n \nscalar\n, KL divergence.\n\n\n\n\nCalculates the per-example cross-entropy loss for a sequence of logits and\n\n\ntefla.core.losses.cross_entropy_sequence_loss\n  (logits,  targets,  sequence_length)\n\nmasks out all losses passed the sequence length.\n\n\nArgs\n\n\n\n\n\nlogits\n: Logits of shape \n[T, B, vocab_size]\n\n\ntargets\n: Target classes of shape \n[T, B]\n\n\nsequence_length\n: An int32 tensor of shape \n[B]\n corresponding\n -to the length of each input\n\n\n\n\nReturns\n\n\n\nA tensor of shape [T, B] that contains the loss per example, per time step.", 
            "title": "Losses"
        }, 
        {
            "location": "/core/losses/#define-a-log-loss", 
            "text": "tefla.core.losses.log_loss_custom   (predictions,  labels,  eps=1e-07,  name='log')", 
            "title": "Define a log loss"
        }, 
        {
            "location": "/core/losses/#define-a-log-loss_1", 
            "text": "tefla.core.losses.log_loss_tf   (predictions,  labels,  eps=1e-07,  weights=1.0,  name='log_loss')", 
            "title": "Define a log loss"
        }, 
        {
            "location": "/core/losses/#define-a-kappa-loss-its-a-continuous-differentiable-approximation-of-discrete-kappa-loss", 
            "text": "tefla.core.losses.kappa_loss   (predictions,  labels,  y_pow=1,  eps=1e-15,  num_ratings=5,  batch_size=32,  name='kappa')", 
            "title": "Define a kappa loss, Its a continuous differentiable approximation of discrete kappa loss"
        }, 
        {
            "location": "/core/losses/#define-a-joint-kappa-and-log-loss-kappa-is-a-continuous-differentiable-approximation-of-discrete-kappa-loss", 
            "text": "tefla.core.losses.kappa_log_loss   (predictions,  labels,  label_smoothing=0.0,  y_pow=1,  batch_size=32,  log_scale=0.5,  num_classes=5,  log_offset=0.5,  name='kappa_log')", 
            "title": "Define a joint kappa and log loss, Kappa is a continuous differentiable approximation of discrete kappa loss"
        }, 
        {
            "location": "/core/losses/#define-a-joint-kappa-and-log-loss-log-loss-is-clipped-by-a-defined-min-value-kappa-is-a-continuous-differentiable-approximation-of-discrete-kappa-loss", 
            "text": "tefla.core.losses.kappa_log_loss_clipped   (predictions,  labels,  label_smoothing=0.0,  y_pow=1,  batch_size=32,  log_scale=0.5,  log_cutoff=0.8,  num_classes=5,  name='kappa_log_clipped')", 
            "title": "Define a joint kappa and log loss; log loss is clipped by a defined min value; Kappa is a continuous differentiable approximation of discrete kappa loss"
        }, 
        {
            "location": "/core/losses/#define-a-cross-entropy-loss-with-label-smoothing", 
            "text": "tefla.core.losses.cross_entropy_loss   (logits,  labels,  label_smoothing=0.0,  weight=1.0,  name='cross_entropy_loss')", 
            "title": "Define a cross entropy loss with label smoothing"
        }, 
        {
            "location": "/core/losses/#define-a-l2loss-useful-for-regularize-ie-weight-decay", 
            "text": "tefla.core.losses.l1_l2_regularizer   (var,  weight_l1=1.0,  weight_l2=1.0,  name='l1_l2_regularizer')", 
            "title": "Define a L2Loss, useful for regularize, i.e. weight decay"
        }, 
        {
            "location": "/core/losses/#returns-a-function-that-can-be-used-to-apply-l1-regularization-to-weights", 
            "text": "tefla.core.losses.l1_regularizer   (scale,  name='l1_regularizer') \nL1 regularization encourages sparsity.", 
            "title": "Returns a function that can be used to apply L1 regularization to weights"
        }, 
        {
            "location": "/core/losses/#returns-a-function-that-can-be-used-to-apply-l2-regularization-to-weights", 
            "text": "tefla.core.losses.l2_regularizer   (scale,  name='l2_regularizer') \nSmall values of L2 can help prevent overfitting the training data.", 
            "title": "Returns a function that can be used to apply L2 regularization to weights"
        }, 
        {
            "location": "/core/losses/#log-likelihood-for-mixture-of-discretized-logistics-assumes-the-data-has-been-rescaled-to-11-interval", 
            "text": "tefla.core.losses.discretized_mix_logistic_loss   (inputs,  predictions,  sum_all=True,  name='disretized_mix_logistic_loss')", 
            "title": "log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval"
        }, 
        {
            "location": "/core/losses/#pull-away-loss-calculation", 
            "text": "tefla.core.losses.pullaway_loss   (embeddings,  name='pullaway_loss')", 
            "title": "Pull Away loss calculation"
        }, 
        {
            "location": "/core/losses/#calculate-the-loss-from-the-logits-and-the-labels", 
            "text": "tefla.core.losses.segment_loss   (logits,  labels,  num_classes,  head=None)", 
            "title": "Calculate the loss from the logits and the labels"
        }, 
        {
            "location": "/core/losses/#calculate-the-triplet-loss-according-to-the-facenet-paper", 
            "text": "tefla.core.losses.triplet_loss   (anchor,  positive,  negative,  alpha=0.2,  name='triplet_loss')", 
            "title": "Calculate the triplet loss according to the FaceNet paper"
        }, 
        {
            "location": "/core/losses/#decov-loss-as-described-in-httpsarxivorgpdf151106068pdf", 
            "text": "tefla.core.losses.decov_loss   (xs,  name='decov_loss') \n'Reducing Overfitting In Deep Networks by Decorrelating Representation'", 
            "title": "Decov loss as described in https://arxiv.org/pdf/1511.06068.pdf"
        }, 
        {
            "location": "/core/losses/#center-loss-based-on-the-paper-a-discriminative-feature-learning-approach-for-deep-face-recognition", 
            "text": "tefla.core.losses.center_loss   (features,  label,  alpha,  num_classes,  name='center_loss') \n   (http://ydwen.github.io/papers/WenECCV16.pdf)", 
            "title": "Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\""
        }, 
        {
            "location": "/core/losses/#adds-a-similarity-loss-term-the-correlation-between-two-representations", 
            "text": "tefla.core.losses.correlation_loss   (source_samples,  target_samples,  weight,  name='corr_loss')", 
            "title": "Adds a similarity loss term, the correlation between two representations"
        }, 
        {
            "location": "/core/losses/#computes-the-maximum-mean-discrepancy-mmd-of-two-samples-x-and-y", 
            "text": "tefla.core.losses.maximum_mean_discrepancy   (x,  y,  kernel= ,  name='maximum_mean_discrepancy')  Maximum Mean Discrepancy (MMD) is a distance-measure between the samples of\nthe distributions of x and y. Here we use the kernel two sample estimate\nusing the empirical mean of the two distributions.  MMD^2(P, Q) = || \\E{\\phi(x)} - \\E{\\phi(y)} ||^2= \\E{ K(x, x) } + \\E{ K(y, y) } - 2 \\E{ K(x, y) },  where K =  \\phi(x), \\phi(y) ,\n  is the desired kernel function, in this case a radial basis kernel.", 
            "title": "Computes the Maximum Mean Discrepancy (MMD) of two samples: x and y"
        }, 
        {
            "location": "/core/losses/#adds-a-similarity-loss-term-the-mmd-between-two-representations", 
            "text": "tefla.core.losses.mmd_loss   (source_samples,  target_samples,  weight,  name='mmd_loss')  This Maximum Mean Discrepancy (MMD) loss is calculated with a number of\ndifferent Gaussian kernels.", 
            "title": "Adds a similarity loss term, the MMD between two representations"
        }, 
        {
            "location": "/core/losses/#adds-the-domain-adversarial-dann-loss", 
            "text": "tefla.core.losses.dann_loss   (source_samples,  target_samples,  weight,  name='dann_loss')", 
            "title": "Adds the domain adversarial (DANN) loss"
        }, 
        {
            "location": "/core/losses/#adds-the-difference-loss-between-the-private-and-shared-representations", 
            "text": "tefla.core.losses.difference_loss   (private_samples,  shared_samples,  weight=1.0,  name='difference_loss')", 
            "title": "Adds the difference loss between the private and shared representations"
        }, 
        {
            "location": "/core/losses/#a-helper-function-to-compute-the-error-between-quaternions", 
            "text": "tefla.core.losses.log_quaternion_loss_batch   (predictions,  labels,  name='log_quaternion_batch_loss')", 
            "title": "A helper function to compute the error between quaternions"
        }, 
        {
            "location": "/core/losses/#a-helper-function-to-compute-the-mean-error-between-batches-of-quaternions", 
            "text": "tefla.core.losses.log_quaternion_loss   (predictions,  labels,  batch_size,  name='log_quaternion_loss')  The caller is expected to add the loss to the graph.", 
            "title": "A helper function to compute the mean error between batches of quaternions"
        }, 
        {
            "location": "/core/losses/#adds-noise-to-embeddings-and-recomputes-classification-loss", 
            "text": "tefla.core.losses.random_perturbation_loss   (embedded,  length,  loss_fn,  perturb_norm_length=0.1)", 
            "title": "Adds noise to embeddings and recomputes classification loss"
        }, 
        {
            "location": "/core/losses/#adds-gradient-to-embedding-and-recomputes-classification-loss", 
            "text": "tefla.core.losses.adversarial_loss   (embedded,  loss,  loss_fn,  perturb_norm_length=0.1)", 
            "title": "Adds gradient to embedding and recomputes classification loss"
        }, 
        {
            "location": "/core/losses/#virtual-adversarial-loss", 
            "text": "tefla.core.losses.virtual_adversarial_loss   (logits,  embedded,  labels,  length,  logits_from_embedding_fn,  num_classes,  num_power_iteration=1,  small_constant_for_finite_diff=0.001,  perturb_norm_length=0.1) \nComputes virtual adversarial perturbation by finite difference method and\npower iteration, adds it to the embedding, and computes the KL divergence\nbetween the new logits and the original logits.", 
            "title": "Virtual adversarial loss"
        }, 
        {
            "location": "/core/losses/#adds-noise-to-embeddings-and-recomputes-classification-loss-fir-bidirectional-rnn-models", 
            "text": "tefla.core.losses.random_perturbation_loss_brnn   (embedded,  length,  loss_fn,  perturb_norm_length=0.1)", 
            "title": "Adds noise to embeddings and recomputes classification loss fir bidirectional rnn models"
        }, 
        {
            "location": "/core/losses/#adds-gradient-to-embeddings-and-recomputes-classification-loss-for-bidirectional-rnn-models", 
            "text": "tefla.core.losses.adversarial_loss_brnn   (embedded,  loss,  loss_fn,  perurb_norm_length=0.1)", 
            "title": "Adds gradient to embeddings and recomputes classification loss for bidirectional rnn models"
        }, 
        {
            "location": "/core/losses/#virtual-adversarial-loss-for-bidirectional-models", 
            "text": "tefla.core.losses.virtual_adversarial_loss_brnn   (logits,  embedded,  labels,  length,  logits_from_embedding_fn,  vocab_size,  num_classes,  num_power_iteration=1,  small_constant_for_finite_diff=0.001,  perturb_norm_length=0.1) \nComputes virtual adversarial perturbation by finite difference method and\npower iteration, adds it to the embedding, and computes the KL divergence\nbetween the new logits and the original logits.", 
            "title": "Virtual adversarial loss for bidirectional models"
        }, 
        {
            "location": "/core/losses/#generate-a-mask-for-the-eos-token-10-on-eos-00-otherwise", 
            "text": "tefla.core.losses._end_of_seq_mask   (tokens,  vocab_size)", 
            "title": "Generate a mask for the EOS token (1.0 on EOS, 0.0 otherwise)"
        }, 
        {
            "location": "/core/losses/#returns-weighted-kl-divergence-between-distributions-q-and-p", 
            "text": "tefla.core.losses._kl_divergence_with_logits   (q_logits,  p_logits,  weights,  num_classes)", 
            "title": "Returns weighted KL divergence between distributions q and p"
        }, 
        {
            "location": "/core/losses/#calculates-the-per-example-cross-entropy-loss-for-a-sequence-of-logits-and", 
            "text": "tefla.core.losses.cross_entropy_sequence_loss   (logits,  targets,  sequence_length) \nmasks out all losses passed the sequence length.", 
            "title": "Calculates the per-example cross-entropy loss for a sequence of logits and"
        }, 
        {
            "location": "/core/summary/", 
            "text": "Add summary to a tensor, scalar summary if the tensor is 1D, else scalar and histogram summary\n\n\ntefla.core.summary.summary_metric\n  (tensor,  name=None,  collections=None)\n\n\nArgs\n\n\n\n\n\ntensor\n: a tensor to add summary\n\n\nname\n: name of the tensor\n\n\ncollections\n: training or validation collections\n\n\n\n\n\n\nAdd summary to a tensor, scalar summary if the tensor is 1D, else  scalar and histogram summary\n\n\ntefla.core.summary.summary_activation\n  (tensor,  name=None,  collections=None)\n\n\nArgs\n\n\n\n\n\ntensor\n: a tensor to add summary\n\n\nname\n: name of the tensor\n\n\ncollections\n: training or validation collections\n\n\n\n\n\n\ncreates the summar writter for training and validation\n\n\ntefla.core.summary.create_summary_writer\n  (summary_dir,  sess)\n\n\nArgs\n\n\n\n\n\nsummary_dir\n: the directory to write summary\n\n\nsess\n: the session to sun the ops\n\n\n\n\nReturns\n\n\n\ntraining and vaidation summary writter\n\n\n\n\nAdd summary as per the ops mentioned\n\n\ntefla.core.summary.summary_param\n  (op,  tensor,  ndims,  name,  collections=None)\n\n\nArgs\n\n\n\n\n\nop\n: name of the summary op; e.g. 'stddev'\navailable ops: ['scalar', 'histogram', 'sparsity', 'mean', 'rms', 'stddev', 'norm', 'max', 'min']\n\n\ntensor\n: the tensor to add summary\n\n\nndims\n: dimension of the tensor\n\n\nname\n: name of the op\n\n\ncollections\n: training or validation collections\n\n\n\n\n\n\nAdd summary to all trainable tensors\n\n\ntefla.core.summary.summary_trainable_params\n  (summary_types,  collections=None)\n\n\nArgs\n\n\n\n\n\nsummary_type\n: a list of all sumary types to add\ne.g.: ['scalar', 'histogram', 'sparsity', 'mean', 'rms', 'stddev', 'norm', 'max', 'min']\n\n\ncollections\n: training or validation collections\n\n\n\n\n\n\nAdd summary to all gradient tensors\n\n\ntefla.core.summary.summary_gradients\n  (grad_vars,  summary_types,  collections=None)\n\n\nArgs\n\n\n\n\n\ngrads_vars\n: grads and vars list\n\n\nsummary_type\n: a list of all sumary types to add\ne.g.: ['scalar', 'histogram', 'sparsity', 'mean', 'rms', 'stddev', 'norm', 'max', 'min']\n\n\ncollections\n: training or validation collections\n\n\n\n\n\n\nAdd image summary to a image tensor\n\n\ntefla.core.summary.summary_image\n  (tensor,  name=None,  max_images=10,  collections=None)\n\n\nArgs\n\n\n\n\n\ntensor\n: a tensor to add summary\n\n\nname\n: name of the tensor\n\n\nmax_images\n: num of images to add summary\n\n\ncollections\n: training or validation collections", 
            "title": "Summaries"
        }, 
        {
            "location": "/core/summary/#add-summary-to-a-tensor-scalar-summary-if-the-tensor-is-1d-else-scalar-and-histogram-summary", 
            "text": "tefla.core.summary.summary_metric   (tensor,  name=None,  collections=None)", 
            "title": "Add summary to a tensor, scalar summary if the tensor is 1D, else scalar and histogram summary"
        }, 
        {
            "location": "/core/summary/#add-summary-to-a-tensor-scalar-summary-if-the-tensor-is-1d-else-scalar-and-histogram-summary_1", 
            "text": "tefla.core.summary.summary_activation   (tensor,  name=None,  collections=None)", 
            "title": "Add summary to a tensor, scalar summary if the tensor is 1D, else  scalar and histogram summary"
        }, 
        {
            "location": "/core/summary/#creates-the-summar-writter-for-training-and-validation", 
            "text": "tefla.core.summary.create_summary_writer   (summary_dir,  sess)", 
            "title": "creates the summar writter for training and validation"
        }, 
        {
            "location": "/core/summary/#add-summary-as-per-the-ops-mentioned", 
            "text": "tefla.core.summary.summary_param   (op,  tensor,  ndims,  name,  collections=None)", 
            "title": "Add summary as per the ops mentioned"
        }, 
        {
            "location": "/core/summary/#add-summary-to-all-trainable-tensors", 
            "text": "tefla.core.summary.summary_trainable_params   (summary_types,  collections=None)", 
            "title": "Add summary to all trainable tensors"
        }, 
        {
            "location": "/core/summary/#add-summary-to-all-gradient-tensors", 
            "text": "tefla.core.summary.summary_gradients   (grad_vars,  summary_types,  collections=None)", 
            "title": "Add summary to all gradient tensors"
        }, 
        {
            "location": "/core/summary/#add-image-summary-to-a-image-tensor", 
            "text": "tefla.core.summary.summary_image   (tensor,  name=None,  max_images=10,  collections=None)", 
            "title": "Add image summary to a image tensor"
        }, 
        {
            "location": "/core/logger/", 
            "text": "Set the log file name, using append mode\n\n\ntefla.core.logger.setFileHandler\n  (filename,  mode='a')\n\n\nArgs\n\n\n\n\n\nfilename\n: log file name\n\n\ne.g. tefla.log\n\n\nmode\n: file writing mode, append/over write if exists else start new file\n\n\ne.g. a string, 'a' or 'w'\n\n\n\n\n\n\nset the verbosity level of logging\n\n\ntefla.core.logger.setVerbosity\n  (verbosity=0)\n\n\nArgs\n\n\n\n\n\nverbosity\n: set the verbosity level using an integer {0, 1, 2, 3, 4} \n\n\ne.g. verbosity=0, imply DEBUG logging, it logs all level of logs\n verbosity=1, imply INFO logging\n verbosity=2, imply WARN logging\n verbosity=3, imply ERROR logging\n verbosity=4, imply FATAL logging, it logs only the lowest FATAL level\n\n\n\n\n\n\nLogs the Highest level DEBUG logging, it logs all level\n\n\ntefla.core.logger.debug\n  (msg,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nmsg\n: the message to log\n\n\n\n\n\n\nLogs the level INFO logging, it logs all LEVEL BELOW INFO\n\n\ntefla.core.logger.info\n  (msg,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nmsg\n: the message to log\n\n\n\n\n\n\nLogs the WARN logging, it logs all level BELOW WARN\n\n\ntefla.core.logger.warn\n  (msg,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nmsg\n: the message to log\n\n\n\n\n\n\nLogs the level ERROR logging, it logs level ERROR  and FATAL\n\n\ntefla.core.logger.error\n  (msg,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nmsg\n: the message to log\n\n\n\n\n\n\nLogs thE level FATAL logging, it logs only FATAL\n\n\ntefla.core.logger.fatal\n  (msg,  \nargs,  \n*kwargs)\n\n\nArgs\n\n\n\n\n\nmsg\n: the message to log", 
            "title": "Logger"
        }, 
        {
            "location": "/core/logger/#set-the-log-file-name-using-append-mode", 
            "text": "tefla.core.logger.setFileHandler   (filename,  mode='a')", 
            "title": "Set the log file name, using append mode"
        }, 
        {
            "location": "/core/logger/#set-the-verbosity-level-of-logging", 
            "text": "tefla.core.logger.setVerbosity   (verbosity=0)", 
            "title": "set the verbosity level of logging"
        }, 
        {
            "location": "/core/logger/#logs-the-highest-level-debug-logging-it-logs-all-level", 
            "text": "tefla.core.logger.debug   (msg,   args,   *kwargs)", 
            "title": "Logs the Highest level DEBUG logging, it logs all level"
        }, 
        {
            "location": "/core/logger/#logs-the-level-info-logging-it-logs-all-level-below-info", 
            "text": "tefla.core.logger.info   (msg,   args,   *kwargs)", 
            "title": "Logs the level INFO logging, it logs all LEVEL BELOW INFO"
        }, 
        {
            "location": "/core/logger/#logs-the-warn-logging-it-logs-all-level-below-warn", 
            "text": "tefla.core.logger.warn   (msg,   args,   *kwargs)", 
            "title": "Logs the WARN logging, it logs all level BELOW WARN"
        }, 
        {
            "location": "/core/logger/#logs-the-level-error-logging-it-logs-level-error-and-fatal", 
            "text": "tefla.core.logger.error   (msg,   args,   *kwargs)", 
            "title": "Logs the level ERROR logging, it logs level ERROR  and FATAL"
        }, 
        {
            "location": "/core/logger/#logs-the-level-fatal-logging-it-logs-only-fatal", 
            "text": "tefla.core.logger.fatal   (msg,   args,   *kwargs)", 
            "title": "Logs thE level FATAL logging, it logs only FATAL"
        }, 
        {
            "location": "/core/iter_ops/", 
            "text": "Creates training iterator to access and augment the dataset\n\n\ntefla.core.iter_ops.create_training_iters\n  (cnf,  data_set,  standardizer,  crop_size,  epoch,  parallel=True)\n\n\nArgs\n\n\n\n\n\ncnf\n: configs dict with all training and augmentation params\n\n\ndata_set\n: an instance of the dataset class\n\n\nstandardizer\n: data samples standardization; either samplewise or aggregate\n\n\ncrop_size\n: training time crop_size of the data samples\n\n\nepoch\n: the current epoch number; used for data balancing\n\n\nparallel\n: iterator type; either parallel or queued\n\n\n\n\n\n\nCreates prediction iterator to access and augment the dataset\n\n\ntefla.core.iter_ops.create_prediction_iter\n  (cnf,  standardizer,  crop_size,  preprocessor=None,  sync=False)\n\n\nArgs\n\n\n\n\n\ncnf\n: configs dict with all training and augmentation params\n\n\nstandardizer\n: data samples standardization; either samplewise or aggregate\n\n\ncrop_size\n: training time crop_size of the data samples\n\n\npreprocessor\n: data processing or cropping function\n\n\nsync\n: a bool, if False, used parallel iterator", 
            "title": "Iter Ops"
        }, 
        {
            "location": "/core/iter_ops/#creates-training-iterator-to-access-and-augment-the-dataset", 
            "text": "tefla.core.iter_ops.create_training_iters   (cnf,  data_set,  standardizer,  crop_size,  epoch,  parallel=True)", 
            "title": "Creates training iterator to access and augment the dataset"
        }, 
        {
            "location": "/core/iter_ops/#creates-prediction-iterator-to-access-and-augment-the-dataset", 
            "text": "tefla.core.iter_ops.create_prediction_iter   (cnf,  standardizer,  crop_size,  preprocessor=None,  sync=False)", 
            "title": "Creates prediction iterator to access and augment the dataset"
        }, 
        {
            "location": "/da/data/", 
            "text": "Warp an image according to a given coordinate transformation\n\n\ntefla.da.data.fast_warp\n  (img,  tf,  output_shape,  mode='constant',  mode_cval=0,  order=0)\n\n\nThis wrapper function is faster than skimage.transform.warp\n\nArgs\n\n\n\n\nimg\n: \nndarray\n, input image\n\n\ntf\n: For 2-D images, you can directly pass a transformation object\ne.g. skimage.transform.SimilarityTransform, or its inverse.\n\n\noutput_shape\n: tuple, (rows, cols)\n\n\nmode\n: mode for transformation\navailable modes: {\nconstant\n, \nedge\n, \nsymmetric\n, \nreflect\n, \nwrap\n}\n\n\nmode_cval\n: float, Used in conjunction with mode \nconstant\n, the value outside the image boundaries\n\n\norder\n: int, The order of interpolation. The order has to be in the range 0-5:\n0: Nearest-neighbor\n1: Bi-linear (default)\n2: Bi-quadratic\n3: Bi-cubic\n4: Bi-quartic\n5: Bi-quintic\n\n\n\n\nReturns\n\n\n\nwarped, double \nndarray\n\n\n\n\nTransform input image contrast\n\n\ntefla.da.data.contrast_transform\n  (img,  contrast_min=0.8,  contrast_max=1.2)\n\n\nTransform the input image contrast by a factor returned by a unifrom\ndistribution with \ncontarst_min\n and \ncontarst_max\n as params\n\n\nArgs\n\n\n\n\n\nimg\n: \nndarray\n, input image\n\n\ncontrast_min\n: float, minimum contrast for transformation\n\n\ncontrast_max\n: float, maximum contrast for transformation\n\n\n\n\nReturns\n\n\n\nndarray\n, contrast enhanced image\n\n\n\n\nTransform input image brightness\n\n\ntefla.da.data.brightness_transform\n  (img,  brightness_min=0.93,  brightness_max=1.4)\n\n\nTransform the input image brightness by a factor returned by a unifrom\ndistribution with \nbrightness_min\n and \nbrightness_max\n as params\n\n\nArgs\n\n\n\n\n\nimg\n: \nndarray\n, input image\n\n\nbrightness_min\n: float, minimum contrast for transformation\n\n\nbrightness_max\n: float, maximum contrast for transformation\n\n\n\n\nReturns\n\n\n\nndarray\n, brightness transformed image\n\n\n\n\nRescale Transform\n\n\ntefla.da.data.build_rescale_transform_slow\n  (downscale_factor,  image_shape,  target_shape)\n\n\nThis mimics the skimage.transform.resize function.\nThe resulting image is centered.\n\n\nArgs\n\n\n\n\n\ndownscale_factor\n: float, \n1\n\n\nimage_shape\n: tuple(rows, cols), input image shape\n\n\ntarget_shape\n: tuple(rows, cols), output image shape\n\n\n\n\nReturns\n\n\n\nrescaled centered image transform instance\n\n\n\n\nRescale Transform\n\n\ntefla.da.data.build_rescale_transform_fast\n  (downscale_factor,  image_shape,  target_shape)\n\n\nestimating the correct rescaling transform is slow, so just use the\ndownscale_factor to define a transform directly. This probably isn't\n100% correct, but it shouldn't matter much in practice.\nThe resulting image is centered.\n\n\nArgs\n\n\n\n\n\ndownscale_factor\n: float, \n1\n\n\nimage_shape\n: tuple(rows, cols), input image shape\n\n\ntarget_shape\n: tuple(rows, cols), output image shape\n\n\n\n\nReturns\n\n\n\nrescaled and centering transform instance\n\n\n\n\nImage cetering transform\n\n\ntefla.da.data.build_centering_transform\n  (image_shape,  target_shape)\n\n\nArgs\n\n\n\n\n\nimage_shape\n: tuple(rows, cols), input image shape\n\n\ntarget_shape\n: tuple(rows, cols), output image shape\n\n\n\n\nReturns\n\n\n\na centering transform instance\n\n\n\n\nCenter Unceter transform\n\n\ntefla.da.data.build_center_uncenter_transforms\n  (image_shape)\n\n\nThese are used to ensure that zooming and rotation happens around the center of the image.\nUse these transforms to center and uncenter the image around such a transform.\n\n\nArgs\n\n\n\n\n\nimage_shape\n: tuple(rows, cols), input image shape\n\n\n\n\nReturns\n\n\n\na center and an uncenter transform instance\n\n\n\n\nAugmentation transform\n\n\ntefla.da.data.build_augmentation_transform\n  (zoom=  (1.0,  1.0),  rotation=0,  shear=0,  translation=  (0,  0),  flip=False)\n\n\nIt performs zooming, rotation, shear, translation and flip operation\nAffine Transformation on the input image\n\n\nArgs\n\n\n\n\n\nzoom\n: a tuple(zoom_rows, zoom_cols)\n\n\nrotation\n: float, Rotation angle in counter-clockwise direction as radians.\n\n\nshear\n: float, shear angle in counter-clockwise direction as radians\n\n\ntranslation\n: tuple(trans_rows, trans_cols)\n\n\nflip\n: bool, flip an image\n\n\n\n\nReturns\n\n\n\naugment tranform instance\n\n\n\n\nRandom perturbation\n\n\ntefla.da.data.random_perturbation_transform\n  (zoom_range,  rotation_range,  shear_range,  translation_range,  do_flip=True,  allow_stretch=False,  rng=\n)\n\n\nIt perturbs the image randomly\n\n\nArgs\n\n\n\n\n\nzoom_range\n: a tuple(min_zoom, max_zoom)\ne.g.: (1/1.15, 1.15)\n\n\nrotation_range\n: a tuple(min_angle, max_angle)\ne.g.: (0. 360)\n\n\nshear_range\n: a tuple(min_shear, max_shear)\ne.g.: (0, 15)\n\n\ntranslation_range\n: a tuple(min_shift, max_shift)\ne.g.: (-15, 15)\n\n\ndo_flip\n: bool, flip an image\n\n\nallow_stretch\n: bool, stretch an image\n\n\nrng\n: an instance\n\n\n\n\nReturns\n\n\n\naugment transform instance\n\n\n\n\ncrop an image\n\n\ntefla.da.data.definite_crop\n  (img,  bbox)\n\n\nArgs\n\n\n\n\n\nimg\n: \nndarray\n, input image\n\n\nbbox\n: list, with crop co-ordinates and width and height\ne.g.: [x, y, width, height]\n\n\n\n\nReturns\n\n\n\nreturns cropped image\n\n\n\n\nPerturb image\n\n\ntefla.da.data.perturb\n  (img,  augmentation_params,  target_shape,  rng=\n,  mode='constant',  mode_cval=0)\n\n\nIt perturbs an image with augmentation transform\n\n\nArgs\n\n\n\n\n\nimg\n: a \nndarray\n, input image\n\n\naugmentation_paras\n: a dict, with augmentation name as keys and values as params\n\n\ntarget_shape\n: a tuple(rows, cols), output image shape\n\n\nrng\n: an instance for random number generation\n\n\nmode\n: mode for transformation\navailable modes: {\nconstant\n, \nedge\n, \nsymmetric\n, \nreflect\n, \nwrap\n}\n\n\nmode_cval\n: float, Used in conjunction with mode \nconstant\n,\nthe value outside the image boundaries\n\n\n\n\nReturns\n\n\n\na \nndarray\n of transformed image\n\n\n\n\nPerturb image rescaled\n\n\ntefla.da.data.perturb_rescaled\n  (img,  scale,  augmentation_params,  target_shape=  (224,  224),  rng=\n,  mode='constant',  mode_cval=0)\n\n\nIt perturbs an image with augmentation transform\n\n\nArgs\n\n\n\n\n\nimg\n: a \nndarray\n, input image\n\n\nscale\n: float, \n1, downscaling factor.\n\n\naugmentation_paras\n: a dict, with augmentation name as keys and values as params\n\n\ntarget_shape\n: a tuple(rows, cols), output image shape\n\n\nrng\n: an instance for random number generation\n\n\nmode\n: mode for transformation\navailable modes: {\nconstant\n, \nedge\n, \nsymmetric\n, \nreflect\n, \nwrap\n}\n\n\nmode_cval\n: float, Used in conjunction with mode \nconstant\n,\nthe value outside the image boundaries\n\n\n\n\nReturns\n\n\n\na \nndarray\n of transformed image\n\n\n\n\nPerturb image Determinastic\n\n\ntefla.da.data.perturb_fixed\n  (img,  tform_augment,  target_shape=  (50,  50),  mode='constant',  mode_cval=0)\n\n\nIt perturbs an image with augmentation transform with determinastic params\nused for validation/testing data\n\n\nArgs\n\n\n\n\n\nimg\n: a \nndarray\n, input image\n\n\naugmentation_paras\n: a dict, with augmentation name as keys and values as params\n\n\ntarget_shape\n: a tuple(rows, cols), output image shape\n\n\nmode\n: mode for transformation\navailable modes: {\nconstant\n, \nedge\n, \nsymmetric\n, \nreflect\n, \nwrap\n}\n\n\nmode_cval\n: float, Used in conjunction with mode \nconstant\n,\nthe value outside the image boundaries\n\n\n\n\nReturns\n\n\n\na \nndarray\n of transformed image\n\n\n\n\nLoad augmented image with output shape (w, h)\n\n\ntefla.da.data.load_augment\n  (fname,  preprocessor,  w,  h,  is_training,  aug_params={'zoom_range':(1.0,  1.0),  'translation_range':(0,  0),  'shear_range':(0,  0),  'do_flip':  False,  'allow_stretch':  False,  'rotation_range':(0,  0)},  transform=None,  bbox=None,  fill_mode='constant',  fill_mode_cval=0,  standardizer=None,  save_to_dir=None)\n\n\nDefault arguments return non augmented image of shape (w, h).\nTo apply a fixed transform (color augmentation) specify transform\n(color_vec).\nTo generate a random augmentation specify aug_params and sigma.\n\n\nArgs\n\n\n\n\n\nfname\n: string, image filename\n\n\npreprocessor\n: real-time image processing/crop\n\n\nw\n: int, width of target image\n\n\nh\n: int, height of target image\n\n\nis_training\n: bool, if True then training else validation\n\n\naug_params\n: a dict, augmentation params\n\n\ntransform\n: transform instance\n\n\nbbox\n: object bounding box\n\n\nfll_mode\n: mode for transformation\navailable modes: {\nconstant\n, \nedge\n, \nsymmetric\n, \nreflect\n, \nwrap\n}\n\n\nfill_mode_cval\n: float, Used in conjunction with mode \nconstant\n,\nthe value outside the image boundaries\n\n\nstandardizer\n: image standardizer, zero mean, unit variance image\n e.g.: samplewise standardized each image based on its own value\n\n\nsave_to_dir\n: a string, path to save image, save output image to a dir\n\n\n\n\nReturns\n\n\n\naugmented image\n\n\n\n\nOpen Image\n\n\ntefla.da.data.image_no_preprocessing\n  (fname)\n\n\nArgs\n\n\n\n\n\nfname\n: Image filename\n\n\n\n\nReturns\n\n\n\nPIL formatted image\n\n\n\n\nLoad batch of images\n\n\ntefla.da.data.load_images\n  (imgs,  preprocessor=\n)\n\n\nArgs\n\n\n\n\n\nimgs\n: a list of image filenames\n\n\npreprocessor\n: image processing function\n\n\n\n\nReturns\n\n\n\na \nndarray\n with a batch of images\n\n\n\n\nLoad image\n\n\ntefla.da.data.load_image\n  (img,  preprocessor=\n)\n\n\nArgs\n\n\n\n\n\nimg\n: a image filename\n\n\npreprocessor\n: image processing function\n\n\n\n\nReturns\n\n\n\na processed image\n\n\n\n\nSave image\n\n\ntefla.da.data.save_image\n  (x,  fname)\n\n\nArgs\n\n\n\n\n\nx\n: input array\n\n\nfname\n: filename of the output image\n\n\n\n\n\n\nData balancing utility\n\n\ntefla.da.data.balance_per_class_indices\n  (y,  weights)\n\n\nArgs\n\n\n\n\n\ny\n: class labels\n\n\nweights\n: sampling weights per class\n\n\n\n\nReturns\n\n\n\nbalanced batch as per weights", 
            "title": "Data Augmentation"
        }, 
        {
            "location": "/da/data/#warp-an-image-according-to-a-given-coordinate-transformation", 
            "text": "tefla.da.data.fast_warp   (img,  tf,  output_shape,  mode='constant',  mode_cval=0,  order=0)  This wrapper function is faster than skimage.transform.warp", 
            "title": "Warp an image according to a given coordinate transformation"
        }, 
        {
            "location": "/da/data/#transform-input-image-contrast", 
            "text": "tefla.da.data.contrast_transform   (img,  contrast_min=0.8,  contrast_max=1.2)  Transform the input image contrast by a factor returned by a unifrom\ndistribution with  contarst_min  and  contarst_max  as params", 
            "title": "Transform input image contrast"
        }, 
        {
            "location": "/da/data/#transform-input-image-brightness", 
            "text": "tefla.da.data.brightness_transform   (img,  brightness_min=0.93,  brightness_max=1.4)  Transform the input image brightness by a factor returned by a unifrom\ndistribution with  brightness_min  and  brightness_max  as params", 
            "title": "Transform input image brightness"
        }, 
        {
            "location": "/da/data/#rescale-transform", 
            "text": "tefla.da.data.build_rescale_transform_slow   (downscale_factor,  image_shape,  target_shape)  This mimics the skimage.transform.resize function.\nThe resulting image is centered.", 
            "title": "Rescale Transform"
        }, 
        {
            "location": "/da/data/#rescale-transform_1", 
            "text": "tefla.da.data.build_rescale_transform_fast   (downscale_factor,  image_shape,  target_shape)  estimating the correct rescaling transform is slow, so just use the\ndownscale_factor to define a transform directly. This probably isn't\n100% correct, but it shouldn't matter much in practice.\nThe resulting image is centered.", 
            "title": "Rescale Transform"
        }, 
        {
            "location": "/da/data/#image-cetering-transform", 
            "text": "tefla.da.data.build_centering_transform   (image_shape,  target_shape)", 
            "title": "Image cetering transform"
        }, 
        {
            "location": "/da/data/#center-unceter-transform", 
            "text": "tefla.da.data.build_center_uncenter_transforms   (image_shape)  These are used to ensure that zooming and rotation happens around the center of the image.\nUse these transforms to center and uncenter the image around such a transform.", 
            "title": "Center Unceter transform"
        }, 
        {
            "location": "/da/data/#augmentation-transform", 
            "text": "tefla.da.data.build_augmentation_transform   (zoom=  (1.0,  1.0),  rotation=0,  shear=0,  translation=  (0,  0),  flip=False)  It performs zooming, rotation, shear, translation and flip operation\nAffine Transformation on the input image", 
            "title": "Augmentation transform"
        }, 
        {
            "location": "/da/data/#random-perturbation", 
            "text": "tefla.da.data.random_perturbation_transform   (zoom_range,  rotation_range,  shear_range,  translation_range,  do_flip=True,  allow_stretch=False,  rng= )  It perturbs the image randomly", 
            "title": "Random perturbation"
        }, 
        {
            "location": "/da/data/#crop-an-image", 
            "text": "tefla.da.data.definite_crop   (img,  bbox)", 
            "title": "crop an image"
        }, 
        {
            "location": "/da/data/#perturb-image", 
            "text": "tefla.da.data.perturb   (img,  augmentation_params,  target_shape,  rng= ,  mode='constant',  mode_cval=0)  It perturbs an image with augmentation transform", 
            "title": "Perturb image"
        }, 
        {
            "location": "/da/data/#perturb-image-rescaled", 
            "text": "tefla.da.data.perturb_rescaled   (img,  scale,  augmentation_params,  target_shape=  (224,  224),  rng= ,  mode='constant',  mode_cval=0)  It perturbs an image with augmentation transform", 
            "title": "Perturb image rescaled"
        }, 
        {
            "location": "/da/data/#perturb-image-determinastic", 
            "text": "tefla.da.data.perturb_fixed   (img,  tform_augment,  target_shape=  (50,  50),  mode='constant',  mode_cval=0)  It perturbs an image with augmentation transform with determinastic params\nused for validation/testing data", 
            "title": "Perturb image Determinastic"
        }, 
        {
            "location": "/da/data/#load-augmented-image-with-output-shape-w-h", 
            "text": "tefla.da.data.load_augment   (fname,  preprocessor,  w,  h,  is_training,  aug_params={'zoom_range':(1.0,  1.0),  'translation_range':(0,  0),  'shear_range':(0,  0),  'do_flip':  False,  'allow_stretch':  False,  'rotation_range':(0,  0)},  transform=None,  bbox=None,  fill_mode='constant',  fill_mode_cval=0,  standardizer=None,  save_to_dir=None)  Default arguments return non augmented image of shape (w, h).\nTo apply a fixed transform (color augmentation) specify transform\n(color_vec).\nTo generate a random augmentation specify aug_params and sigma.", 
            "title": "Load augmented image with output shape (w, h)"
        }, 
        {
            "location": "/da/data/#open-image", 
            "text": "tefla.da.data.image_no_preprocessing   (fname)", 
            "title": "Open Image"
        }, 
        {
            "location": "/da/data/#load-batch-of-images", 
            "text": "tefla.da.data.load_images   (imgs,  preprocessor= )", 
            "title": "Load batch of images"
        }, 
        {
            "location": "/da/data/#load-image", 
            "text": "tefla.da.data.load_image   (img,  preprocessor= )", 
            "title": "Load image"
        }, 
        {
            "location": "/da/data/#save-image", 
            "text": "tefla.da.data.save_image   (x,  fname)", 
            "title": "Save image"
        }, 
        {
            "location": "/da/data/#data-balancing-utility", 
            "text": "tefla.da.data.balance_per_class_indices   (y,  weights)", 
            "title": "Data balancing utility"
        }, 
        {
            "location": "/da/standardizer/", 
            "text": "Samplewise Standardizer\n\n\ntefla.da.standardizer.SamplewiseStandardizer\n  (clip,  channel_wise=False)\n\n\nArgs\n\n\n\n\n\nclip\n: max/min allowed value in the output image\ne.g.: 6\n\n\nchannel_wise\n: perform standarization separately accross channels\n\n\n\n\n\n\nSamplewise Standardizer\n\n\ntefla.da.standardizer.SamplewiseStandardizerTF\n  (clip,  channel_wise=False)\n\n\nArgs\n\n\n\n\n\nclip\n: max/min allowed value in the output image\ne.g.: 6\n\n\nchannel_wise\n: perform standarization separately accross channels\n\n\n\n\n\n\nAggregate Standardizer\n\n\ntefla.da.standardizer.AggregateStandardizer\n  (mean,  std,  u,  ev,  sigma=0.0,  color_vec=None)\n\n\nCreates a standardizer based on whole training dataset\n\n\nArgs\n\n\n\n\n\nmean\n: 1-D array, aggregate mean array\ne.g.: mean is calculated for each color channel, R, G, B\n\n\nstd\n: 1-D array, aggregate standard deviation array\ne.g.: std is calculated for each color channel, R, G, B\n\n\nu\n: 2-D array, eigenvector for the color channel variation\n\n\nev\n: 1-D array, eigenvalues\n\n\nsigma\n: float, noise factor\n\n\ncolor_vec\n: an optional color vector\n\n\n\n\nMethods\n\n\n\n \n\n\naugment_color\n  (img,  sigma=0.0,  color_vec=None)\n\n\nArgs\n\n\n\n\n\nimg\n: input image\n\n\nsigma\n: a float, noise factor\n\n\ncolor_vec\n: an optional color vec\n\n\n\n\n\n\nAggregate Standardizer\n\n\ntefla.da.standardizer.AggregateStandardizerTF\n  (mean,  std,  u,  ev,  sigma=0.0,  color_vec=None)\n\n\nCreates a standardizer based on whole training dataset\n\n\nArgs\n\n\n\n\n\nmean\n: 1-D array, aggregate mean array\ne.g.: mean is calculated for each color channel, R, G, B\n\n\nstd\n: 1-D array, aggregate standard deviation array\ne.g.: std is calculated for each color channel, R, G, B\n\n\nu\n: 2-D array, eigenvector for the color channel variation\n\n\nev\n: 1-D array, eigenvalues\n\n\nsigma\n: float, noise factor\n\n\ncolor_vec\n: an optional color vector\n\n\n\n\nMethods\n\n\n\n \n\n\naugment_color\n  (img,  sigma=0.0,  color_vec=None)\n\n\nArgs\n\n\n\n\n\nimg\n: input image\n\n\nsigma\n: a float, noise factor\n\n\ncolor_vec\n: an optional color vec", 
            "title": "Standardizer"
        }, 
        {
            "location": "/da/standardizer/#samplewise-standardizer", 
            "text": "tefla.da.standardizer.SamplewiseStandardizer   (clip,  channel_wise=False)", 
            "title": "Samplewise Standardizer"
        }, 
        {
            "location": "/da/standardizer/#samplewise-standardizer_1", 
            "text": "tefla.da.standardizer.SamplewiseStandardizerTF   (clip,  channel_wise=False)", 
            "title": "Samplewise Standardizer"
        }, 
        {
            "location": "/da/standardizer/#aggregate-standardizer", 
            "text": "tefla.da.standardizer.AggregateStandardizer   (mean,  std,  u,  ev,  sigma=0.0,  color_vec=None)  Creates a standardizer based on whole training dataset", 
            "title": "Aggregate Standardizer"
        }, 
        {
            "location": "/da/standardizer/#aggregate-standardizer_1", 
            "text": "tefla.da.standardizer.AggregateStandardizerTF   (mean,  std,  u,  ev,  sigma=0.0,  color_vec=None)  Creates a standardizer based on whole training dataset", 
            "title": "Aggregate Standardizer"
        }, 
        {
            "location": "/dataset/image_to_tfrecords/", 
            "text": "", 
            "title": "TfRecords"
        }, 
        {
            "location": "/dataset/base/", 
            "text": "A simple class for handling data sets,\n\n\ntefla.dataset.base.Dataset\n  (name,  decoder,  data_dir=None,  num_classes=10,  num_examples_per_epoch=1,  batch_size=1,  items_to_descriptions=None,  **kwargs)\n\n\nArgs\n\n\n\n\n\nname\n: a string, Name of the class instance\n\n\ndecoder\n: object instance, tfrecords object decoding and image encoding and decoding\n\n\ndata_dir\n: a string, path to the data folder\n\n\nnum_classes\n: num of classes of the dataset\n\n\nnum_examples_per_epoch\n: total number of examples per epoch\n\n\nitems_to_description\n: a string descriving the items of the dataset\n\n\n\n\nMethods\n\n\n\n \n\n\ndata_files\n  (self)\n\n\nReturns\n\n\n\npython list of all (sharded) data set files.", 
            "title": "Dataset"
        }, 
        {
            "location": "/dataset/base/#a-simple-class-for-handling-data-sets", 
            "text": "tefla.dataset.base.Dataset   (name,  decoder,  data_dir=None,  num_classes=10,  num_examples_per_epoch=1,  batch_size=1,  items_to_descriptions=None,  **kwargs)", 
            "title": "A simple class for handling data sets,"
        }, 
        {
            "location": "/dataset/dataflow/", 
            "text": "Dataflow handling class\n\n\ntefla.dataset.dataflow.Dataflow\n  (dataset,  num_readers=1,  shuffle=True,  num_epochs=None,  min_queue_examples=1024,  capacity=2048)\n\n\nArgs\n\n\n\n\n\ndataset\n: an instance of the dataset class\n\n\nnum_readers\n: num of readers to  read the dataset\n\n\nshuffle\n: a bool, shuffle the dataset\n\n\nnum_epochs\n: total number of epoch for training or validation\n\n\nmin_queue_examples\n: minimum number of items after dequeue\n\n\ncapacity\n: total queue capacity\n\n\n\n\nMethods\n\n\n\n \n\n\nbatch_inputs\n  (batch_size,  train,  tfrecords_image_size,  crop_size,  im_size=None,  bbox=None,  image_preprocessing=None,  num_preprocess_threads=16)\n\n\nArgs\n\n\n\n\n\ndataset\n: instance of Dataset class specifying the dataset.\n\n\nSee dataset.py for details.\n\n\nbatch_size\n: integer\n\n\ntrain\n: boolean\n\n\ncrop_size\n: training time image size. a int or tuple\n\n\ntfrecords_image_size\n: a list with original image size used to encode image in tfrecords\ne.g.: [width, height, channel]\n\n\nimage_processing\n: a function to process image\n\n\nnum_preprocess_threads\n: integer, total number of preprocessing threads\n\n\n\n\nReturns\n\n\n\nimages: 4-D float Tensor of a batch of images\nlabels: 1-D integer Tensor of [batch_size].\n\n\n \n\n\nget\n  (items,  image_size,  resize_size=None)\n\n\nArgs\n\n\n\n\n\nitems\n: a list, with items to get from the dataset\ne.g.: ['image', 'label']\n\n\nimage_size\n: a list with original image size\ne.g.: [width, height, channel]\n\n\nresize_size\n: if image resize required, provide a list of width and height\ne.g.: [width, height]\n\n\n\n\n \n\n\nget_batch\n  (batch_size,  target_probs,  image_size,  resize_size=None,  crop_size=[32,  32,  3],  image_preprocessing=None,  num_preprocess_threads=32,  init_probs=None,  enqueue_many=True,  queue_capacity=2048,  threads_per_queue=4,  name='balancing_op',  data_balancing=True)\n\n\nStochastically creates batches based on per-class probabilities.\nThis method discards examples. Internally, it creates one queue to\namortize the cost of disk reads, and one queue to hold the properly-proportioned batch.\n\n\nArgs\n\n\n\n\n\nbatch_size\n: a int, batch_size\n\n\ntarget_probs\n: probabilities of class samples to be present in the batch\n\n\nimage_size\n: a list with original image size\ne.g.: [width, height, channel]\n\n\nresize_size\n: if image resize required, provide a list of width and height\ne.g.: [width, height]\n\n\ninit_probs\n: initial probs of data sample in the first batch\n\n\nenqueue_many\n: bool, if true, interpret input tensors as having a batch dimension.\n\n\nqueue_capacity\n: Capacity of the large queue that holds input examples.\n\n\nthreads_per_queue\n: Number of threads for the large queue that holds\ninput examples and for the final queue with the proper class proportions.\n\n\nname\n: a optional scope/name of the op\n\n\n\n\n \n\n\nprefetch\n  (tensor_dict,  capacity)\n\nCreates a FIFO queue to asynchronously enqueue tensor_dicts and returns a\ndequeue op that evaluates to a tensor_dict. This function is useful in\nprefetching preprocessed tensors so that the data is readily available for\nconsumers.\n\n\nArgs\n\n\n\n\n\ntensor_dict\n: a dictionary of tensors to prefetch.\n\n\ncapacity\n: the size of the prefetch queue.\n\n\n\n\nReturns\n\n\n\na FIFO prefetcher queue", 
            "title": "Dataflow"
        }, 
        {
            "location": "/dataset/dataflow/#dataflow-handling-class", 
            "text": "tefla.dataset.dataflow.Dataflow   (dataset,  num_readers=1,  shuffle=True,  num_epochs=None,  min_queue_examples=1024,  capacity=2048)", 
            "title": "Dataflow handling class"
        }, 
        {
            "location": "/dataset/decoder/", 
            "text": "A Decoder class to decode examples\n\n\ntefla.dataset.decoder.Decoder\n  (feature_keys)\n\n\nArgs\n\n\n\n\n\nfeature_keys\n: a dict, with features name and data types\n\n\ne.g.:\nfeatures_keys = {'image/encoded/image': tf.FixedLenFeature((), tf.string, default_value=''),'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),'image/class/label': tf.FixedLenFeature([], tf.int64, - default_value=tf.zeros([], dtype=tf.int64)),\n}\n\n\n\n\nMethods\n\n\n\n \n\n\ndecode\n  (example_serialized,  image_size,  resize_size=None)\n\n\nArgs\n\n\n\n\nexample_serialized\n: scalar Tensor tf.string containing a serialized\nExample protocol buffer.\n\n\nReturns\n:\nimage_buffer: Tensor tf.string containing the contents of a JPEG file.\nlabel: Tensor tf.int32 containing the label.\ntext: Tensor tf.string containing the human-readable label.\n\n\n\n\nReturns\n\n\n\nimage_buffer: Tensor tf.string containing the contents of a JPEG file.\nlabel: Tensor tf.int32 containing the label.\ntext: Tensor tf.string containing the human-readable label.\n\n\n \n\n\ndistort_image\n  (image,  distort_op,  height,  width,  thread_id=0,  scope=None)\n\n\nArgs\n\n\n\n\nimage\n: 3-D float Tensor of image\n\n\nheight\n: integer\n\n\nwidth\n: integer\n\n\nthread_id\n: integer indicating the preprocessing thread.\n\n\n\n\nscope\n: Optional scope for name_scope.\n\nReturns\n\n\n\n\n\n\n3-D float Tensor of distorted image used for training.\n\n\n\n\n\n\nReturns\n\n\n\n3-D float Tensor of distorted image used for training.\n\n\n \n\n\neval_image\n  (image,  height,  width,  scope=None)\n\n\nArgs\n\n\n\n\nimage\n: 3-D float Tensor\n\n\nheight\n: integer\n\n\nwidth\n: integer\n\n\n\n\nscope\n: Optional scope for name_scope.\n\nReturns\n\n\n\n\n\n\n3-D float Tensor of prepared image.\n\n\n\n\n\n\nReturns\n\n\n\n3-D float Tensor of prepared image.\n\n\n \n\n\nparse_example_proto\n  (example_serialized,  is_bbox=False)\n\nThe output of the build_image_data.py image preprocessing script is a dataset\ncontaining serialized Example protocol buffers. Each Example proto contains\nthe following fields:\nimage/height: 462\nimage/width: 581\nimage/colorspace: 'RGB'\nimage/channels: 3\nimage/class/label: 615\nimage/class/synset: 'n03623198'\nimage/class/text: 'knee pad'\nimage/object/bbox/xmin: 0.1\nimage/object/bbox/xma\nx\n\n\n0.9\nimage/object/bbox/ymin: 0.2\nimage/object/bbox/yma\nx\n\n\n0.6\nimage/object/bbox/label: 615\nimage/format: 'JPEG'\nimage/filename: 'ILSVRC2012_val_00041207.JPEG'\nimage/encoded: \n\n\nArgs\n\n\n\n\n\nexample_serialized\n: scalar Tensor tf.string containing a serialized\n\n\nExample protocol buffer.\n\n\n\n\nReturns\n\n\n\nimage_buffer: Tensor tf.string containing the contents of a JPEG file.\nlabel: Tensor tf.int32 containing the label.\nbbo\nx\n\n\n3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\nwhere each coordinate is [0, 1) and the coordinates are arranged as\n[ymin, xmin, ymax, xmax].\ntext: Tensor tf.string containing the human-readable label.", 
            "title": "Decoder"
        }, 
        {
            "location": "/dataset/decoder/#a-decoder-class-to-decode-examples", 
            "text": "tefla.dataset.decoder.Decoder   (feature_keys)", 
            "title": "A Decoder class to decode examples"
        }, 
        {
            "location": "/dataset/reader/", 
            "text": "TFrecords reader class\n\n\ntefla.dataset.reader.Reader\n  (dataset,  reader_kwargs=None,  shuffle=True,  num_readers=16,  capacity=1,  num_epochs=None)\n\n\nArgs\n\n\n\n\n\ndataset\n: an instance of the dataset class\n\n\nreader_kwargs\n: extra arguments to be passed to the TFRecordReader\n\n\nshuffle\n: whether to shuffle the dataset\n\n\nnum_readers\n:a int, num of readers to launch\n\n\ncapacity\n: a int, capacity of the queue used\n\n\nnum_epochs\n: a int, num of epochs for training or validation\n\n\n\n\nMethods\n\n\n\n \n\n\nparallel_reader\n  (min_queue_examples=1024)\n\n\nPrimarily used for Training ops\n\n\nArgs\n\n\n\n\n\nmin_queue_examples\n: min number of queue examples after dequeue\n\n\n\n\n \n\n\nsingle_reader\n  (num_epochs=1,  shuffle=False,  capacity=1)\n\n\nData will be read using single TFRecordReader, primarily used for validation\n\n\nArgs\n\n\n\n\n\nnum_epochs\n: number of epoch\n\n\nshuffle\n: shuffle the dataset. False for validation\n\n\ncapacity\n: queue capacity\n\n\n\n\nReturns\n\n\n\na single item from the tfrecord files", 
            "title": "Reader"
        }, 
        {
            "location": "/dataset/reader/#tfrecords-reader-class", 
            "text": "tefla.dataset.reader.Reader   (dataset,  reader_kwargs=None,  shuffle=True,  num_readers=16,  capacity=1,  num_epochs=None)", 
            "title": "TFrecords reader class"
        }, 
        {
            "location": "/utils/util/", 
            "text": "Device chooser for variables\n\n\ntefla.utils.util.VariableDeviceChooser\n  (num_parameter_servers=0,  ps_device='/job:ps',  placement='CPU:0')\n\nWhen using a parameter server it will assign them in a round-robin fashion.\nWhen not using a parameter server it allows GPU:0 placement otherwise CPU:0.\nInitialize VariableDeviceChooser.\n\n\nArgs\n\n\n\n\n\nnum_parameter_servers\n: number of parameter servers.\n\n\nps_device\n: string representing the parameter server device.\n\n\nplacement\n: string representing the placement of the variable either CPU:0\nor GPU:0. When using parameter servers forced to CPU:0.\n\n\n\n\n\n\nValid types for loss, variables and gradients\n\n\ntefla.utils.util.valid_dtypes\n  ()\n\nSubclasses should override to allow other float types.\n\nReturns\n\n\nValid types for loss, variables and gradients.\n\n\n\n\nAsserts tensors are all valid types (see \n_valid_dtypes\n)\n\n\ntefla.utils.util.assert_valid_dtypes\n  (tensors)\n\n\nArgs\n\n\n\n\n\n\ntensors\n: Tensors to check.\n\nRaises\n\n\n\n\n\n\nValueError\n: If any tensor is not a valid type.\n\n\n\n\n\n\n\n\nReturns value if value_or_tensor_or_var has a constant value\n\n\ntefla.utils.util.constant_value\n  (value_or_tensor_or_var,  dtype=None)\n\n\nArgs\n\n\n\n\n\nvalue_or_tensor_or_var\n: A value, a \nTensor\n or a \nVariable\n.\n\n\ndtype\n: Optional \ntf.dtype\n, if set it would check it has the right\n\n\ndtype.\n\n\n\n\nReturns\n\n\n\nThe constant value or None if it not constant.\n\n\n\n\nReturn either fn1() or fn2() based on the boolean value of \npred\n\n\ntefla.utils.util.static_cond\n  (pred,  fn1,  fn2)\n\n\nSame signature as \ncontrol_flow_ops.cond()\n but requires pred to be a bool.\n\n\nArgs\n\n\n\n\n\npred\n: A value determining whether to return the result of \nfn1\n or \nfn2\n.\n\n\nfn1\n: The callable to be performed if pred is true.\n\n\nfn2\n: The callable to be performed if pred is false.\n\n\n\n\nReturns\n\n\n\nTensors returned by the call to either \nfn1\n or \nfn2\n.\n\n\n\n\nReturn either fn1() or fn2() based on the boolean predicate/value \npred\n\n\ntefla.utils.util.smart_cond\n  (pred,  fn1,  fn2,  name=None)\n\n\nIf \npred\n is bool or has a constant value it would use \nstatic_cond\n,\n otherwise it would use \ntf.cond\n.\n\n\nArgs\n\n\n\n\n\npred\n: A scalar determining whether to return the result of \nfn1\n or \nfn2\n.\n\n\nfn1\n: The callable to be performed if pred is true.\n\n\nfn2\n: The callable to be performed if pred is false.\n\n\n\n\nname\n: Optional name prefix when using tf.cond\n\nReturns\n\n\n\n\n\n\nTensors returned by the call to either \nfn1\n or \nfn2\n.\n\n\n\n\n\n\nReturns\n\n\n\nTensors returned by the call to either \nfn1\n or \nfn2\n.\n\n\n\n\nTransform numeric labels into onehot_labels\n\n\ntefla.utils.util.one_hot\n  (labels,  num_classes,  name='one_hot')\n\n\nArgs\n\n\n\n\nlabels\n: [batch_size] target labels.\n\n\nnum_classes\n: total number of classes.\n\n\n\n\nscope\n: Optional scope for op_scope.\n\nReturns\n\n\n\n\n\n\none hot encoding of the labels.\n\n\n\n\n\n\nReturns\n\n\n\none hot encoding of the labels.\n\n\n\n\nReturns a true if its input is a collections.Sequence (except strings)\n\n\ntefla.utils.util.is_sequence\n  (seq)\n\n\nArgs\n\n\n\n\n\nseq\n: an input sequence.\n\n\n\n\nReturns\n\n\n\nTrue if the sequence is a not a string and is a collections.Sequence.\n\n\n\n\nReturns a flat sequence from a given nested structure\n\n\ntefla.utils.util.flatten_sq\n  (nest_sq)\n\nIf \nnest\n is not a sequence, this returns a single-element list: \n[nest]\n.\n\n\nArgs\n\n\n\n\n\nnest\n: an arbitrarily nested structure or a scalar object.\nNote, numpy arrays are considered scalars.\n\n\n\n\nReturns\n\n\n\nA Python list, the flattened version of the input.\n\n\n\n\nReturns the last dimension of shape while checking it has min_rank\n\n\ntefla.utils.util.last_dimension\n  (shape,  min_rank=1)\n\n\nArgs\n\n\n\n\n\nshape\n: A \nTensorShape\n.\n\n\nmin_rank\n: Integer, minimum rank of shape.\n\n\n\n\nReturns\n\n\n\nThe value of the last dimension.\n\n\n\n\nLoad Graph from frozen weights and model\n\n\ntefla.utils.util.load_frozen_graph\n  (frozen_graph)\n\n\nArgs\n\n\n\n\n\nfrozen_graph\n: binary pb file\n\n\n\n\nReturns\n\n\n\nloaded graph\n\n\n\n\nNormalize a input layer\n\n\ntefla.utils.util.normalize\n  (input_layer)\n\n\nArgs\n\n\n\n\n\ninmput_layer\n: input layer tp normalize\n\n\n\n\nReturns\n\n\n\nnormalized layer\n\n\n\n\nDeNormalize a input layer\n\n\ntefla.utils.util.denormalize\n  (input_layer)\n\n\nArgs\n\n\n\n\n\ninput_layer\n: input layer to de normalize\n\n\n\n\nReturns\n\n\n\ndenormalized layer\n\n\n\n\nComputes the squared pairwise Euclidean distances between x and y\n\n\ntefla.utils.util.compute_pairwise_distances\n  (x,  y)\n\n\nArgs\n\n\n\n\n\nx\n: a tensor of shape [num_x_samples, num_features]\n\n\ny\n: a tensor of shape [num_y_samples, num_features]\n\n\n\n\nReturns\n\n\n\na distance matrix of dimensions [num_x_samples, num_y_samples].\n\n\n\n\nComputes a Guassian Radial Basis Kernel between the samples of x and y\n\n\ntefla.utils.util.gaussian_kernel_matrix\n  (x,  y,  sigmas)\n\nWe create a sum of multiple gaussian kernels each having a width sigma_i.\n\n\nArgs\n\n\n\n\n\nx\n: a tensor of shape [num_samples, num_features]\n\n\ny\n: a tensor of shape [num_samples, num_features]\n\n\nsigmas\n: a tensor of floats which denote the widths of each of the\ngaussians in the kernel.\n\n\n\n\nReturns\n\n\n\nA tensor of shape [num_samples{x}, num_samples{y}] with the RBF kernel.\n\n\n\n\ncompute the length of a sequence. 0 are masked\n\n\ntefla.utils.util.retrieve_seq_length\n  (data)\n\n\nArgs\n\n\n\n\n\ndata\n: input sequence\n\n\n\n\nReturns\n\n\n\na \nint\n, length of the sequence\n\n\n\n\nAdvanced Indexing for Sequences\n\n\ntefla.utils.util.advanced_indexing\n  (inp,  index)\n\n\nArgs\n\n\n\n\ninp\n: input sequence\n\n\nindex\n: input index for indexing\n\n\n\n\nReturns\n\n\n\na indexed sequence\n\n\n\n\npad_sequences\n\n\ntefla.utils.util.pad_sequences\n  (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0)\n\nPad each sequence to the same length: the length of the longest sequence.\nIf maxlen is provided, any sequence longer than maxlen is truncated to\nmaxlen. Truncation happens off either the beginning or the end (default)\nof the sequence. Supports pre-padding and post-padding (default).\n\n\nArgs\n\n\n\n\n\nsequences\n: list of lists where each element is a sequence.\n\n\nmaxlen\n: a \nint\n, maximum length.\n\n\ndtype\n: type to cast the resulting sequence.\n\n\npadding\n: 'pre' or 'post', pad either before or after each sequence.\n\n\ntruncating\n: 'pre' or 'post', remove values from sequences larger than\nmaxlen either in the beginning or in the end of the sequence\n\n\nvalue\n: \nfloat\n, value to pad the sequences to the desired value.\n\n\n\n\nReturns\n\n\n\nx\n\n\n\nnumpy array\n with dimensions (number_of_sequences, maxlen)\n\n\n\n\nCreates a dictionary char:integer for each unique character\n\n\ntefla.utils.util.chars_to_dictionary\n  (string)\n\n\nArgs\n\n\n\n\nstring\n: a \nstring\n input\n\n\n\n\nReturns\n\n\n\ndictionary of chars\n\n\n\n\nstring_to_semi_redundant_sequences\n\n\ntefla.utils.util.string_to_semi_redundant_sequences\n  (string,  seq_maxlen=25,  redun_step=3,  char_idx=None)\n\nVectorize a string and returns parsed sequences and targets, along with\nthe associated dictionary.\n\n\nArgs\n\n\n\n\n\nstring\n: \nstr\n. Lower-case text from input text file.\n\n\nseq_maxlen\n: \nint\n. Maximum length of a sequence. Default: 25.\n\n\nredun_step\n: \nint\n. Redundancy step. Default: 3.\n\n\nchar_idx\n: 'dict'. A dictionary to convert chars to positions. Will be automatically generated if None\n\n\n\n\nReturns\n\n\n\nA tuple: (inputs, targets, dictionary)\n\n\n\n\nVectorize Text file\n\n\ntefla.utils.util.textfile_to_semi_redundant_sequences\n  (path,  seq_maxlen=25,  redun_step=3,  to_lower_case=False,  pre_defined_char_idx=None)\n\ntextfile_to_semi_redundant_sequences.\nVectorize a string from a textfile and returns parsed sequences and targets, along with\nthe associated dictionary.\n\n\nArgs\n\n\n\n\n\npath\n: \nstr\n. path of the input text file.\n\n\nseq_maxlen\n: \nint\n. Maximum length of a sequence. Default: 25.\n\n\nredun_step\n: \nint\n. Redundancy step. Default: 3.\n\n\nto_lower_case\n: a \nbool\n, if true, convert to lowercase\n\n\npre_defined_char_idx\n: 'dict'. A dictionary to convert chars to positions. Will be automatically generated if None\n\n\n\n\nReturns\n\n\n\nA tuple: (inputs, targets, dictionary)\n\n\n\n\nComputes log probabilities using numerically stable trick\n\n\ntefla.utils.util.logits_to_log_prob\n  (logits)\n\nThis uses two numerical stability tricks:\n1) softmax(x) = softmax(x - c) where c is a constant applied to all\narguments. If we set c = max(x) then the softmax is more numerically\nstable.\n2) log softmax(x) is not numerically stable, but we can stabilize it\nby using the identity log softmax(x) = x - log sum exp(x)\n\n\nArgs\n\n\n\n\n\nlogits\n: Tensor of arbitrary shape whose last dimension contains logits.\n\n\n\n\nReturns\n\n\n\nA tensor of the same shape as the input, but with corresponding log\nprobabilities.\n\n\n\n\nGet the name of the op that created a tensor\n\n\ntefla.utils.util.GetTensorOpName\n  (x)\n\nUseful for naming related tensors, as ':' in name field of op is not permitted\n\n\nArgs\n\n\n\nx\n\n\nthe input tensor.\n\n\nReturns\n\n\n\nthe name of the op.\n\n\n\n\nReturns the union of two lists\n\n\ntefla.utils.util.ListUnion\n  (list_1,  list_2)\n\nPython sets can have a non-deterministic iteration order. In some\ncontexts, this could lead to TensorFlow producing two different\nprograms when the same Python script is run twice. In these contexts\nwe use lists instead of sets.\nThis function is not designed to be especially fast and should only\nbe used with small lists.\n\n\nArgs\n\n\n\n\n\nlist_1: A list\n\n\nlist_2: Another list\n\n\n\n\nReturns\n\n\n\nA new list containing one copy of each unique element of list_1 and\n  list_2. Uniqueness is determined by \"x in union\" logic; e.g. two\n`  string of that value appearing in the union.\n\n\n\n\nMaps xs to consumers\n\n\ntefla.utils.util.Interface\n  (ys,  xs)\n\n  Returns a dict mapping each element of xs to any of its consumers that are\n  indirectly consumed by ys.\n\n\nArgs\n\n\n\nys: The outputs\n  xs: The inputs\n\n\nReturns\n\n\n\nout: Dict mapping each member x of \nxs\n to a list of all Tensors that are\n   direct consumers of x and are eventually consumed by a member of\n   \nys\n.\n\n\n\n\nClip an array of tensors by L2 norm\n\n\ntefla.utils.util.BatchClipByL2norm\n  (t,  upper_bound,  name=None)\n\nShrink each dimension-0 slice of tensor (for matrix it is each row) such\nthat the l2 norm is at most upper_bound. Here we clip each row as it\ncorresponds to each example in the batch.\n\n\nArgs\n\n\n\nt: the input tensor.\n  upper_bound: the upperbound of the L2 norm.\n  name: optional name.\n\n\nReturns\n\n\n\nthe clipped tensor.\n\n\n\n\nAdd i.i.d. Gaussian noise (0, sigma^2) to every entry of t\n\n\ntefla.utils.util.AddGaussianNoise\n  (t,  sigma,  name=None)\n\n\nArgs\n\n\n\nt: the input tensor.\n  sigma: the stddev of the Gaussian noise.\n  name: optional name.\n\n\nReturns\n\n\n\nthe noisy tensor.", 
            "title": "Utils"
        }, 
        {
            "location": "/utils/util/#device-chooser-for-variables", 
            "text": "tefla.utils.util.VariableDeviceChooser   (num_parameter_servers=0,  ps_device='/job:ps',  placement='CPU:0') \nWhen using a parameter server it will assign them in a round-robin fashion.\nWhen not using a parameter server it allows GPU:0 placement otherwise CPU:0.\nInitialize VariableDeviceChooser.", 
            "title": "Device chooser for variables"
        }, 
        {
            "location": "/utils/util/#valid-types-for-loss-variables-and-gradients", 
            "text": "tefla.utils.util.valid_dtypes   () \nSubclasses should override to allow other float types.", 
            "title": "Valid types for loss, variables and gradients"
        }, 
        {
            "location": "/utils/util/#asserts-tensors-are-all-valid-types-see-_valid_dtypes", 
            "text": "tefla.utils.util.assert_valid_dtypes   (tensors)", 
            "title": "Asserts tensors are all valid types (see _valid_dtypes)"
        }, 
        {
            "location": "/utils/util/#returns-value-if-value_or_tensor_or_var-has-a-constant-value", 
            "text": "tefla.utils.util.constant_value   (value_or_tensor_or_var,  dtype=None)", 
            "title": "Returns value if value_or_tensor_or_var has a constant value"
        }, 
        {
            "location": "/utils/util/#return-either-fn1-or-fn2-based-on-the-boolean-value-of-pred", 
            "text": "tefla.utils.util.static_cond   (pred,  fn1,  fn2)  Same signature as  control_flow_ops.cond()  but requires pred to be a bool.", 
            "title": "Return either fn1() or fn2() based on the boolean value of pred"
        }, 
        {
            "location": "/utils/util/#return-either-fn1-or-fn2-based-on-the-boolean-predicatevalue-pred", 
            "text": "tefla.utils.util.smart_cond   (pred,  fn1,  fn2,  name=None)  If  pred  is bool or has a constant value it would use  static_cond ,\n otherwise it would use  tf.cond .", 
            "title": "Return either fn1() or fn2() based on the boolean predicate/value pred"
        }, 
        {
            "location": "/utils/util/#transform-numeric-labels-into-onehot_labels", 
            "text": "tefla.utils.util.one_hot   (labels,  num_classes,  name='one_hot')", 
            "title": "Transform numeric labels into onehot_labels"
        }, 
        {
            "location": "/utils/util/#returns-a-true-if-its-input-is-a-collectionssequence-except-strings", 
            "text": "tefla.utils.util.is_sequence   (seq)", 
            "title": "Returns a true if its input is a collections.Sequence (except strings)"
        }, 
        {
            "location": "/utils/util/#returns-a-flat-sequence-from-a-given-nested-structure", 
            "text": "tefla.utils.util.flatten_sq   (nest_sq) \nIf  nest  is not a sequence, this returns a single-element list:  [nest] .", 
            "title": "Returns a flat sequence from a given nested structure"
        }, 
        {
            "location": "/utils/util/#returns-the-last-dimension-of-shape-while-checking-it-has-min_rank", 
            "text": "tefla.utils.util.last_dimension   (shape,  min_rank=1)", 
            "title": "Returns the last dimension of shape while checking it has min_rank"
        }, 
        {
            "location": "/utils/util/#load-graph-from-frozen-weights-and-model", 
            "text": "tefla.utils.util.load_frozen_graph   (frozen_graph)", 
            "title": "Load Graph from frozen weights and model"
        }, 
        {
            "location": "/utils/util/#normalize-a-input-layer", 
            "text": "tefla.utils.util.normalize   (input_layer)", 
            "title": "Normalize a input layer"
        }, 
        {
            "location": "/utils/util/#denormalize-a-input-layer", 
            "text": "tefla.utils.util.denormalize   (input_layer)", 
            "title": "DeNormalize a input layer"
        }, 
        {
            "location": "/utils/util/#computes-the-squared-pairwise-euclidean-distances-between-x-and-y", 
            "text": "tefla.utils.util.compute_pairwise_distances   (x,  y)", 
            "title": "Computes the squared pairwise Euclidean distances between x and y"
        }, 
        {
            "location": "/utils/util/#computes-a-guassian-radial-basis-kernel-between-the-samples-of-x-and-y", 
            "text": "tefla.utils.util.gaussian_kernel_matrix   (x,  y,  sigmas) \nWe create a sum of multiple gaussian kernels each having a width sigma_i.", 
            "title": "Computes a Guassian Radial Basis Kernel between the samples of x and y"
        }, 
        {
            "location": "/utils/util/#compute-the-length-of-a-sequence-0-are-masked", 
            "text": "tefla.utils.util.retrieve_seq_length   (data)", 
            "title": "compute the length of a sequence. 0 are masked"
        }, 
        {
            "location": "/utils/util/#advanced-indexing-for-sequences", 
            "text": "tefla.utils.util.advanced_indexing   (inp,  index)", 
            "title": "Advanced Indexing for Sequences"
        }, 
        {
            "location": "/utils/util/#pad_sequences", 
            "text": "tefla.utils.util.pad_sequences   (sequences,  maxlen=None,  dtype='int32',  padding='post',  truncating='post',  value=0.0) \nPad each sequence to the same length: the length of the longest sequence.\nIf maxlen is provided, any sequence longer than maxlen is truncated to\nmaxlen. Truncation happens off either the beginning or the end (default)\nof the sequence. Supports pre-padding and post-padding (default).", 
            "title": "pad_sequences"
        }, 
        {
            "location": "/utils/util/#creates-a-dictionary-charinteger-for-each-unique-character", 
            "text": "tefla.utils.util.chars_to_dictionary   (string)", 
            "title": "Creates a dictionary char:integer for each unique character"
        }, 
        {
            "location": "/utils/util/#string_to_semi_redundant_sequences", 
            "text": "tefla.utils.util.string_to_semi_redundant_sequences   (string,  seq_maxlen=25,  redun_step=3,  char_idx=None) \nVectorize a string and returns parsed sequences and targets, along with\nthe associated dictionary.", 
            "title": "string_to_semi_redundant_sequences"
        }, 
        {
            "location": "/utils/util/#vectorize-text-file", 
            "text": "tefla.utils.util.textfile_to_semi_redundant_sequences   (path,  seq_maxlen=25,  redun_step=3,  to_lower_case=False,  pre_defined_char_idx=None) \ntextfile_to_semi_redundant_sequences.\nVectorize a string from a textfile and returns parsed sequences and targets, along with\nthe associated dictionary.", 
            "title": "Vectorize Text file"
        }, 
        {
            "location": "/utils/util/#computes-log-probabilities-using-numerically-stable-trick", 
            "text": "tefla.utils.util.logits_to_log_prob   (logits) \nThis uses two numerical stability tricks:\n1) softmax(x) = softmax(x - c) where c is a constant applied to all\narguments. If we set c = max(x) then the softmax is more numerically\nstable.\n2) log softmax(x) is not numerically stable, but we can stabilize it\nby using the identity log softmax(x) = x - log sum exp(x)", 
            "title": "Computes log probabilities using numerically stable trick"
        }, 
        {
            "location": "/utils/util/#get-the-name-of-the-op-that-created-a-tensor", 
            "text": "tefla.utils.util.GetTensorOpName   (x) \nUseful for naming related tensors, as ':' in name field of op is not permitted", 
            "title": "Get the name of the op that created a tensor"
        }, 
        {
            "location": "/utils/util/#returns-the-union-of-two-lists", 
            "text": "tefla.utils.util.ListUnion   (list_1,  list_2) \nPython sets can have a non-deterministic iteration order. In some\ncontexts, this could lead to TensorFlow producing two different\nprograms when the same Python script is run twice. In these contexts\nwe use lists instead of sets.\nThis function is not designed to be especially fast and should only\nbe used with small lists.", 
            "title": "Returns the union of two lists"
        }, 
        {
            "location": "/utils/util/#maps-xs-to-consumers", 
            "text": "tefla.utils.util.Interface   (ys,  xs) \n  Returns a dict mapping each element of xs to any of its consumers that are\n  indirectly consumed by ys.", 
            "title": "Maps xs to consumers"
        }, 
        {
            "location": "/utils/util/#clip-an-array-of-tensors-by-l2-norm", 
            "text": "tefla.utils.util.BatchClipByL2norm   (t,  upper_bound,  name=None) \nShrink each dimension-0 slice of tensor (for matrix it is each row) such\nthat the l2 norm is at most upper_bound. Here we clip each row as it\ncorresponds to each example in the batch.", 
            "title": "Clip an array of tensors by L2 norm"
        }, 
        {
            "location": "/utils/util/#add-iid-gaussian-noise-0-sigma2-to-every-entry-of-t", 
            "text": "tefla.utils.util.AddGaussianNoise   (t,  sigma,  name=None)", 
            "title": "Add i.i.d. Gaussian noise (0, sigma^2) to every entry of t"
        }, 
        {
            "location": "/license/", 
            "text": "MIT License\n\n\nCopyright (c) 2016 Tefla contributors\n\n\nTefla uses a shared copyright model: each contributor holds copyright over\ntheir contributions to Tefla. The project versioning records all such\ncontribution and copyright details.\nBy contributing to the Tefla repository through a pull-request, comment,\nor otherwise, a contributor releases their content to the license and\ncopyright terms herein.\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", 
            "title": "License"
        }
    ]
}